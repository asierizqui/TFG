
\documentclass[11pt]{article}

% Sinboloak bilatzeko: http://detexify.kirelabs.org/classify.html

\usepackage[left=2.0cm,right=2.0cm,top=2.5cm,bottom=2.5cm]{geometry}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx} %For the graphics

\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{physics}
\usepackage{tocbibind}
\usepackage{lipsum}
\usepackage{sidenotes}

\usepackage{emptypage}
%\setlength{\oddsidemargin}{20mm}
%\setlength{\evensidemargin}{10mm}


\usepackage[english]{babel}															% English language/hyphenation
\usepackage[protrusion=true,expansion=true]{microtype}	
\usepackage{url}
\usepackage{epigraph} %https://www.overleaf.com/learn/latex/Typesetting_quotations
%\vspace{5cm}
%\epigraph{Mucha gente pequeña, en lugares pequeños, haciendo cosas pequeñas, puede cambiar el mundo}{\textit{Eduardo Galeano}}

\usepackage{hyperref}   %https://tex.stackexchange.com/questions/107832/how-to-create-internet-link-in-pdf
\hypersetup{
     colorlinks   = true,
     citecolor    = blue
}
\usepackage{tocloft} %https://tex.stackexchange.com/questions/98528/further-customize-color-of-hyperref-links
\renewcommand{\cftsubsecfont}{\normalfont\hypersetup{linkcolor=black}}
\renewcommand{\cftsubsecafterpnum}{\hypersetup{linkcolor=gray}}

\usepackage[normalem]{ulem} %https://tex.stackexchange.com/questions/13377/how-can-i-underline-a-single-word-with-latex
\usepackage{braket} % https://tex.stackexchange.com/questions/214728/braket-notation-in-latex
\usepackage[usenames]{color}
\usepackage[dvipsnames]{xcolor}

\addto\captionsspanish{\renewcommand{\tablename}{Tabla}}

\newcommand{\refeq}[1]%
        {\hypersetup{linkcolor=Blue}%
        (\ref{#1})%
        \hypersetup{linkcolor=black}}
\newcommand{\reffig}[1]%
        {\hypersetup{linkcolor=OliveGreen}%
        \ref{#1}%
        \hypersetup{linkcolor=black}}
        
\numberwithin{equation}{section} % To number the equations using the section number as well.  
\numberwithin{figure}{section} % To number the figures using the section number as well.        
\newcommand{\angstrom}{\mbox{\normalfont\AA}}      
        
\graphicspath{ {Images/} }

\usepackage{subcaption}
\usepackage{float}   % https://www.overleaf.com/learn/latex/Positioning_of_Figures
\usepackage[framed, numbered]{matlab-prettifier} %https://tex.stackexchange.com/questions/212098/choosing-lines-from-a-matlab-file-using-matlab-prettifier
\usepackage{multirow}
\usepackage{array}

\usepackage{enumitem}
\usepackage{pdfpages}
\usepackage[titletoc]{appendix}

\makeatletter
\def\@makechapterhead#1{%
  %%%%\vspace*{50\p@}% %%% removed!
  {\parindent \z@ \raggedright \normalfont
    \ifnum \c@secnumdepth >\m@ne
        \huge\bfseries \@chapapp\space \thechapter
        \par\nobreak
        \vskip 20\p@
    \fi
    \interlinepenalty\@M
    \Huge \bfseries #1\par\nobreak
    \vskip 40\p@
  }}
\def\@makeschapterhead#1{%
  %%%%%\vspace*{50\p@}% %%% removed!
  {\parindent \z@ \raggedright
    \normalfont
    \interlinepenalty\@M
    \Huge \bfseries  #1\par\nobreak
    \vskip 40\p@
  }}
\makeatother
\usepackage{etoolbox}
\makeatletter
\appto{\appendices}{\def\Hy@chapapp{Appendix}}
\makeatother 



\usepackage{dblfloatfix}    % To enable figures at the bottom of page
\usepackage{xcolor} %https://www.overleaf.com/learn/latex/Using_colours_in_LaTeX

\newcommand\numeq[1] %https://tex.stackexchange.com/questions/439768/put-reference-above-equal-sign-and-refer-to-it
  {\stackrel{\scriptscriptstyle(\mkern-1.5mu#1\mkern-1.5mu)}{=}}  







%https://tex.stackexchange.com/questions/96549/how-do-i-write-above-a-left-right-arrow
\makeatletter
\newcommand\xleftrightarrow[2][]{%
  \ext@arrow 9999{\longleftrightarrowfill@}{#1}{#2}}
\newcommand\longleftrightarrowfill@{%
  \arrowfill@\leftarrow\relbar\rightarrow}
\makeatother

\usepackage{lineno}  % https://tex.stackexchange.com/questions/130945/refer-to-a-particular-line-of-a-page
%\pagewiselinenumbers    % eskuz EZ zenbatzeko !
%\renewcommand\linenumberfont{\color{black}}

\usepackage{nccmath} % https://tex.stackexchange.com/questions/166378/big-matrix-in-latex






\begin{document}

\begin{center}
\thispagestyle{empty}

\vspace*{-3.5cm}
\makebox[\dimexpr\textwidth+3cm][l]{\includegraphics[scale=0.4]{Images/EHU_and_ZTF_logo.png}}


%\begin{figure}[H]
%\hspace*{-1.5in}
%{\centering {
%\includegraphics[scale=1.0]{Images/EHU_logo.png}%\hspace*{+6 cm}
%\includegraphics[scale=0.3]{Images/ZTF_logo.png}
%\hspace*{-1.5in}
%}\par}\end{figure}


\vspace{2cm}

{\centering \textit{\large{Gradu Amaierako Lana/Trabajo Fin de Grado}}} \\
\vspace{0.3cm}
{\centering \textit{{ \bf{Fisikako Gradua/Grado en F\'isica}}}}
\bigskip
{\centering \large
\par \vspace{2cm}

\hrule \vspace*{0.5cm}

{\LARGE \bf {Classical and Quantum Artificial Life}}

\vspace{0.5cm}\hrule \vspace{3 cm}
{\Large \bf{Asier Izquierdo}}\\
\vspace{1.25cm}
{\it{Director:}} \\
\vspace{0.1cm}
{\large \bf {Prof. Enrique Solano}}\\
\vspace{0.1cm}
{\it{Codirector:}} \\
\vspace{0.1cm}
{\large \bf {Dr. Mikel Sanz}}\\

\vspace{5 cm}

Department of Physical Chemistry \\
Faculty of Science and Technology \\
University of the Basque Country UPV/EHU \\
\vspace*{0.5cm}
Leioa, June 2018}
\end{center}




\newpage

\hypersetup{linkcolor=black} % Colour of the headline of the Table of Contents
\tableofcontents

\newpage

\hypersetup{linkcolor=red} % Equations' Ref. colour

\section{Introduction and Objectives} \label{Introduction}
Analogous to the way classical computers are built from electrical circuits, quantum computers (QC) can be built from so-called quantum circuits \cite[p.~17, l.~29]{Nielsen}, the generalization of classical logic gates. Classical bits are stored on capacitors: an uncharged (charged) capacitor registers a 0 (1). 

On the other hand, in contrast to the pure abstraction usual in classical computation, QCs process information by physical means such as  photons, spins or atoms: the polarization of a photon with its two polarization states,  a spin-$1/2$ particle with its up $\uparrow$ and down $\downarrow$ states, or the superposition of two atomic states, respectively. For the latter, an ion in its ground, or lowest energy, state $\ket{g}\equiv\ket{0}$ (one of its excited states $\ket{e}\equiv\ket{1}$)  can be identified with an uncharged (charged) capacitor \cite[p.~1073, l.~8-19]{Lloyd}, where independent manipulation of each qubit is accomplished by laser beams. 

\emph{Quantum computation} studies the latter sort of systems. Combining physics, mathematics and computer science, it is an \emph{abstract paradigm} for information processing encoded in quantum mechanical variables that may have plenty of applications in technology (Section \ref{objectives_and_relevance}). It takes its power from the following features, which have no classical analog: quantum superposition and entanglement (Appendix \ref{Entanglement}). The former allows more efficiency in terms of memory (for example, a two-level state can be represented by a single qubit instead of using two classical bits) and time (superposition allows following various computation paths simultaneously, exploiting what is called \emph{quantum parallelism}). 

If this processing speed is not enough to persuade you, we can sell it better: Moore's law is presumably reaching its asymptote and, at microscopic scale, quantum effects become important and classical computation theory becomes fundamentally inadequate. The future is quantum!
 
  Quantum computers are able to perform classical logic gates --functions from some fixed number $m$ of input bits to some fixed number $n$ of output bits, $f$ $:$ $\{0,1\}^m\,\rightarrow\,\{0,1\}^n$-- as well as quantum ones, which use quantum bits, named \emph{qubits} (Appendix \ref{qubit_approach}), in superposition of classical bits 0 and 1. Since, as mentioned, QCs are capable of using both classical and quantum gates, they are at least as efficient as conventional computers.
  
   In particular, there are three main classes of quantum algorithms which excel those belonging to classical computers: algorithms that provide quantum versions of the Fourier transform (Appendix \ref{Quantum_Fourier_transform}), quantum search algorithms (Appendix \ref{quantum_search_algorithm}) and \emph{quantum simulations} \cite[p.~37, l.~4-10]{Nielsen}  \cite[p.~1073, l.~65-68]{Lloyd}.

Algorithms are precise recipes for performing particular tasks and constitute the key concept of computer science. The latter type entails mimicking quantum mechanical systems, by engineering Hamiltonians which effectively resemble the dynamics of the system to emulate, beyond classical limitations \cite[p.~39, l.~5-8]{Nielsen}, which allows us to manipulate rather than only observe quantum phenomena. Engineering Hamiltonians means having one system simulate another \emph{directly} and classical limitations refer to the use of amounts of resources, computer time and memory space, that grow as exponential functions with the number of variables (particles, lattice sites, etc.) required to characterize the system of interest \cite[p.~1073, l.~89-95]{Lloyd}. 

Superposition, the weighted sum of two or more states, classically corresponds, for example, to the state of the air when two or more musical tones are sounding at once, to the classical interference of their waves (quantum superposition is also called \emph{interference}). However, classical interferences like playing $n$ musical tones at once can only produce a superposition of $n$ states.

On the other hand, a  quantum register of  $n$ qubits or two-state quantum components (for example, spin-$1/2$ particles) is defined by means of $2^n$ complex numbers or amplitudes in a classical computer,  whereas to calculate its time evolution a $2^n\times 2^n$ unitary matrix $\hat{U}(t,t_0)$ is needed. Thus, for $n$ measurements in a quantum circuit, the result will be one of the $2^n$ possible classical bits. For instance, a two-qubit ($n=2$) pure state is described by $2^{n=2}=4$ linearly independent complex numbers or, equivalently, $2^{n=2}=4$ base states: $\ket{\psi}=a\ket{00}+b\ket{01}+c\ket{10}+d\ket{11}$. 

To be more precise, the state of the quantum system is a point represented by a unit-length (if normalized) vector in a $d=2^n$-dimensional (in other words, with $2^n$ basis kets) complex vector space with inner product defined, known as \emph{Hilbert space} $\mathcal{H}\subset\mathbb{C}^d$ \cite[p.~5, l.~29-30]{Shor}. On the other hand, quantum logic gates produce rotations of the mentioned vectors, and, measurements, probabilistic projections to the chosen basis.

Then, a conventional computer needs more than a million numbers (exactly, $2^{n=20}$) to describe 20 qubits! In a QC, however,  performing the time evolution of a quantum system with $n$ variables requires only $n$ quantum bits! $\,$  \cite[p.~1074, l.~1]{Lloyd}

 For all these reasons, quantum simulations constitute a promising medium-scale application of \emph{quantum information} \cite[p.~48, l.~11]{Nielsen} --the study of information processing tasks accomplished via quantum mechanical systems-- \cite[p.~1, l.~33-34 \& p.~51, l.~3-8]{Nielsen}. 

\emph{Artificial life} (AL) -- the study of biological phenomena by means of simulations -- is a prototypical branch of the mentioned quantum simulations. It serves as a source to gain a deeper understanding about the complex systems that characterize living beings or, with a wider connotation, \emph{living systems} (cells -either nerve cells, named neurons, or tumor cells-, tissues, organisms, ecosystems, human societies or   financial markets). \cite[p.~47]{Ricard_Sole}

\subsection{Categorization} \label{Categorization}

The field of Artificial life can be split into two categories:\\

\textbf{Classical Artificial Life} (CAL)\textbf{:} John Conway's popular cellular automaton, the \emph{Game of Life} (GoL), invented in 1970 \cite[p.~40]{Ricard_Sole}, provides its most notable example. It consists of a 2D grid or lattice of square cells that can be in one of two states: populated (\emph{alive}) or not (\emph{dead}). Its evolution is determined by discrete $\Delta t$ time step interactions with each cell's Moore neighborhood.

 These interactions are determined by the following simple set of rules, where we define $n\in\mathbb{N}$ as the number of populated nearest (orthogonally  adjacent) and next nearest (diagonally adjacent) neighbors or, equivalently, the number of populated cells in each one's mentioned Moore neighborhood:
			\begin{itemize}
			\item \textbf{Death:}
			\begin{itemize}
			\item[$\diamond$] by \uline{overpopulation}: populated cells with $n>3$ at time t depopulate at time t+$\Delta t$.
			\item[$\diamond$] by \uline{underpopulation}: populated cells with $n<2$ at time t depopulate at time t+$\Delta t$.
			\end{itemize}
			\item \textbf{Survival} (for the next generation): populated cells with $n=2,3$ at time t do not change state at time t+$\Delta t$.
			\item \textbf{Reproduction:} unpopulated cells with $n=3$ at time t populate at the next move (time t+$\Delta t$).
			
			\end{itemize}
			
All births and deaths must occur \emph{synchronously} and together make up a single so-called \emph{generation}. \cite[p.~2, l.~16-17]{Gardner} \cite[p.~73]{Adamatzky}

Apart from its conspicuous biological analogies, GoL also bears some resemblance to physical laws through the concept of maximum attainable velocity \cite[p.~4, l.~1-2]{Gardner}. Namely, we can define a \emph{speed of light} c, or the upper bound on the speed of any pattern, as one cell-step across Moore's neighborhood per generation or time step $\Delta t$. Notwithstanding, effectively, no pattern can be built which is able to move, unassisted, one cell every generation. Objects can only travel at the defined \emph{speed of light} through trails (stripes of populated cells) and not if, reminiscent of \emph{vacuum} ($\mu_r=\epsilon_r=1$), the medium is an empty space formed by unpopulated cells, contrary to the situation in nature, where in materials ($\mu_r,\epsilon_r>1$) it is always less: $c=\frac{1}{\sqrt[]{\mu\,\epsilon}}=\frac{1}{\sqrt[]{\mu_0\mu_r\,\epsilon_0\epsilon_r}}<c_0=\frac{1}{\sqrt[]{\mu_0\,\epsilon_0}}$.\\
			
The importance of Conway's automaton system resides in the fact that simple individual cells' interaction rules are able to produce patterns of great complexity -- it even has the power to create an Universal Turing machine \cite[p.~520, Fig.~26.1]{Adamatzky}, a classical computing device capable of efficiently carrying out any algorithm [in computation space (memory) and time (steps) that scale polynomially with the input size], according to the Church-Turing thesis \cite[p.~125,l.~10-13]{Nielsen} [in its quantitative or strong form \cite[p.~2,Thesis.~1.1]{Shor}] --  and the evolution of \emph{life} can be described under these straightforward rules. It constitutes one of the simplest examples of \emph{emergent complexity} or \emph{self-organizing systems}.

Roughly speaking, some aspects belonging to the field of \emph{deterministic chaos} could be identified in this CAL example. Id est, the laws of the system are well known and strict (\emph{deterministic}) -- moreover, relatively simple, here --, but the result of applying them cannot be determined precisely and, in spite of the lack of randomness, it recalls \emph{chaos}. This special coexistence among order and disorder, as we shall see, plays a relevant role in understanding some basic features of quantum life systems such as entanglement (Appendix \ref{Entanglement}). Due to the extraordinary complexity of these results, presently, \emph{the computer has become our new telescope} \cite[p.~17-18]{Ricard_Sole}, even for the relatively simple code in Appendix \ref{appendix_A_code}.\\

\textbf{Quantum Artificial Life} (QAL)\textbf{:} In Ref. \cite[p.~1, l.~1-2]{QAL_IBM} \emph{the first experimental realization of a QAL algorithm in a QC} was presented. Here, biological behaviors such as self-replication (used as a reproduction mechanism), mutation, movement, interaction (feeding on predator-prey ecological subsistence relationships), aging and death (finite lifetime), consistent with the mechanisms of evolution (Darwinian laws of natural selection), were mimicked based on quantum information protocols. \\

\subsection{Objectives and relevance} \label{objectives_and_relevance}

Along with the goal of the model proposed in Ref. \cite[p.~2, l.~15-16]{QAL_IBM} --reproducing the characteristic processes of natural selection, adapted to the language of quantum computing and, more precisely, quantum simulation--, intellectually appealing by itself, we also want to emphasize the importance of AL.

For instance, the cohabitation of predators and preys in the just mentioned QAL example could be replaced in another a priori different field such as a medical context by cancerous and healthy cells \cite[p.~49]{Ricard_Sole} or, within an ecological framework, as polluted and clean air. Moreover, processing information quantum mechanically is a utterly new field for us. Henceforth, we can certainly claim that this work signifies a remarkable widening of scope in the applications of quantum mechanics seen so far in our Physics degree.

In addition, we hope to deepen our very basic knowledge relative to the field of quantum mechanics, the most interdisciplinary topic we can think of, while carrying out a work in a more independent and flexible manner that we use to do, beyond the constraints that arise due to the sometimes rigid program of customary courses and much more limited timeframes. 


\newpage
\section{Classical Artificial Life}

We have considered that the most adecuate path was making a gradual transition from CAL to QAL. On top of this, GoL can be seen as a \emph{less abstract} representation of classical conputation, in a parallelism with QCs, which have a mathematical perspective, but can also be physically built in experimental setups!\\

Let us begin from the abstract part of CAL, the mathematical definition of Cellular Automata:

\subsection{Mathematical definition of Cellular Automata} \label{Mathematical definition CA}

A Cellular Automaton (CA) of dimension $d\in\mathbb{Z}^+$ is defined mathematically by a 5-tuple $(T, L,S,N({\bf x}),f)$ where

\begin{itemize}
 
 \item $T$ is the \emph{timeline}. In GoL, $T=\mathbb{Z}$ is the discrete timeline. 

 \item $L$ is the \emph{d}-dimensional  \emph{grid} or \emph{lattice}. For \emph{continuous} CA, $L=\mathbb{R}^d$, where let $\mathbb{R}^d$ denote the  $d$-dimensional Euclidean space of column vectors with $d$ real components. On the other hand, $L=\mathbb{Z}^d$ for \emph{discrete} ones. In GoL, $L=\mathbb{Z}^2$ is the two-dimensional (\emph{d}=2) discrete ($L=\mathbb{Z}^d$) grid.
 
 
 \item $S$ is a finite \emph{set of states}. In GoL, $S=\{0,1\}=$ $\{$unpopulated (\emph{dead}), populated (\emph{alive})$\}$ is the set of each cell's possible states.
 
 \item $N({\bf x})=\{ {\bf x}+{\bf n} : {\bf x},{\bf n} \in \mathbb{R}^d \}$ is the \emph{neighborhood} of the site x $\in L$, a finite ordered subset of $L$. In GoL, ${d=2}$, 
 
\begin{itemize}
\item[$\diamond$] ${\bf x}=(x,y)$ $\in\mathbb{R}^{d=2}$
\item[$\diamond$] $n=\{-1,0,1\}^{d=2}$. The notation $\{-1,0,1\}^{2}$ means the set of two-dimensional vectors with each component being either -1, 0 or 1. \cite[p.~16, l.~23-24]{Nielsen}
\item[$\diamond$] $N({\bf x})$ is the 8-site Moore neighborhood in the Chebyshev $L_\infty$ or \emph{chessboard} metric. The points at a Chebyshev distance of ${\bf n}=$(0,0) from the \emph{cell}-site ${\bf x}=(x,y)$ are the site  ${\bf x}$ itself. Any other combination of $n=\{-1,0,1\}^{2}$ represents one of the 8 Moore neighbors.
\end{itemize}
 
   

 \item $f:\,S^{|N|}\rightarrow S$ is the deterministic \emph{local transition rule} or function, space- and time-homogeneous.
 % Space-homogeneous : The transition function / update table is the same for each cell.
% Time-homogeneous : The transition function / update table is time-independent. 
  In GoL, $f:\,S^{8+1}\rightarrow S$. The domain is $S^{8+1}$  due to the 9 possible combinations allowed in the Moore neighborhood: 8 neighbors + the reference cell itself. Every site's state, which forms the output of the map $f$ or codomain $S$, is updated \emph{simultaneously} according to the following local rule, previously described in the Introduction (\ref{Categorization}, l. 9-14):
 
\[
  {C}(t+\Delta t,{\bf x})=
  \begin{cases}
 1 & \text{if ${C}(t,{\bf x})=1$ \& ${S}(t,{\bf x})\in\{2,3\}$ (\emph{survival})} \\
 1 & \text{if ${C}(t,{\bf x})=0$ \& ${S}(t,{\bf x})\in\{3\}$ (\emph{reproduction})}\\
 0 & \text{otherwise (\emph{death} by underpopulation/overpopulation)}
  \end{cases}
\]
 \end{itemize}
where we define the mapping $C(t,{\bf x}):\,L\rightarrow S$ as the \emph{Configuration} or \emph{pattern} (i.e., the collection of $S$ states over the whole $L$ grid) of site x $\in L$ at time or generation t $\in T$. In GoL, ${\bf x}=(x,y)$, $L=\mathbb{Z}^2$ and $S=\{0,1\}$, so, $C(t,(x,y)):\,(\mathbb{Z}^2)\rightarrow \{0,1\}$. \cite[p.~136]{Adamatzky}\\

Now we will materialize GoL, the abstractly described CAL example:

\vspace{0.5cm}

\subsection{Implementation of Game of Life}

\subsubsection{Code}

\href{https://www.gnu.org/software/octave/}{\emph{GNU Octave}} is a convenient environment for deploying GoL, since its grid or universe is a matrix. Details are relegated to Appendix \ref{appendix_A_code}.

\subsubsection{Results}
Let us introduce some illustrative results obtained by the corresponding \emph{GNU Octave} code shown in Appendix \ref{appendix_A_code}:

\begin{figure}[H] 
	\centering
	\includegraphics[scale=0.2]{Images/Glider.png}
	\caption{\emph{Glider}. The first 15 generations are displayed. Notice the implementation of periodic boundary conditions (PBCs).}
	  \label{fig:Glider}
\end{figure}

\begin{figure}[H] 
	\centering
	\includegraphics[scale=0.2]{Images/Tetromino1.png}
	\caption{The first 6 generations of an example of the so-called \emph{Tetromino} (shape formed by 4 connected populated (black) cells) \cite[p.~4, l.~9-10]{Gardner}. As it can be observed, it becomes an stable figure or \emph{still-life} after the third generation.}
	  \label{fig:Tetromino1}
\end{figure}

\begin{figure}[H] 
	\centering
	\includegraphics[scale=0.2]{Images/Tetromino2.png}
	\caption{The first 14 generations of another example of a \emph{Tetromino} \cite[p.~4, l.~10-11]{Gardner}. It becomes 4 isolated period-2 figures known as \emph{traffic lights} after the $9^\textrm{th}$ generation.}
	  \label{fig:Tetromino2}
\end{figure}

\vspace{1cm}
Continuing with our gradual transition from CAL to QAL, we will deploy some quantum mechanical characteristics to GoL:

\subsection{Transition from Classical to Quantum Artificial Life} \label{Semi-quantum_GoL}

We will give a semiquantum version of GoL. We will use the Schrödinger picture, where quantum states --the ensemble of cells in the grid, here-- evolve in time according to time-independent operators acting on it. This operators would be, in our case, the GoL transition rules, which are, as mentioned,  time-homogeneous (Section \ref{Mathematical definition CA}). Nevertheless, in practice, two problems arise: some of this operators won't be unitary and synchronous
update of all cells cannot be carried in current QCs.

\subsubsection{Probabilistic picture of measurements} \label{probabilistic_picture}

Furthering with GoL, quantum mechanical features can be implemented, such as the \uline{probability} of measuring the system in a particular state, Eq. (\ref{Pr._alive}-\ref{Pr._dead}). Quantum mechanical algorithms work with probability distributions over various states. They come into play due to the impossibility of making definite predictions. 

Suppose that we consider GoL a finite quantum mechanical system that can be exactly imitated by a physical register that at each point in space-time has only two possible base states: either occupied (alive or, e.g., spin $1/2$ up), or unoccupied (dead or, e.g., spin $1/2$ down) \cite[p.~475, l.~27-31]{Feynman}. For this interpretation, the state of each cell is represented in the following manner: \cite[p.~1, Eq.~(1)]{Flitney}

\begin{equation} \label{Eq.1}
\ket{\psi}=a\ket{1}+b\ket{0}\textrm{,}
\end{equation}

where $\ket{1}\equiv\ket{\textrm{alive}}$ and $\ket{0}\equiv\ket{\textrm{dead}}$ are the \emph{computational} or standard \emph{basis states} ($\hat{Z}$) \cite[p.~13, l.~23]{Nielsen}, subject to the normalization condition $|a|^2+|b|^2=1$. $a,b\in\mathbb{C}$ are the complex vectorial \emph{amplitudes} in each state. In the $\{\ket{1},\ket{0}\}$ basis, $\ket{\psi}=a\ket{1}+b\ket{0}\doteq \begin{pmatrix} a \\ b \end{pmatrix}$.\\

Thus, the \uline{probability} \cite[p.~24, Eq.~(1.4.4)]{Sakurai} of measuring the cell as \emph{alive} or \emph{dead} is, respectively,

\begin{equation} \label{Pr._alive}
\textrm{Pr.}_{\ket{\psi}} (\ket{1})=|\braket{1|\psi}|^2\doteq |\begin{pmatrix} 1&0 \end{pmatrix}\begin{pmatrix} a \\ b \end{pmatrix}|^2 = |\begin{pmatrix} a \\ 0 \end{pmatrix}|^2 = \begin{pmatrix} a^*&0 \end{pmatrix}\begin{pmatrix} a \\ 0 \end{pmatrix} = a^*a=|a|^2\textrm{,}
\end{equation}
\begin{equation} \label{Pr._dead}
\textrm{Pr.}_{\ket{\psi}} (\ket{0})=|\braket{0|\psi}|^2\doteq |\begin{pmatrix} 0&1 \end{pmatrix}\begin{pmatrix} a \\ b \end{pmatrix}|^2 = |\begin{pmatrix} 0 \\ b \end{pmatrix}|^2 = \begin{pmatrix} 0&b^* \end{pmatrix}\begin{pmatrix} 0 \\ b \end{pmatrix} = b^*b=|b|^2\textrm{,}
\end{equation}

and, as usual, due to the normalization of the wave function  the total probability is one \cite[p.~107, Eq.~(3.48)]{Griffiths}: $\textrm{Pr.}_{\textrm{tot}}=\textrm{Pr.}_{\ket{\psi}} (\ket{1})+\textrm{Pr.}_{\ket{\psi}} (\ket{0}) = |a|^2+|b|^2=1$, where the last equality $|a|^2+|b|^2=1$ follows from the normalization condition of Eq. (\ref{Eq.1}). See a more complete study, via the \emph{density operator} ($\hat{\rho}$) approach, for Eq. (\ref{Pr._alive}-\ref{Pr._dead}) in Appendix \ref{density_operator_approach}.


\subsubsection{Quantum implementation of GoL rules \normalfont{(without phase difference $e^{i\phi}$)}}

We apply the GoL rules by means of \uline{linear combination}s of the following birth ($\hat{B}$), death ($\hat{D}$) and survival ($\hat{S}$) operators: \cite[p.~2, Eq.~(3)]{Flitney}
\begin{equation} \label{Eq.2}
\hat{B}\ket{\psi}=\ket{1},\, \hat{D}\ket{\psi}=\ket{0},\quad\textrm{and}\quad \hat{S}\ket{\psi}=\ket{\psi}\,\textrm{,}
\end{equation}
where, in the $\{\ket{1},\ket{0}\}$ basis,

\begin{equation} \label{Eq.3}
\hat{B}\doteq \frac{1}{a+b}\begin{pmatrix} 1 & 1 \\ 0 & 0 \end{pmatrix},\,\,\,\hat{D}\doteq   \frac{1}{a+b}\begin{pmatrix} 0 & 0 \\ 1 & 1 \end{pmatrix},\,\,\,\hat{S}\doteq  \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}=\hat{1}_2\,\textrm{.}
\end{equation}

\vspace{0.3cm}

Hence, $\hat{B}\ket{\psi}\doteq \frac{1}{a+b}\begin{pmatrix} 1 & 1 \\ 0 & 0 \end{pmatrix}\begin{pmatrix} a \\ b \end{pmatrix}=\frac{1}{a+b}\begin{pmatrix} a+b \\ 0 \end{pmatrix}=\begin{pmatrix} 1 \\ 0 \end{pmatrix}\doteq\ket{1}$,$\,\,$ $\hat{D}\ket{\psi}\doteq \frac{1}{a+b}\begin{pmatrix} 0 & 0 \\ 1 & 1 \end{pmatrix}\begin{pmatrix} a \\ b \end{pmatrix}=\frac{1}{a+b}\begin{pmatrix} 0 \\ a+b \end{pmatrix}=\begin{pmatrix} 0 \\ 1 \end{pmatrix}\doteq\ket{0}$, and $\hat{S}\ket{\psi}\doteq \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}\begin{pmatrix} a \\ b \end{pmatrix}=\begin{pmatrix} a \\ b \end{pmatrix}\doteq\ket{\psi}$. Thus, Eq.(\ref{Eq.2}) is fulfilled.\\

\vspace{0.3cm}

In addition, the matrix representation of $\hat{S}$ is diagonal when $\ket{1}$ and $\ket{0}$ are used as the base kets. Then, we can infer that these are the eigenkets 
\footnote{In $3$-dimensional real vector space $\mathbb{R}^3$, eigenvectors can be seen as vectors that are transformed into scalar multiples of themselves by the $\theta$ angle rotation about some axis, applied by an operator $\hat{U}$. Exempli gratia, vectors that lie \emph{along} the rotation axis do not change at all ($\hat{U}\ket{\psi}=\ket{\psi}$, eigenvalue$=1$), and, for $\theta=\pi$, if they lie in the \emph{equatorial} plane of the rotation axis, $\hat{U}\ket{\psi}=-1\ket{\psi}$ (eigenvalue$=-1$).}
 of $\hat{S}\,\,\,$ \cite[p.~22, l.~3-5 \& p.~36, l.~5-7]{Sakurai}. These two eigenfunctions share the same eigenvalue ($S=1$, degeneration $g=2$), so any linear combination of them ($\ket{\psi}$ defined in Eq. (\ref{Eq.1}), for instance) is itself an eigenfunction, with the same eigenvalue (obvious from $\hat{S}\ket{\psi}=1\ket{\psi}$, Eq.(\ref{Eq.2})). \cite[p.~102, l.~6-8]{Griffiths} \\

$\hat{B}$ and $\hat{D}$ are not unitary since their Hermitian (conjugate transpose) is not equal to their inverse, or, equivalently, \cite[p.~36, Eq.~(1.5.2)]{Sakurai}


\begin{equation}
\hat{B}\hat{B}^\dagger\doteq \frac{1}{a+b}\begin{pmatrix} 1 & 1 \\ 0 & 0 \end{pmatrix} \frac{1}{a^*+b^*}\begin{pmatrix} 1 & 1 \\ 0 & 0 \end{pmatrix}^T =  \frac{1}{|a+b|^2}  \begin{pmatrix} 1 & 1 \\ 0 & 0 \end{pmatrix}  \begin{pmatrix} 1 & 0 \\ 1 & 0 \end{pmatrix} = \frac{1}{|a+b|^2}  \begin{pmatrix} 2 & 0 \\ 0 & 0 \end{pmatrix} \neq \hat{1}_2\,\textrm{,}
\end{equation}
\begin{equation}
\hat{D}\hat{D}^\dagger\doteq\frac{1}{a+b}\begin{pmatrix} 0 & 0 \\ 1 & 1 \end{pmatrix} \frac{1}{a^*+b^*}\begin{pmatrix} 0 & 0 \\ 1 & 1 \end{pmatrix}^T =  \frac{1}{|a+b|^2}  \begin{pmatrix} 0 & 0 \\ 1 & 1 \end{pmatrix}  \begin{pmatrix} 0 & 1 \\ 0 & 1 \end{pmatrix} = \frac{1}{|a+b|^2}  \begin{pmatrix} 0 & 0 \\ 0 & 2 \end{pmatrix} \neq \hat{1}_2\,\textrm{.}
\end{equation}
A quantum gate is feasible if and only if the corresponding matrix is unitary, so $\hat{B}$ and $\hat{D}$ cannot be empirically deployed. However, this section is valuable for a better comprehension of the ensuing parts of our work.

\vspace{0.5cm}

Obviously, $\hat{S}$ is unitary \cite[p.~36, Eq.~(1.5.2)]{Sakurai}: in the $\{\ket{1},\ket{0}\}$ basis, $\hat{S}=\hat{1}_2=\hat{S}^{-1}=\hat{S}^\dagger$, so $\hat{S}\hat{S}^\dagger=\hat{S}^\dagger\hat{S}=1$. Furthermore, $\hat{S}$ is an Hermitian operator ($\hat{S}=\hat{S}^\dagger\equiv(\hat{S}^*)^T\,\,\,$ \cite[p.~15, Eq.~(1.2.25)]{Sakurai}, where the \emph{Hermitian adjoint} is obtained by transposing and complex conjugating the operator \cite[p.~18, l.~28]{Nielsen}), so its eigenvalues ($S=1$, as we have already seen) are real ($S\in\mathbb{R}$). Notice that, since they do not represent observables, they are just used to apply de GoL rules, the birth ($\hat{B}$), death ($\hat{D}$) and survival ($\hat{S}$) operators do not have to be Hermitian \cite[p.~97, Eq.~(3.18)]{Griffiths}.\\

As mentioned, we apply the rules of GoL through \uline{linear combination}s of the birth ($\hat{B}$), death ($\hat{D}$) and survival ($\hat{S}$) operators defined in Eq. (\ref{Eq.3}). These linear combinations --which will also be operators, and we will call them $\hat{G}$, from \emph{Generation}-- depend on the value of the sum of the $a$ coefficients in the $\ket{\psi}$ (Eq. (\ref{Eq.1})) states corresponding to each of the 8 Moore neighbors. If we define this sum as $a_{\textrm{Moore}}\equiv a_{\textrm{M}}\equiv\sum_{i=1}^8 a_i$, $\,\,\,$ \cite[p.~2, Eq.~(7)]{Flitney}

\begin{equation} \label{G_operator}
  \hat{G}\propto
  \begin{cases}
 \hat{D}         & \text{if $0\leq a_{\textrm{M}}\leq 1$} \\
 (2-a_{\textrm{M}})\hat{D}+(a_{\textrm{M}}-1)\hat{S}         & \text{if $1< a_{\textrm{M}}\leq 2$} \\
 (3-a_{\textrm{M}})\hat{S}+(a_{\textrm{M}}-2)\hat{B}         & \text{if $2< a_{\textrm{M}}\leq 3$} \\
 (4-a_{\textrm{M}})\hat{B}+(a_{\textrm{M}}-3)\hat{D}         & \text{if $3< a_{\textrm{M}}\leq 4$} \\
 \hat{D}         & \text{if $a_{\textrm{M}}> 4$}
  \end{cases}
\end{equation}

\vspace{0.5cm}

Note the continuity of $\hat{G}$ on the boundaries, for $a_{\textrm{M}}=1,2,3,4$,
$$\hat{G}(a_{\textrm{M}^-}=1)=\hat{D}\,\,\,=\,\,\,\hat{G}(a_{\textrm{M}^+}=1)=(2-1)\hat{D}+(1-1)\hat{S}=\hat{D}\,\textrm{,}$$
$$\hat{G}(a_{\textrm{M}^-}=2)=(2-2)\hat{D}+(2-1)\hat{S}=\hat{S}\,\,\,=\,\,\,\hat{G}(a_{\textrm{M}^+}=2)=(3-2)\hat{S}+(2-2)\hat{B}=\hat{S}\,\textrm{,}$$
$$\hat{G}(a_{\textrm{M}^-}=3)=(3-3)\hat{S}+(3-2)\hat{B}=\hat{B}\,\,\,=\,\,\,\hat{G}(a_{\textrm{M}^+}=3)=(4-3)\hat{B}+(3-3)\hat{D}=\hat{B}\,\textrm{,}\quad\textrm{and}$$
$$\hat{G}(a_{\textrm{M}^-}=4)=(4-4)\hat{S}+(4-3)\hat{D}=\hat{D}\,\,\,=\,\,\,\hat{G}(a_{\textrm{M}^+}=4)=\hat{D}\,\textrm{.}$$

In general, for $a_{\textrm{M}}\in\mathbb{N}$, $\hat{G}$ is equal to $\hat{B}$, $\hat{D}$ or $\hat{S}$ (only one of these 3 operators, not a linear combination of 2 of them). Then, the rules of the classical GoL are recovered!\\

In the new \emph{generation} or time step, the state of the cell is

\begin{equation} \label{psi_prime}
\ket{\psi^\prime}=a^\prime\ket{1}+b^\prime\ket{0}=\hat{G}\ket{\psi}\doteq \begin{pmatrix} a^\prime \\ b^\prime \end{pmatrix}=\hat{G}\begin{pmatrix} a \\ b \end{pmatrix}\,\textrm{,}
\end{equation}
in the $\{\ket{1},\ket{0}\}$ basis, where the new state $\ket{\psi^\prime}$ requires renormalization so that $|a^\prime|^2+|b^\prime|^2=1$; that is, after applying $\hat{B}$, $\hat{D}$, $\hat{S}$ or some mixture of them, the probabilities of being dead or live must still sum to unity. Because of this \emph{renormalization}, overall factors on Eq. (\ref{G_operator}) have no effect \cite[p.~3, Eq.~(10)]{Flitney}, but relative constants, of course, would matter.\\

\subsubsection{A more quantum-like implementation of GoL rules \normalfont{(with phase difference $e^{i\phi}$)}} \label{GoL quantum with phase}

We can additionally introduce a phase difference $e^{i\phi}$ : $\phi\in\mathbb{R}^+$, with the aim of achieving a different behavior from the classical GoL and allow \emph{interference} --the reinforcement or cancellation between states of different relative phases--, which is a fundamental quantum property, along with the uncertainty or probabilistic picture introduced in Section \ref{probabilistic_picture}. The \emph{phase} has no classical analog and it comes about in quantum mechanics because amplitudes are complex numbers \cite[p.~2, l.~65-68]{Grover}.

Similar to the consequences of renormalizing Eq. (\ref{psi_prime}), while relative phase constants (in a superposition) are important, the \emph{global} phase factor of the wave function is physically irrelevant; in this case, however, because it cancels out whenever we calculate a measurable quantity \cite[p.~39, l.~14-16]{Griffiths} \cite[p.~15, Eq.~(1.3) \& p.~93, l.~10-17]{Nielsen}, rather than by renormalization. In other words, the \emph{overall} phase of a quantum state is not measurable, has no quantum physical significance: $\ket{\psi}$ is the same as $e^{i\phi}\ket{\psi}$ and both yield the same density matrix $\hat{\rho}$.\\

Now, instead of Eq. (\ref{Eq.2}), we have $\,\,\,$ \cite[p.~3]{Flitney}
\begin{equation} \label{2.13} 
\hat{B}\ket{\psi}=\frac{a+be^{i\phi}}{\sqrt[]{|a+be^{i\phi}|^2}}\ket{1},\, \hat{D}\ket{\psi}=\frac{ae^{i\phi}+b}{\sqrt[]{|ae^{i\phi}+b|^2}}\ket{0},\, \hat{S}\ket{\psi}=\ket{\psi}\,\textrm{,}  
\end{equation}

where
\begin{itemize}
\item $|a+be^{i\phi}|^2=(a+be^{i\phi})(a^*+b^*e^{-i\phi})=|a|^2+ab^*e^{-i\phi}+a^*be^{i\phi}+|b|^2=|a|^2+|b|^2+2Re(a^*be^{i\phi})=|a|^2+|b|^2+2Re(a^*b)\cos\phi$
\item $|ae^{i\phi}+b|^2=(ae^{i\phi}+b)(a^*e^{-i\phi}+b^*)=|a|^2+ab^*e^{i\phi}+a^*be^{-i\phi}+|b|^2=|a|^2+|b|^2+2Re(ab^*e^{i\phi})=|a|^2+|b|^2+2Re(ab^*)\cos\phi$
\end{itemize}

Therefore, Eq. (\ref{2.13}) becomes
\begin{equation} 
\hat{B}\ket{\psi}=\frac{a+be^{i\phi}}{\sqrt[]{|a|^2+|b|^2+2Re(a^*b)\cos\phi}}\ket{1},\, \hat{D}\ket{\psi}=\frac{ae^{i\phi}+b}{\sqrt[]{|a|^2+|b|^2+2Re(ab^*)\cos\phi}}\ket{0},\, \hat{S}\ket{\psi}=\ket{\psi}  \,\textrm{,}
\end{equation}


or, equivalently: $\hat{B}\ket{1}=\ket{1}$, $\hat{B}\ket{0}=e^{i\phi}\ket{1}$,  $\hat{D}\ket{1}=e^{i\phi}\ket{0}$, $\hat{D}\ket{0}=\ket{0}$ and $\hat{S}\ket{\psi}=\ket{\psi}$.\\

\noindent
{\color{red} \rule{\linewidth}{0.5mm} }

Instead of $a_{\textrm{M}}\equiv\sum_{i=1}^8 a_i$, we will use $a_{\textrm{M}}\equiv\sum_{i=1}^8 a_i\,e^{i\phi}$ $\,\,\,$ \cite[p.~3, Eq.~(12)]{Flitney}. Simply put, we want the computational basis state ($\ket{0}$ or $\ket{1}$) to have the same phase difference ($e^{i\phi}$) as the sum of the $a$ coefficients of the surrounding nearest 8 cells ($a_{\textrm{M}}$), but just if it has changed its computational basis state ($\ket{0}\leftrightarrow\ket{1}$ in the last time step; in other words, if the current cell is alive (dead) and in the previous generation was dead (alive).\\

Eq. (\ref{G_operator}) is applied in the same way as before. The phase ($e^{i\phi}$) in $a_{\textrm{M}}\equiv\sum_{i=1}^8 a_i\,e^{i\phi}$ allows for interference effects; for instance, a cell with $a_{\textrm{i}}=e^{\pm i(\phi=\pi)}=-1$ still has a unit probability of being measured in the live state but its effect on the sum will cancel (\emph{interference}) that of a cell with $a_{\textrm{i}}=e^{i(\phi=0)}=1$.

\noindent
{\color{red} \rule{\linewidth}{0.5mm} }



\newpage

\section{Quantum Artificial Life}

In the QAL model proposed by Ref. \cite{QAL_IBM}, \cite{AL_in_QT} and \cite{Bio_Cloning}, \emph{individuals} or quantum artificial living entities are composed by two \emph{qubit}s (Fig. \ref{fig:Self_replication}): one of the qubits represents its \emph{genotype}, genetic information that is transmitted throughout generations, and, the other, its \emph{phenotype} \cite[p.~2, l.~9-12]{QAL_IBM}\cite[p.~1, l.~35-37]{AL_in_QT}, the set of observable characteristics of the genotype resulting from the individual's interaction with the environment and other living units. For more information about the \emph{qubit} approach, see Appendix \ref{qubit_approach}.

This model corresponds to the research field of QAL because individuals are encoded in the mentioned two-qubit quantum states and quantum operations are used in order to implement the following natural selection processes:
\begin{itemize}
\item (Section \ref{age_and_predatorness}) Finite lifetime, preservation of the genotype information in time and trophic roles. 
\item (Section \ref{self-replication}) Self replication (as asexual \emph{reproduction} mechanism) that maintains genotype information partially from generation to generation. Possible presence of \emph{mutation}s due to experimental setup errors.
\item (Section \ref{environment}) Aging, via phenotype degradation by the environment.
\item (Section \ref{inter-individual}) Inter-individual interaction.
\end{itemize}

\subsection{Finite lifetime ($\braket{\hat{\sigma}_z}_p(t)$), time constant genotype and relative "predatorness" ($\braket{\hat{\sigma}_z}_g$)} \label{age_and_predatorness}

Finite lifetime, a genotype constant in time and relative \emph{predatorness} are the first three biological features we will introduce.

In the model described in Ref. \cite{QAL_IBM}, the expectation value of the Pauli matrix $\hat{\sigma}_3\equiv\hat{\sigma}_z$ $\,$ \cite[p.~169, Eq.~(3.2.32c)]{Sakurai} in the phenotype ($p$) qubit, $\braket{\hat{\sigma}_z}_p(t)$, measures the age (spent lifetime) of the artificial living units, where $t$ is the elapsed time from the birth \cite[p.~3, l.~10]{AL_in_QT}. Nota bene, $\braket{\hat{\sigma}_z}_p=\braket{\hat{\sigma}_z}_p(t)$, because it changes \cite[p.~2, l.~13-14]{QAL_IBM} due to the interaction performed during time $t$ with other individuals and the environment \footnote{Precisely, the phenotype qubit degrades towards $\hat{\rho}_{\textrm{Ancillary}}\equiv\hat{\rho}_A=\ket{0}\bra{0}$. See Section \ref{environment}.}, as it occurs in nature!

A different observable could have been selected, but we have chosen $\hat{\sigma}_z$ just to make calculations easier, because its matrix representation is diagonal in $\{\ket{0},\ket{1}\}$, the basis given by the steady state ($\hat{\rho}_A=\ket{0}\bra{0}$) of the Lindblad master equation we use to simulate the effect of the environment or bath (Section \ref{environment}).

The \emph{finite lifetime}, characteristic of all living beings, is mimicked by the time elapsed in the evolution of the phenotype from its creation to the vicinity of an asymptotic value; here, $1-\epsilon$, for fixed $\epsilon$. In other words, \cite[p.~3, l.~11-12]{AL_in_QT} the death age $t_d$ is achieved when $\braket{\hat{\sigma}_z}_p(t=t_d)=1-\epsilon$, so an individual is alive $\leftrightarrow$ $\braket{\hat{\sigma}_z}_p(t)<1-\epsilon$. Here, then, $t_d$ can be physically regarded as the decoherence time (Section \ref{environment}). \\

On the other hand, $\braket{\hat{\sigma}_z}_g$ --the expectation value of $\hat{\sigma}_3\equiv\hat{\sigma}_z$ in the genotype ($g$) qubit-- determines, in addition to its lifetime (implicitly, because $\braket{\hat{\sigma}_z}_p(t_0)=\braket{\hat{\sigma}_z}_g$, from Eq. (\ref{preservation_condition})), its role (predator or prey) in the tropic chain \cite[p.~1, l.~39]{AL_in_QT}. Furthermore, contrary to the phenotype, the genotype --we mean, the expectation value of $\hat{\sigma}_z$ in the genotype subspace-- remains unchanged in time under the influence of all sort of interactions --$\braket{\hat{\sigma}_z}_g\neq\braket{\hat{\sigma}_z}_g(t)$--, again following the logic of nature!

 Predators need to feed from preys because their $\braket{\hat{\sigma}_z}_p$ is bigger, closer to the death value $1-\epsilon$. In nature, predators or preys do not change their trophic role during life; id est, the trophic role, as mentioned, is determined by the genotype. Let us suppose that we have $\braket{\hat{\sigma}_z}_1{_{g}}$ $>$ $\braket{\hat{\sigma}_z}_2{_{g}}$. As logic dictates, individual $1$ will act as a predator, because, we know that $\braket{\hat{\sigma}_z}_1{_{g}}$ $>$ $\braket{\hat{\sigma}_z}_2{_{g}}$ $\,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{(\ref{preservation_condition})}}}}{\rightarrow}}}\,\,$ $\braket{\hat{\sigma}_z}_1{_{p}}(t_0)$ $>$ $\braket{\hat{\sigma}_z}_2{_{p}}(t_0)$, individual $1$ is closer to death, even from its birth time $t_0$. So, due to the fact that $\braket{\hat{\sigma}_z}_{p}$ increases with time, individual $1$ has to feed from $2$ in order to survive: individual $1$ is the predator, if you are individual $2$, ... fly, you fools! Obviously, here, \emph{predatorness} is relative (it depends on the two individuals that interact), which emulates the great diversity of predator species in nature! 
  
\subsection{Reproduction: Self-replication} \label{self-replication}

Besides the three biological characteristics described in Section \ref{age_and_predatorness}, reproduction is also an ability common in all alive ($\braket{\hat{\sigma}_z}_p(t)<1-\epsilon$, in our formalism) organisms. Here, \emph{self-replication} is chosen as a reproduction mechanism $\,$\cite[p.~2, l.~16-23]{QAL_IBM}. It is performed following two steps based on \emph{partial quantum cloning} (Appendix \ref{partial_quantum_cloning}), copying the expectation value of a chosen observable ($\hat{\sigma}_z$, here, for reasons presented in Section \ref{age_and_predatorness} (l. 8-10)) into a blank or ancillary state ($\hat{\rho}_A=\ket{0}\bra{0}$) $\,$ \cite[p.~2, l.~16-17]{QAL_IBM} that the environment or bath provides via the closure of the trophic cycle (Section \ref{environment} (l. 13-17)). This partial quantum cloning operation \emph{entangles}\footnote{Due to its relevance, \emph{entanglement} is briefly introduced in Appendix \ref{Entanglement}.} the genotype or the penotype with the ancillary state \cite[p.~2, l.~17-18]{QAL_IBM}, and this entanglement is spread across generations.

Live begins from an arbitrary initial genotype $\hat{\rho}_{g_0}$. It will be taken as the genotype of the $0^{\textrm{th}}$ generation individual after the first {\color{orange}phenotype creation}. Here, from the genotype $\hat{\rho}_{g_0}$, the phenotype $\hat{\rho}_{p_0}$ is created, cloning $\braket{\hat{\sigma}_z}_{g_0}$ to a blank state. With this, the $0^{\textrm{th}}$ generation living unit is born.

Then, the $0^{\textrm{th}}$ individual and the forthcoming generations breed via self-replication. Self-replication is essentially the same mechanism used to create the $0^{\textrm{th}}$ individual, with the exception that in the formation of the $0^{\textrm{th}}$ individual, we used a given genotype. Now, however, we have to create it first. First, we create the new individual's genotype from the progenitor's genotype, and then the phenotype, from the new genotype. Thus, as mentioned, two events form the self-replication process. For example, let us create the $1^\textrm{st}$ generation individual:      $\,\,\,$ (Fig. \ref{fig:Self_replication})

%the self-replication consists in duplicating the expectation value of σz in the genotype, in a blank state that will be transformed in the genotype of the individual in the next generation

\begin{itemize}
\item {\color{purple}Genotype creation} (\ref{genotype_replication}): From the $0^{\textrm{th}}$ individual's genotype $\hat{\rho}_{g_0}$, the genotype of a $1^\textrm{st}$ individual $\hat{\rho}_{g_1}$ is created, duplicating $\braket{\hat{\sigma}_z}$ to a blank state $\hat{\rho}_A=\ket{0}\bra{0}$. $\,$  \cite[p.~2, l.~19-20]{QAL_IBM}

\item {\color{orange}Phenotype creation} (\ref{phenotype_creation}): From the new genotype $\hat{\rho}_{g_1}$, the phenotype of the same new individual $\hat{\rho}_{p_1}$ is created, copying again $\braket{\hat{\sigma}_z}$ to a blank state. $\,$ \cite[p.~2, l.~20-22]{QAL_IBM}
\end{itemize}

 \begin{figure}[H] 
	\centering
	\includegraphics[scale=0.20]{Images/Self_replication.png}
	\caption{(Left) Creation of the $0^\textrm{th}$ individual via {\color{orange}phenotype creation} from $\hat{\rho}_{g_0}$. (Right) Creation of the $1^\textrm{st}$ individual via \emph{self-replication} (\ref{self-replication}): {\color{purple}genotype creation} (\ref{genotype_replication}) from $\hat{\rho}_{g_0}$ $+$ {\color{orange}phenotype creation} (\ref{phenotype_creation}) from $\hat{\rho}_{g_1}$.}
 \label{fig:Self_replication}
\end{figure}


% Koloreak:
% https://osl.ugr.es/CTAN/macros/latex/contrib/xcolor/xcolor.pdf   (page 38)
%$${\color{ForestGreen}\hat{\rho}_{p_0}}$$
%$${\color{blue}\hat{\rho}_{1}}$$

Partial quantum cloning, or duplicating a chosen set of observables ($\hat{\sigma_z}$, here), will be effectuated via the operator proposed in Ref. \cite[p.~2, Eq.~(1b) \& (3c)]{AL_in_QT}, \cite[p.~2, Eq.~(7)]{Bio_Cloning} and \cite[p.~2, l.~19]{Ferraro} (Appendix \ref{cloning_of_observables}):
\begin{equation} \label{rho_old_to_new}
\hat{\rho}_{\textrm{new}} = \hat{U}\,(\hat{\rho}_{\textrm{old}}\otimes\hat{\rho}_A)\,\hat{U}^\dagger\,\textrm{.}
\end{equation} 
The unitary transformation $\hat{U}$ acts on an $n$-dimension initial quantum state $\hat{\rho}_{\textrm{old}}$. $\hat{U}$ copies the expectation value of a chosen set of observables ($\hat{\sigma}_z$, here) from $\hat{\rho}_{\textrm{old}}$ to a blank state $\hat{\rho}_A$, in order to create $\hat{\rho}_{\textrm{new}}$.
In our model, $n=\dim \hat{\rho}_{\textrm{old}}= \dim \hat{\rho}_{\textrm{new}}=\dim \mathcal{H}_{g_i}=\dim\mathcal{H}_{p_i}=2$, because qubits are $2$-level quantum systems. If the chosen observable is $\hat{\sigma}_z$, as in our case, $\hat{U}=\hat{U}_{C_{NOT}}$ (Appendix \ref{why_U_CNOT_proof}). 

$\hat{U}\numeq{\textrm{\ref{why_U_CNOT}}}\hat{U}_{C_{NOT}}$ in Eq. (\ref{rho_old_to_new}) is the matrix representation of the \emph{controlled}-NOT or CNOT gate. See Appendix \ref{U_CNOT_theory_Appendix} for more information about this quantum logic gate.

Thus, from a precursor qubit $\hat{\rho}_{\textrm{old}}$, a new qubit $\hat{\rho}_{\textrm{new}}$ is created. For instance, $\hat{\rho}_{\textrm{old}}=\hat{\rho}_{g_0}$ and $\hat{\rho}_{\textrm{new}}=\hat{\rho}_{g_1}$ [$\hat{\rho}_{\textrm{old}}=\hat{\rho}_{g_1}$ and $\hat{\rho}_{\textrm{new}}=\hat{\rho}_{p_1}$], for the {\color{purple}genotype creation} [{\color{orange}phenotype creation}] of the $1^{\textrm{th}}$ individual in Fig. \ref{fig:Self_replication}. 

Moreover, the first {\color{orange}phenotype creation} and the first {\color{purple}genotype creation} --the creation of $\hat{\rho}_{p_0}$ from $\hat{\rho}_{g_0}$ and, $\hat{\rho}_{g_1}$ from $\hat{\rho}_{g_0}$, respectively-- in Fig. \ref{fig:Self_replication} are the equivalent to Fig. 1 in Ref. \cite[p.~2]{Bio_Cloning}. Hence, the following conservation condition ought to be imposed for the both output qubits ($\hat{\rho}_{p_0}$ and $\hat{\rho}_{g_1}$): $\,\,\,$ \cite[p.~2, Eq.~(1a)]{AL_in_QT} \cite[p.~1, Eq.~(1)]{Bio_Cloning} \cite[p.~2, Eq.~(1)]{Ferraro}
\begin{equation} \label{preservation_condition}
\braket{\hat{\sigma}_z}_{\hat{\rho}_0} \numeq{{\color{purple}1}} \braket{ \left(\hat{\sigma}_z\right)_{g_1}\otimes \hat{1}_{p_0}}_{\hat{\rho}_1}\equiv \braket{\hat{\sigma}_z}_{g_1} \numeq{{\color{orange}2}} \braket{\hat{1}_{g_1}\otimes\left(\hat{\sigma}_z\right)_{p_0}}_{\hat{\rho}_1}\equiv\braket{\hat{\sigma}_z}_{p_0}(t_0)\,\textrm{,}
\end{equation}
where operators' subscripts indicate the qubits ($g_1$ or $p_0$) they act on. We have chosen the left (right) operator to act on $g_1$ ($p_0$) because of the result in Eq. (\ref{sigma_p0(t)}). You can think of the left (right) operator as acting on the qubit located  in the top right (bottom left) part of Fig. \ref{fig:Self_replication}.

Furthermore, $\hat{\rho}_0\equiv\hat{\rho}_{g_0}$ and 
\begin{equation} \label{rho_p0_and_rho_g1}
\hat{\rho}_1\equiv \hat{\rho}_{p_0}(t_0)=\hat{\rho}_{g_1}\numeq{\textrm{\ref{rho_old_to_new}}} \hat{U}\,(\hat{\rho}_{g_0}\otimes\hat{\rho}_A)\,\hat{U}^\dagger
\end{equation}
Moreover, $t_0$ is the moment of the replication, when the phenotype qubit has not changed yet, due to interactions.

Thus, a chosen set of observables --in this case, $\hat{\sigma}_z$-- is propagated, via partial quantum cloning, Eq. (\ref{rho_old_to_new}), from an arbitrary initial genotype $\hat{\rho}_{\textrm{old}}=\hat{\rho}_{0}\equiv\hat{\rho}_{g_0}$, Eq. (\ref{AL_in_QT_Eq_3a}), to the following generation's genotype $\hat{\rho}_{g_1}$--in equality $({\color{purple}1})$--, and to the same generation's phenotype $\hat{\rho}_{p_0}$ --in equality $({\color{orange}2})$--. That is, equality $({\color{purple}1})$ [$({\color{orange}2})$] corresponds to the first {\color{purple}genotype creation} (\ref{genotype_replication}) [{\color{orange}phenotype creation} (\ref{phenotype_creation})] in Fig. \ref{fig:Self_replication}. Definitions $\braket{ \left(\hat{\sigma}_z\right)_{g_1}\otimes \hat{1}_{p_0}}_{\hat{\rho}_1}\equiv \braket{\hat{\sigma}_z}_{g_1}$ and $\braket{\hat{1}_{g_1}\otimes\left(\hat{\sigma}_z\right)_{p_0}}_{\hat{\rho}_1}\equiv\braket{\hat{\sigma}_z}_{p_0}(t_0)$ can be deduced from Section (\ref{lindbladian_calculations}), l. 3-4.

Using Eq. (\ref{Nielsen_2175}) for interpretation purposes, the action of the just exposed cloning protocol can be regarded as the perfect copying of the component $r_3$ of the \emph{Bloch vector} or \emph{Polarization vector} $\vec{r}=(r_1,r_2,r_3)$, whereas the values of $r_1$ and $r_2$ are completely disregarded, since we have $\vec{\sigma}=(0,0,\hat{\sigma}_3)$ \cite[p.~4, l.~33-35]{Ferraro}. That is, the no-cloning theorem (Appendix \ref{No-cloning theorem}) only allows approximate cloning, the cloning of a %shrunk
part of the Bloch vector $\vec{r}$.\\

Withal, possible errors in the replication stage would provide this model's simile of \emph{mutation}! $\,\,$ \cite[p.~2, l.~27]{QAL_IBM} \cite[p.~2, l.~3-4]{AL_in_QT}


\subsubsection{Genotype creation} \label{genotype_replication}

As said, the first step in the reproduction via self-replication is \emph{partially cloning} --without violating the \emph{no-cloning} theorem\footnote{As one of the most notable results of quantum information, the \emph{no-cloning} theorem is studied in detail in Appendix \ref{No-cloning theorem}.}-- the expectation value of a certain set of observables (only $\braket{\hat{\sigma}_z}_g$, in this model) belonging to a predecesor genotype ($\hat{\rho}_{g_0}$, for example, in order to create the $1^\textrm{st}$ individual) to an ancillary state $\hat{\rho}_\textrm{A}=\ket{0}\bra{0}$, originated by the environment. 

The self-replication process must preserve the expectation value for the chosen observable, Eq. (\ref{preservation_condition}). Therefore, $\braket{\hat{\sigma}_z}_g$ will be constant both in time ($\braket{\hat{\sigma}_z}_g\neq\braket{\hat{\sigma}_z}_g(t)$, as mentioned in Section \ref{age_and_predatorness}) and from generation to generation. This mimics the preservation of the genetic information throughout successive generations, a crucial feature in natural selection \cite[p.~2, l.~31-32]{AL_in_QT}!

In order to prove that $\braket{\hat{\sigma}_z}_g$  remains constant, let us suppose that the foremost genotype state from which subsequent phenotypes will be created is described by the following density operator, in the $\{\ket{0},\ket{1}\}$ computational basis (as we work in a basis in which $\hat{\sigma_z}$ is diagonal \cite[p.~2, l.~20-21]{Bio_Cloning}): \footnote{See in Appendix {\ref{rho_g_properties}} that $\hat{\rho}_g$, Eq. (\ref{AL_in_QT_Eq_3a}), satisfies the usual properties of the density operator ($\hat{\rho}$).}

\begin{equation} \label{AL_in_QT_Eq_3a}
\hat{\rho}_0\equiv\hat{\rho}_{g_0}\doteq\begin{pmatrix}a&b-ic\\b+ic&1-a\end{pmatrix}\,\textrm{.}
\end{equation}

From  this precursor genotype $\hat{\rho}_{g_0}$, Eq. (\ref{AL_in_QT_Eq_3a}), we create the genotype qubit belonging to the new individual of the $1^\textrm{st}$ generation, $\hat{\rho}_{g_1}$, via the operator proposed in Eq. (\ref{rho_p0_and_rho_g1}): \footnote{See calculations of Eq. (\ref{rho_0}-\ref{U_CNOT}) in Appendix \ref{rho_0_and_U_CNOT}.}

\begin{equation} \label{rho_0}
\hat{\rho}_1   \,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{(\ref{rho_p0_and_rho_g1})}}}}{\equiv}}}\,\,    \hat{\rho}_{g_1}=\hat{U}(\hat{\rho}_{g_0}\otimes\hat{\rho}_A)\hat{U}^\dagger\numeq{\textrm{\ref{rho_0_Appendix}}}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}
\,\textrm{,}
\end{equation}
%$$\hat{\rho}_{p_1}\equiv\hat{U}(\hat{\rho}_A\otimes\hat{\rho}_{g_0})\hat{U}^\dagger$$
where we have used, in the $\{\ket{0},\ket{1}\}^{\otimes 2}=\{\ket{0},\ket{1}\}\otimes\{\ket{0},\ket{1}\}=\{\ket{00},\ket{01},\ket{10},\ket{11}\}$ \footnote{We use the abbreviated notations $\ket{v}\otimes\ket{w}\equiv \ket{v}\ket{w} \equiv \ket{v,w}\equiv \ket{vw}$ \cite[p.~72, l.~33]{Nielsen}, where $\otimes$ is the Kronecker product} basis, $\,\,\,$ \cite[p.~xxxi, l.~1]{Nielsen}
\begin{equation} \label{U_CNOT}
\hat{U}
\numeq{\textrm{\ref{why_U_CNOT}}}\hat{U}_{C_{NOT}}\numeq{\textrm{\ref{U_CNOT_Appendix}}}\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\,\textrm{,}
\end{equation}

and $\hat{U}^\dagger\equiv\hat{U}_{C_{NOT}}^\dagger=\hat{U}_{C_{NOT}}\equiv\hat{U}$. Since $\hat{U}\in\mathbb{R}$, $\hat{U}^\dagger=\hat{U}^T$, and unitarity $\hat{U}^\dagger=\hat{U}^{-1}$ simplifies to orthogonality $\hat{U}^T=\hat{U}^{-1}$. Then, $\hat{U}^T\equiv\hat{U}_{C_{NOT}}^T=\hat{U}_{C_{NOT}}\equiv\hat{U}$. $\hat{U}$ is  a symmetric matrix, a square matrix that is equal to its transpose.


\subsubsection{Phenotype creation} \label{phenotype_creation}

Then, the new phenotype is created. As in the genotype creation, the expectation value of $\hat{\sigma}_z$ is copied, but now from the new genotype ($\hat{\rho}_{g_1}$, for instance, to create the $1^\textrm{st}$ individual) to an ancillary state $\hat{\rho}_{\textrm{Ancillary}}\equiv\hat{\rho}_\textrm{A}=\ket{0}\bra{0}\,\,\,$ \cite[p.~2, Eq.~(3c)]{AL_in_QT}, without contradicting the \emph{no-cloning} theorem \cite[p.~2, l.~17-19]{Bio_Cloning}. Now, however, the phenotype of the same new individual is a subspace prone to change because of the environment and inter-individual interactions.

Prior to any interaction (with the environment and/or other individuals) that makes the phenotype's $\braket{\hat{\sigma}_z}_p(t)$ change --conversely, $\braket{\hat{\sigma}_z}_g$ remains constant ($\braket{\hat{\sigma}_z}_g\neq\braket{\hat{\sigma}_z}_g(t)$) as mentioned in Section \ref{age_and_predatorness}--, when this process has just taken place; id est, just when the newborn individual's phenotype is created from the initial genotype ($\hat{\rho}_{g_0}$) at time $t=t_0$: $\braket{\hat{\sigma}_z}_p(t_0)=\braket{\hat{\sigma}_z}_g$ $\,$  \cite[p.~2, l.~29-30]{AL_in_QT}. 

For example, as it is described in Eq.  (\ref{preservation_condition}), $\braket{\hat{\sigma}_z}_{\hat{\rho}_0} = \braket{\hat{\sigma}_z}_{g_1} =\braket{\hat{\sigma}_z}_{p_0}(t_0)$, or, from the right hand side of Fig. \ref{fig:Self_replication}, $\braket{\hat{\sigma}_z}_{g_1} =\braket{\hat{\sigma}_z}_{p_1}(t_0^\prime)$. However, since the cloning operation from which $\hat{\rho}_{p_0}$ and $\hat{\rho}_{g_1}$ are created from $\hat{\rho}_{g_0}$ occurs at time $t_0$ and $\hat{\rho}_{p_1}$ (along with a $\hat{\rho}_{g_2}$ we don't explicitly describe here) is created from $\hat{\rho}_{g_1}$ at a later time $t_0^\prime>t_0$, $\braket{\hat{\sigma}_z}_{\hat{\rho}_0} = \braket{\hat{\sigma}_z}_{g_1} =\braket{\hat{\sigma}_z}_{p_1}(t_0^\prime)\neq\braket{\hat{\sigma}_z}_{p_0}(t_0^\prime)$. That is, since both cloning operations are not simultaneous ($t_0\neq t_0^\prime$), $p_0$ has already changed by the time $p_1$ is created.

As it appears in Eq. (\ref{rho_p0_and_rho_g1}), $\hat{\rho}_{p_0}(t_0)=\hat{\rho}_{g_1}$, because they are created using the same cloning operation $\hat{\rho}_1 =(\ref{rho_p0_and_rho_g1})$. Nevertheless, note that
\begin{equation} \label{pheno_t0} 
\hat{\rho}_{p_1}(t_0^\prime)\neq\hat{\rho}_{g_1}=(\ref{rho_0})
\,\textrm{.}
\end{equation} 
From Eq. (\ref{Nielsen_2175}), in order to be equal, we should have $\braket{\hat{\sigma}_i}_p(t_0^\prime)=\braket{\hat{\sigma}_i}_g$, $\forall i$, $:$ $i=1,2,3$. Not just for $i=3$. Instead, we have: $\,$ \cite[p.~2, Eq.~(8)]{Bio_Cloning}
\begin{equation}
\begin{split}
\hat{\rho}_2
&\equiv \hat{\rho}_{p_1} (t_0^\prime)\numeq{\ref{rho_old_to_new}}\hat{U} \left[\hat{\rho}_{g_1}\otimes\hat{\rho}_A \right]\hat{U}^\dagger  \,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{(1)}}}}{\equiv}}}\,\,   \hat{U}_1 \left[\hat{\rho}_{g_1}\otimes\hat{\rho}_A \right]\hat{U}_1^\dagger \numeq{\ref{rho_0}}\hat{U}_1\left[\left(  \hat{U}_0 (\hat{\rho}_{g_0}\otimes\hat{\rho}_A)\hat{U}_0^\dagger\right)\otimes\hat{\rho}_A\right]\hat{U}_1^\dagger\\
& \numeq{2} \left(\hat{U}_1\hat{U}_0 \right)  \left(\hat{\rho}_{g_0}\otimes\hat{\rho}_A\ \otimes\hat{\rho}_A\right) \left(\hat{U}_0^\dagger\hat{U}_1^\dagger\right) = \left(\hat{U}_1\hat{U}_0 \right)  \left(\hat{\rho}_{g_0}\otimes\hat{\rho}_A\ \otimes\hat{\rho}_A\right) \left(\hat{U}_1\hat{U}_0\right)^\dagger  \,\textrm{,}
\end{split}
\end{equation}
where in $(1)$ we redefined Eq. (\ref{rho_old_to_new}) as $\hat{\rho}_{i+1}=\hat{U}_i (\hat{\rho}_i\otimes\hat{\rho}_A)\hat{U}_i^\dagger$ for $i=0,1,...$, just to differentiate the $\hat{U}\equiv \hat{U}_0$ operators that belong to Eq. (\ref{rho_0}). On the other hand, in $(2)$ we used $(\hat{A}\otimes\hat{B})(\hat{C}\otimes\hat{D})=(\hat{A}\hat{C})\otimes(\hat{B}\hat{D})$. where $\hat{A}\otimes\hat{1}_B$ ($\hat{1}_A\otimes\hat{B}$) is an operator which acts only on subspace $A$ ($B$): $(\hat{A}\otimes\hat{1}_B)(\hat{1}_A\otimes\hat{B})=\hat{A}\hat{1}_A\otimes \hat{1}_B\hat{B}=\hat{A}\otimes\hat{B}$ 



\subsubsection{Preservation of $\braket{\hat{\sigma}_z}$ after self-replications}  \label{preservation_sigma_z}

Being the condition imposed in Eq. (\ref{preservation_condition}), we will show that our self-replication protocol  maintains $\braket{\hat{\sigma}_z}$, the expectation value taken in the two output qubits: either the genotype or the phenotype subspace. For instance, in $\hat{\rho}_{g_1}$ and $\hat{\rho}_{p_0}(t_0)$, respectively, if the partial quantum cloning is applied to $\hat{\rho}_{g_0}$. 

Of course, what it is truly conserved, both in time $t$ and from generation to generation, is the expectation value taken in the $i^{th}$ generation's genotype subspace, $\braket{\hat{\sigma}_z}_{g_i}$. For the same individual, both the genotype and the phenotype subspace are created using the information of the same predecesor genotype, which has the same $\braket{\hat{\sigma}_z}$ that its ancestors, but then the phenotype changes with time $t$. 

Nevertheless, what we want to prove here is that the protocol chosen is effective in the sense that the expectation value of the chosen observable is copied or preserved during the replication process, conservation described by Eq. (\ref{preservation_condition}). We will see as well that $\braket{\hat{\sigma}_x}$ and $\braket{\hat{\sigma}_y}$, instead, are not preserved by our self-replication protocol.\\

Starting with the \emph{zero generation genotype}, the arbitrary initial genotype, defined by $\hat{\rho}_0 \equiv \hat{\rho}_{g_0}$ (Eq.(\ref{AL_in_QT_Eq_3a})),  $\braket{\hat{\sigma}_i}_{g_0}=[\hat{\sigma}_i]_{\hat{\rho}_{g_0}}=\textrm{Tr}(\hat{\rho}_{g_0}\hat{\sigma}_i)$ $:$ $i=1,2,3$ \cite[p.~181, Eq.~(3.4.10)]{Sakurai}. Hence,

\begin{equation} \label{sigma_z}
\braket{\hat{\sigma}_z}_{g_0}=[\hat{\sigma}_z]_{\hat{\rho}_{g_0}}=\textrm{Tr}(\hat{\rho}_{g_0}\hat{\sigma}_z)\doteq \textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&b-ic\\b+ic&1-a\end{pmatrix}\begin{pmatrix}1&0\\0&-1\end{pmatrix}\end{pmatrix}=\textrm{Tr}\begin{pmatrix}a&ic-b\\b+ic&a-1\end{pmatrix}=2a-1\,\textrm{,}
\end{equation}
\begin{equation} \label{sigma_x}
\braket{\hat{\sigma}_x}_{g_0}=[\hat{\sigma}_x]_{\hat{\rho}_{g_0}}=\textrm{Tr}(\hat{\rho}_{g_0}\hat{\sigma}_x)\doteq \textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&b-ic\\b+ic&1-a\end{pmatrix}\begin{pmatrix}0&1\\1&0\end{pmatrix}\end{pmatrix}=\textrm{Tr}\begin{pmatrix}b-ic&a\\1-a&b+ic\end{pmatrix}=2b\,\textrm{,}
\end{equation}
\begin{equation} \label{sigma_y}
\textrm{and,}\quad\braket{\hat{\sigma}_y}_{g_0}=[\hat{\sigma}_y]_{\hat{\rho}_{g_0}}=\textrm{Tr}(\hat{\rho}_{g_0}\hat{\sigma}_y)\doteq \textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&b-ic\\b+ic&1-a\end{pmatrix}\begin{pmatrix}0&-i\\i&0\end{pmatrix}\end{pmatrix}=\textrm{Tr}\begin{pmatrix}bi+c&-ai\\i-ai&c-ib\end{pmatrix}=2c\,\textrm{.}
\end{equation}

Now, in the creation of the corresponding two output qubits: the \emph{$1^\textrm{st}$ generation's genotype} and \emph{$0^\textrm{th}$ generation's phenotype},  defined by $\hat{\rho}_{g_1}$ (Eq. (\ref{rho_0})) and $\hat{\rho}_{p_0}$, respectively, Eq. (\ref{preservation_condition}) ought to be fullfilled.\footnote{See calculations pertaining to Eq. (\ref{sigmaz_otimes_one}-\ref{sigmay_otimes_one}) in Appendix \ref{sigma_otimes_one_appendix}.} $\,\,$ \cite[p.~2, Eq.~(1)]{Ferraro}
\begin{equation} \label{sigmaz_otimes_one}
\begin{cases}
 \braket{\hat{\sigma}_z}_{g_1}= \braket{ \left(\hat{\sigma}_z\right)_{g_1}\otimes \hat{1}_{p_0}}_{\hat{\rho}_1} \equiv\braket{\hat{\sigma}_z\otimes\hat{1}_2}_{\hat{\rho}_1}
 \numeq{\textrm{\ref{sigmaz_otimes_one_appendix}}}2a-1\\
 \braket{\hat{\sigma}_z}_{p_0}(t_0)= \braket{\hat{1}_{g_1}\otimes\left(\hat{\sigma}_z\right)_{p_0}}_{\hat{\rho}_1} \equiv\braket{\hat{1}_2\otimes\hat{\sigma}_z}_{\hat{\rho}_1}
 \numeq{\textrm{\ref{sigmaz_otimes_one_appendix2}}}2a-1
\end{cases}
\end{equation}

Then, Eq. (\ref{preservation_condition}) is satisfied: $\braket{\hat{\sigma}_z}_{g_0} \numeq{\textrm{\ref{sigma_z}}} 2a-1  \numeq{\textrm{\ref{sigmaz_otimes_one_appendix}}} \braket{\hat{\sigma}_z}_{g_1} \numeq{\textrm{\ref{sigmaz_otimes_one_appendix2}}}\braket{\hat{\sigma}_z}_{p_0}(t_0)$.\\

On the other hand, if we replace $\hat{\sigma}_z$ by $\hat{\sigma}_x$ and $\hat{\sigma}_y$, respectively, 

% https://tex.stackexchange.com/questions/291133/two-labels-on-the-same-equation-line
    \noindent\begin{minipage}{0.415\textwidth}
\begin{equation} \label{sigmax_otimes_one}
\begin{cases}
 \braket{\hat{\sigma}_x}_{g_1}\equiv\braket{\hat{\sigma}_x\otimes\hat{1}_2}_{\hat{\rho}_1}
 \numeq{\textrm{\ref{sigmax_otimes_one_appendix}}}0\\
 \braket{\hat{\sigma}_x}_{p_0}(t_0)\equiv\braket{\hat{1}_2\otimes\hat{\sigma}_x}_{\hat{\rho}_1}
 \numeq{\textrm{\ref{sigmax_otimes_one_appendix2}}}0
\end{cases}
\end{equation} 
    \end{minipage}%
    \begin{minipage}{0.10\textwidth}\centering
    and 
    \end{minipage}%
    \begin{minipage}{0.415\textwidth}
\begin{equation} \label{sigmay_otimes_one}
\begin{cases}
 \braket{\hat{\sigma}_y}_{g_1} \equiv\braket{\hat{\sigma}_y\otimes\hat{1}_2}_{\hat{\rho}_1}
 \numeq{\textrm{\ref{sigmay_otimes_one_appendix}}}0\\
 \braket{\hat{\sigma}_y}_{p_0}(t_0)\equiv\braket{\hat{1}_2\otimes\hat{\sigma}_y}_{\hat{\rho}_1}
 \numeq{\textrm{\ref{sigmay_otimes_one_appendix2}}}0
\end{cases}
\end{equation}
    \end{minipage}\vskip1em



Thus, Eq. (\ref{preservation_condition}) is not obeyed for $\braket{\hat{\sigma}_x}$ and $\braket{\hat{\sigma}_x}$: $\braket{\hat{\sigma}_x}_{g_0} \numeq{\textrm{\ref{sigma_x}}}2b\neq 0  \numeq{\textrm{\ref{sigmax_otimes_one_appendix}}} \braket{\hat{\sigma}_x}_{g_1} \numeq{\textrm{\ref{sigmax_otimes_one_appendix2}}}\braket{\hat{\sigma}_x}_{p_0}(t_0)$ and $\braket{\hat{\sigma}_y}_{g_0} \numeq{\textrm{\ref{sigma_y}}}2c\neq 0  \numeq{\textrm{\ref{sigmay_otimes_one_appendix}}} \braket{\hat{\sigma}_y}_{g_1} \numeq{\textrm{\ref{sigmay_otimes_one_appendix2}}}\braket{\hat{\sigma}_y}_{p_0}(t_0)$.\\

Thus, as mentioned, the protocol proposed in Ref. \cite[p.~2, Eq.~(1b) \& (3c)]{AL_in_QT} and Ref. \cite[p.~2, Eq.~(7)]{Bio_Cloning} for the reproduction of individuals conserves only $\braket{\hat{\sigma}_z}$, the expectation value of the chosen observable.



\subsection{Phenotype change}

As explained in Section \ref{age_and_predatorness} (l. 4-5), as in nature, the phenotype --$\braket{\hat{\sigma}_z}_p$, here-- changes by the interaction with both the environment (Section \ref{environment}) and other individuals (Section \ref{inter-individual}):

\subsubsection{Environment} \label{environment}

All physical systems are subjected to external influences to a greater or lesser extent. Uncontrolled environmental interaction decoheres QCs, and pure states get mixed. Decoherence destroys quantum superpositions and entanglement, the cornerstones of QCs (Section \ref{Introduction}), thus decreasing the probability of successful computation. Nevertheless, here, we will take advantage of this disturbances in order to simulate the aging of living units!

Systems that approximately preserve quantum coherence (off-diagonal elements of the density matrix $\hat{\rho}$) are treated with Hamiltonian time evolution $\hat{\rho}(t)=\hat{U}\,\hat{\rho}(t_0)\,\hat{U}^\dagger$ $:$ $\hat{U}=\hat{U}(t,t_0)$ $\,$\cite[p.~4604, Eq.~(8)]{DiVincenzo}. For those that, because of environmental effects, do not, as in our case, master equations are used \cite[p.~1074, l.~55-60]{Lloyd}.

 Precisely, we will model the effect of the environment, the phenotype qubit's degradation (\emph{aging}) until the asymptotic state $\braket{\hat{\sigma}_z}_p(t=t_d)=1-\epsilon$ (\emph{death}), using the \emph{Lindblad master equation} as the bath coupled with each phenotype qubit: $\,\,\,$ \cite[p.~2, Eq.~(2)]{AL_in_QT} $\,\,\,$ (Appendix \ref{lindblad_appendix})
\begin{equation} \label{lindblad_environ}
\frac{d}{dt}\hat{\rho}(t)=\hat{\dot{\rho}}\numeq{\textrm{\ref{lindbla_origin}}}\lambda\left(\hat{\sigma}\hat{\rho}\hat{\sigma}^\dagger - \frac{1}{2}\hat{\sigma}^\dagger \hat{\sigma}\hat{\rho}-\frac{1}{2}\hat{\rho}\hat{\sigma}^\dagger\hat{\sigma}\right)\,\textrm{,}
\end{equation}

where $\hat{\sigma}\equiv\ket{0}\bra{1}\doteq\begin{pmatrix}0&1\\0&0
\end{pmatrix}$ is the \emph{Lindblad} or \emph{jump} operator \cite[p.~2, l.~24-25]{QAL_IBM}. Its \emph{steady state} is the ancillary (or blank) state $\hat{\rho}_\textrm{A}=\ket{0}\bra{0}$. 

It decoheres living units towards its steady states, Eq.  (\ref{Lindblad_evol_infinity}), in analogy to their aging process, or the thermal dissipation of thermodynamical systems, which fluctuate until they reach the environment's temperature, modeled as a thermal reservoir. These steady states can be said to be the cadavers belonging to the living entities and, at the same time, the starting point of newborn individuals, the register where information is copied in the two events (Section \ref{self-replication}) that constitute the self-replication process. Such a duality would resemble the final link in the trophic chain, the role decomposers play: the closure of the cycle!\\

Furthering with Eq. (\ref{rho_0}),\footnote{See the corresponding calculations in Appendix \ref{lindbladian_calculations}.}
\begin{equation} \label{rho_1_lindblad}
\hat{\dot{\rho}}_{1} \,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{(\ref{rho_p0_and_rho_g1})}}}}{\equiv}}}\,\,   \hat{\dot{\rho}}_{p_0}\numeq{\textrm{\ref{lindblad_calc}}}\lambda\left(\hat{\sigma}\hat{\rho}_{p_0}\hat{\sigma}^\dagger - \frac{1}{2}\hat{\sigma}^\dagger \hat{\sigma}\hat{\rho}_{p_0}-\frac{1}{2}\hat{\rho}_{p_0}\hat{\sigma}^\dagger\hat{\sigma}\right)
\end{equation}

and we obtain (Eq. (\ref{rho_11}-\ref{rho_otherwise})) $\,\,\,$ \cite[p.~3, Eq.~(4)]{AL_in_QT}
\begin{equation} \label{rho_g1(t)}
\hat{\rho}_{1}(t)  \,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{(\ref{rho_p0_and_rho_g1})}}}}{\equiv}}}\,\,  \hat{\rho}_{p_0}(t)\,\doteq\begin{pmatrix}a&0&0&(b-ic)e^{-\lambda t/2}\\0&0&0&0 \\ 0&0&(1-a)(1-e^{-\lambda t})&0 \\ (b+ic)e^{-\lambda t/2}&0&0&(1-a)e^{-\lambda t} \end{pmatrix}
\end{equation}

As mentioned in Section (\ref{preservation_sigma_z}) and the logic of nature dictates, the expectation value of the selected observable ($\hat{\sigma}_z$, here) remains constant in the genotype subspace --Eq. (\ref{sigma_otimes_one(t)})--, but is a function of time $t$ in the phenotype subspace --Eq. (\ref{sigma_otimes_one(t)2})--: $\,\,\,$ \cite[p.~3, Eq.~(5)]{AL_in_QT}


% https://tex.stackexchange.com/questions/291133/two-labels-on-the-same-equation-line
\begin{equation} \label{sigma_otimes_one(t)}
 \braket{\hat{\sigma}_z}_{g_1}= \braket{ \left(\hat{\sigma}_z\right)_{g_1}\otimes \hat{1}_{p_0}}_{\hat{\rho}_1\,(t)} \equiv\braket{\hat{\sigma}_z\otimes\hat{1}_2}_{{\hat{\rho}_1\,(t)}}
 \numeq{\textrm{\ref{sigmaz_otimes_one(t)_appendix}}}2a-1\,\numeq{\textrm{\ref{sigmaz_otimes_one}a}}\braket{\hat{\sigma}_z}_{g_1}(t_0)\,\neq\braket{\hat{\sigma}_z}_{g_1}(t)\,\textrm{,}
\end{equation} 

\begin{equation} \label{sigma_otimes_one(t)2}
 \textrm{and}\quad\braket{\hat{\sigma}_z}_{p_0}(t)= \braket{\hat{1}_{g_1}\otimes\left(\hat{\sigma}_z\right)_{p_0}}_{\hat{\rho}_1\,(t)}\equiv\braket{\hat{1}_2\otimes\hat{\sigma}_z}_{\hat{\rho}_1\,(t)}
 \numeq{\textrm{\ref{sigma_p0(t)}}} 1+2e^{-\lambda t}(a-1)\neq\,\braket{\hat{\sigma}_z}_{p_0}(t_0)\textrm{.}
\end{equation}
If we substitute in these equations $t=t_0=0$, the time at when both the phenotype $\hat{\rho}_{p_0}$ and the genotype qubit $\hat{\rho}_{g_1}$ have just been created from a predecesor genotype, we recover Eq. (\ref{sigmaz_otimes_one}):  $\braket{\hat{\sigma}_z}_{p_0}(t=t_0)\numeq{\textrm{\ref{sigma_otimes_one(t)2}}} 1+2e^{-\lambda 0}(a-1)=1+2a-2=2a-1\numeq{\textrm{\ref{sigma_otimes_one(t)}}}\braket{\hat{\sigma}_z}_{g_1}=(\ref{sigmaz_otimes_one})$.


\subsubsection{Inter-individual interaction} \label{inter-individual}

This is the last biological feature we will introduce. By the interaction between individuals, phenotypes are exchanged, conditionally, depending on the correspoding genotypes \cite[p.~2, l.~28-29]{QAL_IBM}. 

The $2$ individual that interact sum $4$ qubits, so the implementation is achieved by a $4\times 4$ unitary operation, which, as said, changes both phenotypes contingent upon both genotypes. Thus, phenotypes are the target qubits, and the genotypes, the control ones \cite[p.~2, l.~29-30]{QAL_IBM}. See Section \ref{experimental_implementation_interindividual} for more information.

\subsection{Experimental implementation} \label{experimental_implementation}

\subsubsection{Experimental implementation of environment's decoherence} \label{experimental_implementation_decoherence}

Regarding the experimental implementation, the environment's influence, decoherence towards $\hat{\rho}_A$, cannot be directly simulated in our device, \href{https://quantumexperience.ng.bluemix.net/qx/editor}{IBM}'s QC. The alternative is considering projections to $\ket{0}$ as rotations along $OY$, $e^{i\hat{\sigma}_y\,\theta}$, \cite[p.~2, l.~37-40]{QAL_IBM} in each phenotype's Bloch sphere, where $\theta$ is inversely proportional to decoherence or death time, $t_d$. 

\subsubsection{Experimental implementation of inter-individual interactions} \label{experimental_implementation_interindividual}

Inter-individual interactions are performed by $\hat{U}_{\textrm{Interact}}\equiv \hat{U}_{\textrm{I}}$, whose effect is to exchange the phenotype qubits:  $\hat{U}_{\textrm{I}}\ket{xxyy}=\ket{xyyx}$ and $\hat{U}_{\textrm{I}}\ket{xyyx}=\ket{xxyy}$ $:$ $x,y\in\{0,1\}$ and the qubit order in the IBM's QC is 
\begin{equation}  \label{qubit_order}
\ket{xxyy}\equiv \left(\ket{x}_{g_1}\ket{x}_{p_1}\right)  \left(\ket{y}_{g_2}\ket{y}_{p_2}\right)\equiv \left(\ket{x}_3\ket{x}_2\right)\left(\ket{y}_1\ket{y}_0\right)\,\textrm{.}
\end{equation}
Thus, $\hat{U}_{\textrm{I}}\hat{U}_{\textrm{I}}=\hat{1}_4$, or, equivalently, $\hat{U}_{\textrm{I}}=\hat{U}_{\textrm{I}}^{-1}=\hat{U}_{\textrm{I}}^\dagger$.

We will decompose $\hat{U}_{\textrm{I}}$ in terms of the gates offered by IBM's experimental setup. Ref. \cite{QAL_IBM}'s solution is 
\begin{equation} \label{interaction_operator}
\hat{U}_{\textrm{I}}\numeq{\textrm{\ref{U_I_gates}}}\hat{S}_{21}\,\hat{U}_{32}\,(\hat{1}_4\otimes\hat{F})\,\hat{U}_{32}\,\hat{S}_{21}\,\textrm{,}\quad\textrm{where}\,\, \hat{F}\equiv \hat{U}_{01}\,\hat{C}_{10}\,\hat{C}_{20}\,\hat{U}_{21}\,\hat{C}_{10}^\dagger\,\hat{U}_{01}\,\hat{U}_{21}\,\textrm{,}
\end{equation}
and the first and second subindices denote the control and target qubit respectively. For example, if $\ket{x}_1\ket{y}_0\equiv\ket{xy}$, $\hat{U}_{10}\ket{xy}=\ket{x}\ket{x\oplus y}$ --qubit $1$ is the control, and, $0$, the target-- and $\hat{U}_{01}\ket{xy}=\ket{x\oplus y}\ket{x}$, where $\hat{U}\equiv\hat{U}_{C_{NOT}}$. Our usual definition of  $\hat{U}_{C_{NOT}}$, Eq. (\ref{U_CNOT_Appendix}) is the one that takes the first (second) qubit as the control (target). For the qubit order in the IBM computer, Eq. (\ref{qubit_order}), it corresponds, among others, to the former in the previous example, $\hat{U}_{10}$. Generally stated, (Appendix \ref{U_10 U_21 proof})
\begin{equation} \label{U_10 U_21}
 \hat{U}_{C_{NOT}}=\hat{U}_{ij}\,\textrm{ : } \,i,j=0,1,2,3\,\,\,\textrm{and}\,\,\,i>j\textrm{.}
\end{equation} 
IBM's real quantum computers only allow the experimental implementation of CNOT gates in the $\hat{U}_{ij}$, $i>j$ direction! It can be checked in the \href{https://quantumexperience.ng.bluemix.net/qx/editor}{composer}. Nevertheless, the control/target roles can be exchanged in the following way: $\hat{U}_{ji}=\hat{U}_{\textrm{Had}}^{\otimes 2}\,\hat{U}_{ij}\,\hat{U}_{\textrm{Had}}^{\otimes 2}$ $\textrm{ : } \,i,j=0,1,2,3\,\,\,\textrm{and}\,\,\,i>j\textrm{.}$ \emph{Proof}:
\begin{equation} \label{U_CNOT_12}
\begin{split}
\hat{U}_{ji}
&	=\hat{U}_{\textrm{Had}}^{\otimes 2}\,\hat{U}_{ij}\,\hat{U}_{\textrm{Had}}^{\otimes 2}=\left( \frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\ 1&-1\end{pmatrix}\otimes \frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\ 1&-1\end{pmatrix} \right)\hat{U}_{ij}\hat{U}_{\textrm{had}}^{\otimes 2}\\
&	\numeq{\textrm{\ref{U_10 U_21}}}\frac{1}{2}\begin{pmatrix}1&1&1&1\\ 1&-1&1&-1\\ 1&1&-1&-1\\ 1&-1&-1&1\end{pmatrix} \begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix} \hat{U}_{\textrm{Had}}^{\otimes 2}\\
&	= \frac{1}{2}\begin{pmatrix}1&1&1&1\\ 1&-1&-1&1\\ 1&1&-1&-1\\ 1&-1&1&-1\end{pmatrix}\,\frac{1}{2}\begin{pmatrix}1&1&1&1\\ 1&-1&1&-1\\ 1&1&-1&-1\\ 1&-1&-1&1\end{pmatrix}=\frac{1}{4}\begin{pmatrix}4&&&\\ &&&4\\ &&4&\\ &4&&\end{pmatrix}= \begin{pmatrix}1&&&\\ &&&1\\ &&1&\\ &1&&\end{pmatrix}\,\textrm{,}
\end{split}
\end{equation}
where $\hat{U}_{10}\ket{00}=\ket{00}$, $\hat{U}_{10}\ket{01}=\ket{11}$, $\hat{U}_{10}\ket{10}=\ket{10}$ and $\hat{U}_{10}\ket{11}=\ket{01}$. In other words, the second (first) qubit is the control (target). In the same manner, although these gates can be implemented directly, $\hat{U}_{ij}=\hat{U}_{\textrm{Had}}^{\otimes 2}\,\hat{U}_{ji}\,\hat{U}_{\textrm{Had}}^{\otimes 2}$ $\textrm{ : } \,i,j=0,1,2,3\,\,\,\textrm{and}\,\,\,i>j\textrm{.}$ \emph{Proof}:
\begin{equation}
\begin{split}
\hat{U}_{ij}
&	=\hat{U}_{\textrm{Had}}^{\otimes 2}\,\hat{U}_{ji}\,\hat{U}_{\textrm{Had}}^{\otimes 2}=\left( \frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\ 1&-1\end{pmatrix}\otimes \frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\ 1&-1\end{pmatrix} \right)\hat{U}_{ji}\hat{U}_{\textrm{had}}^{\otimes 2}\\
&	\numeq{\textrm{\ref{U_CNOT_23}}}\frac{1}{2}\begin{pmatrix}1&1&1&1\\ 1&-1&1&-1\\ 1&1&-1&-1\\ 1&-1&-1&1\end{pmatrix} \begin{pmatrix}1&&&\\ &&&1\\ &&1&\\ &1&&\end{pmatrix} \hat{U}_{\textrm{Had}}^{\otimes 2}\\
&	= \frac{1}{2}\begin{pmatrix}1&1&1&1\\ 1&-1&1&-1\\ 1&-1&-1&1\\ 1&1&-1&-1\end{pmatrix}\,\frac{1}{2}\begin{pmatrix}1&1&1&1\\ 1&-1&1&-1\\ 1&1&-1&-1\\ 1&-1&-1&1\end{pmatrix}=\frac{1}{4}\begin{pmatrix}4&&&\\ &4&&\\ &&&4\\ &&4&\end{pmatrix}= \begin{pmatrix}1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix}\,\textrm{.}
\end{split}
\end{equation}

Moreover, $\hat{S}$ is the swap operator $\hat{U}_{i,}$ (Appendix \ref{swap_proof}) $\,\,\,$ \cite[p.~xxxi, l.~2]{Nielsen} 
\begin{equation} \label{swap}
\hat{S}_{ij}=\hat{U}_{ij}\,\hat{U}_{ji}\,\hat{U}_{ij}\,\textrm{,}\,\,\forall i,j.
\end{equation}
As mentioned, experimentally, IBM's quantum computers only allow the implementation of $\hat{U}_{ij}$, $i>j$, CNOT gates. That is, $\hat{U}_{ji}$, $i>j$, gates are not allowed. Then, for $i>j$, the only permitted swap operators are the following:
\begin{equation} \label{S_ij}
\hat{S}_{ij}\numeq{\textrm{\ref{swap}}}\hat{U}_{ij}\,\hat{U}_{ji}\,\hat{U}_{ij} \numeq{\textrm{\ref{U_CNOT_12}}} \hat{U}_{ij}\,(\hat{U}_{\textrm{Had}}^{\otimes 2}\,\hat{U}_{ij}\,\hat{U}_{\textrm{Had}}^{\otimes 2})\,\hat{U}_{ij}\,\textrm{, and}
\end{equation}
\begin{equation} \label{S_ji}
\hat{S}_{ji}\numeq{\textrm{\ref{swap}}}\hat{U}_{ji}\,\hat{U}_{ij}\,\hat{U}_{ji} \numeq{\textrm{\ref{U_CNOT_12}}} (\hat{U}_{\textrm{Had}}^{\otimes 2}\,\hat{U}_{ij}\,\hat{U}_{\textrm{Had}}^{\otimes 2})\,\hat{U}_{ij}\,(\hat{U}_{\textrm{Had}}^{\otimes 2}\,\hat{U}_{ij}\,\hat{U}_{\textrm{Had}}^{\otimes 2})\,.
\end{equation}
%\doteq \begin{pmatrix} 1&& \\ &\hat{\sigma}_x & \\ &&1 \end{pmatrix}
Finally, $\hat{C}$ is the controlled square root of $\hat{\sigma}_x$. $\hat{\sigma}_x$ is also called NOT gate. The matrix representing a general controlled-$\hat{U}$ is $\hat{U}_{C_{\hat{\sigma}_i}}\doteq \hat{1}_2 \oplus \hat{\sigma}_i$ $:$ $i=1,2,3$. For example, $\hat{U}_{C_{\hat{\sigma}_x}}=\hat{U}_{C_{NOT}}\doteq \hat{1}_2\oplus \hat{\sigma}_x$. For the latter gate, $\hat{C} \equiv \hat{U}_{C_{\sqrt[]{\hat{\sigma}_x}}}\doteq \hat{1}_2\oplus \sqrt[]{\hat{\sigma}_x}$, where 

\begin{equation} \label{sqrt_sigma_x}
\sqrt[]{\hat{\sigma}_x} \numeq{\textrm{\ref{proof_sqrt_sigma_x}}} \frac{1}{2}\begin{pmatrix} 1+i & 1-i \\ 1-i & 1+i
\end{pmatrix}\,\textrm{.}
\end{equation}

For instance, for the both gates in Eq. (\ref{interaction_operator}), $i>j$,  (Appendix \ref{sqrt_sigma_z})
\begin{equation} \label{controlled_not_root}
\begin{split}
\hat{C}_{ij}
&	\numeq{\textrm{\ref{proof_controlled_not_root}}} \left( \sqrt[4]{\hat{\sigma}_z}\otimes\sqrt[]{\hat{\sigma}_z}\, \hat{u}_3(-\frac{\pi}{4},0,0) \right)\,\hat{U}_{ij}\, \left(\hat{1}_2\otimes\hat{u}_3(\frac{\pi}{4},0,0)\right)\,\hat{U}_{ij}\,	\left(\hat{1}_2\otimes(\sqrt[]{\hat{\sigma}_z})^\dagger\right)\\
&	\numeq{\textrm{\ref{proof_controlled_not_root}}}\begin{pmatrix}1&&&\\ &1&&\\ &&\frac{1}{2}\begin{pmatrix} 1+i & 1-i \\ 1-i & 1+i
\end{pmatrix}\end{pmatrix}\,\textrm{.}
\end{split}
\end{equation}
As it can be verified in IBM's quantum computer's \href{https://quantumexperience.ng.bluemix.net/qx/editor}{composer}, $\sqrt[4]{\hat{\sigma}_z}$ ($\hat{T}$, in the composer), $\sqrt[]{\hat{\sigma}_z}$ ($\hat{S}$, in the composer) and their complex conjugates can be deployed directly.

\vspace{0.8cm}
Once we have defined the interaction operator, $\hat{U}_{\textrm{I}}$, Eq. (\ref{interaction_operator}), we analyse the effect of each constituent gate. For it, from Ref. \cite[p.~3, Fig.~1]{QAL_IBM}, we define the initial state as
\begin{equation} \label{psi_t0}
\ket{\psi(t_0)} =\left(\ket{0}_{g_1}\ket{0}_{p_1}\right) \left(\ket{0}_{g_2}\ket{0}_{p_2}\right) \equiv \left(\ket{0}_3\ket{0}_2\right)\left(\ket{0}_1\ket{0}_0\right)\,\textrm{,} 
\end{equation}
where the right hand side refers to IBM's quantum computer's quantum state definition.\\

$t=t_1$: We initialize the genotype $g_1$ [$g_2$] in the state $\frac{1}{\sqrt[]{2}}(\cos(\pi/8)\ket{0}+\sin(\pi/8)\ket{1})$ [$\frac{1}{\sqrt[]{2}}(\cos(3\pi/8)\ket{0}+\sin(3\pi/8)\ket{1})$] by the following operations: $\,$ \cite[p.~3, l.~5]{QAL_IBM} 
\begin{equation} \label{psi_t1}
\begin{split}
\ket{\psi(t_1)}
&	= \left(\hat{u}_3(\pi/4,0,0)\ket{0}_3\,\ket{0}_2\right) \left(\hat{u}_3(3\pi/4,0,0)\ket{0}_1\,\ket{0}_0\right) \\
&	\numeq{\textrm{\ref{IBM_u_gates}}}\left(\frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}&\sin\frac{\pi}{8}\\ \sin\frac{\pi}{8}&\cos\frac{\pi}{8} \end{pmatrix}\ket{0}_3\,\ket{0}_2\right) \left(\frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{3\pi}{8}&\sin\frac{3\pi}{8}\\ \sin\frac{3\pi}{8}&\cos\frac{3\pi}{8} \end{pmatrix}\ket{0}_1\,\ket{0}_0\right)\\
&	\doteq \left(\frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}\\ \sin\frac{\pi}{8}\end{pmatrix}_3\,\ket{0}_2\right) \left(\frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{3\pi}{8}\\ \sin\frac{3\pi}{8}\end{pmatrix}_1\,\ket{0}_0\right)\,\textrm{, or}
\end{split}
\end{equation}

\begin{equation} \label{psi_t1_2}
\begin{split}
\ket{\psi(t_1)}
&	\numeq{\textrm{\ref{psi_t1}}} \frac{1}{2}\left( \cos\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0000} + \cos\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{0010} + \sin\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{1000} + \sin\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1010}\right)\,\textrm{.}
\end{split}
\end{equation}

$t=t_2$: Afterwards,  individual $1$ ($2$) is completed copying the genotype $g_1$ ($g_2$) into $\hat{\rho}_A$: $\,$ \cite[p.~3, l.~5-7]{QAL_IBM} 
\begin{equation} \label{psi_t2}
\begin{split}
\ket{\psi(t_2)}
&	\numeq{\textrm{\ref{psi_t1}}} \hat{U}_{32}\left(\frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}\\ \sin\frac{\pi}{8}\end{pmatrix}_3\otimes\begin{pmatrix}1\\0
\end{pmatrix}_2\right) \hat{U}_{10}\left(\frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{3\pi}{8}\\ \sin\frac{3\pi}{8}\end{pmatrix}_1\otimes\begin{pmatrix}1\\0
\end{pmatrix}_0\right)\\
&	=\left(\begin{pmatrix}1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix}\frac{1}{\sqrt[]{2}}\begin{pmatrix}\cos\frac{\pi}{8}\\ 0\\ \sin\frac{\pi}{8}\\ 0\end{pmatrix}\right)  \left(\begin{pmatrix}1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix}\frac{1}{\sqrt[]{2}}\begin{pmatrix}\cos\frac{3\pi}{8}\\ 0\\ \sin\frac{3\pi}{8}\\ 0\end{pmatrix}\right)\\
&	=\frac{1}{\sqrt[]{2}}\begin{pmatrix}\cos\frac{\pi}{8}\\ 0\\ 0\\ \sin\frac{\pi}{8}\end{pmatrix}\,\,\frac{1}{\sqrt[]{2}}\begin{pmatrix}\cos\frac{3\pi}{8}\\ 0\\ 0\\ \sin\frac{3\pi}{8}\end{pmatrix}\\
&	= \frac{1}{\sqrt[]{2}} \left(\cos\frac{\pi}{8}\ket{0}_3\ket{0}_2 + \sin\frac{\pi}{8}\ket{1}_3\ket{1}_2\right)\,\,\frac{1}{\sqrt[]{2}} \left(\cos\frac{3\pi}{8}\ket{0}_1\ket{0}_0 + \sin\frac{3\pi}{8}\ket{1}_1\ket{1}_0\right)		 \,\textrm{, or}\end{split}
\end{equation}

\begin{equation} \label{psi_t2_2}
\begin{split}
\ket{\psi(t_2)}
&	\numeq{\textrm{\ref{psi_t2}}} \frac{1}{2}\left( \cos\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0000} + \cos\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{0011} + \sin\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{1100} + \sin\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1111}\right) \,\textrm{,}\end{split}
\end{equation}
where $\hat{U}_{ij}\equiv\left(\hat{U}_{C_{NOT}}\right)_{\textrm{ctrl,target}}$. Note that, after $\hat{U}_{ij}$ is applied, $\ket{}_{g_1}\equiv\ket{}_{3}$ ($\ket{}_{g_2}\equiv\ket{}_{1}$) becomes \emph{entangled} with $\ket{}_{p_1}\equiv\ket{}_{2}$ ($\ket{}_{p_2}\equiv\ket{}_{0}$), because the state of individual $1$ ($2$) cannot be written as a product of its constituent qubits separately.\\

$t=t_f$: The rest of the gates in Ref. \cite[p.~3, Fig.~1]{QAL_IBM}, correspond to $\hat{U}_{\textrm{I}}$, Eq. (\ref{interaction_operator}). After the interaction, at time $t=t_{\textrm{final}}\equiv t_f$, we obtain $\,\,$ \cite[p.~3, l.~8]{QAL_IBM} (Appendix \ref{U_I_gates})
\begin{equation} \label{psi_t_f}
\begin{split}
\ket{\psi(t_f)}
&	= \hat{U}_{\textrm{I}}\ket{\psi(t_2)} \numeq{\textrm{\ref{psi_t2_2}}} \frac{1}{2} (\cos\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0000} + \cos\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{0110} +\sin\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{1001} \\
&	 +\sin\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1111})\,\textrm{,}
\end{split}
\end{equation}
where we applied the previously mentioned $\hat{U}_{\textrm{I}}\ket{xxyy}=\ket{xyyx}$ and $\hat{U}_{\textrm{I}}\ket{xyyx}=\ket{xxyy}$ $:$ $x,y\in\{0,1\}$.\\









\newpage

\section{Conclusions}

As mentioned, this work makes up our first approach to a more independent research process. Using, apart from usual textbooks, scientific articles as bibliography has given us the opportunity to    become more aware about the infinite amount of knowledge we completely ignore. However, the proper reaction to this is not sorrow, there is a lot to explore!

This work emphasizes shallowly the path started by Ref.\cite{QAL_IBM}\cite{AL_in_QT}\cite{Bio_Cloning}.  They lead to minimal but consistent simulations of Darwinian quantum scenarios, which could be enriched including spatial information or increasing the complexity of the model by selecting a larger set of observables (not just $\hat{\sigma}_z$) to transmit through generations \cite[p.~2, l.~30-33]{QAL_IBM}.

 The value of these articles resides in the fact that experimental implementation of QAL might notably contribute to understand quantum mechanics and the emergency of life and complex systems like those presented in Section \ref{Introduction} (l. 12-14). 

Although achievable with current technology \cite[p.~1, l.~6-7]{Bio_Cloning}, even constructing QAL experimental setups 
constitutes a great challenge per se. As Richard Feynman said \cite[p.~69, l.~30-31]{Ricard_Sole}: \emph{What I cannot create, I do not understand}. In this case, both parts of the quote feedback: knowledge and tremendous attempts are needed in order to tackle the technological difficulties that await the realization of experimental implementation of QCs, and, at the same time, empirical results are expected to shed new light on the foundations of quantum physics.


\newpage

\begin{appendices}
\section{\normalfont{Game of Life implementation}} 

\subsection{Code} \label{appendix_A_code}

\begin{lstlisting}[
  style      = Matlab-editor,
  basicstyle = \mlttfamily,
]
% ------------------------------  INITIAL CONDITION  ------------------------------------ 

% Dimensions of the 2-D grid or lattice:
n_row= 10;                     
n_column= 12;

% "steps" = number of steps,
steps=30;

% At first, in the matrix display, we used "0" elements to describe "alive" cells, and "1" elements for "dead" ones, being the most intuitive notation. However, in the code section "DISPLAY", by default,"gray" colormap displays "1" as white, and the most intuitive display is black ("0" by default in "gray" colormaps) to describe "alive" cells.  We gave priority to the latter, so we used "0" for "alive" cells. In order to make it intuitive, for example, imagine the "0" represents the form of a sane cell, which can be approximated to an ellipse. When it dies, suppose that the cell empties and becomes a thin cluster of dead biological material, represented by a "1".

% "grid" = initial grid or lattice.

% Initial condition Example 1: 
 % Uncomment (remove "%") the following to fill the "grid" (matrix) randomly with 0 or 1:
  %grid = randi([0 1],n_row,n_column);
  
% Fill the grid with death(=1) cells, in order to deploy the following examples.
for i= 1:n_row
  for j = 1:n_column
    grid(i,j)=1;
  endfor
endfor

% Initial condition Example 2: Glider (fixed shape that moves across the grid). Useful in order to see the periodic boundary conditions (PBCs)
grid(4,2)=grid(5,2)=grid(5,4)=grid(6,2)=grid(6,3)=0; 
 
% Initial condition Example 3: "Tetromino" (shape formed by 4 connected alive cells) that becomes a "beehive" ("still-life" or stable figure) on the fourth generation.
 %(Uncomment, remove "%")
 %grid(4,4)=grid(5,4)=grid(5,5)=grid(5,6)=0;

% Initial condition Example 4: "Tetromino" that after the tenth generation becomes four isolated periodical blinkers. Each of them constitutes the so-called "traffic lights" periodical (period 2) shape.
 %(Uncomment, remove "%")
 %grid(4,5)=grid(5,4)=grid(5,5)=grid(5,6)=0;
  
% "disp('Grid, in the following'),disp(steps),disp('steps')" would print the sentences and parameters in parentheses in different lines. Thus, instead that, in order to display it compactly:
disp(['Grid, in the following  ', num2str(steps),'  steps'])
% where the intrinsic function num2str() converts numerical data to strings.

% ---------------------------------------------------------------------------------------
% --------------------------  INITIAL CONDITION DISPLAY ---------------------------------
                                          
  colormap gray;       % Image traversing black to white in shades of gray.
  imagesc(grid);  
       
  % Notable when n_row >> n_column or n_row << n_column, not to stretch the cells and keep the square shape, we apply the following:
  axis equal tight     
  drawnow            
  
  % Intrinsic function that pauses the GIF for (argument) seconds, in order to visualize each generation:       
  pause(0.1)  



% ---------------------------------------------------------------------------------------
% ----------------------------------  MAIN PROGRAM  ------------------------------------- 

% "n_row" and "n_column" will be referenced later by "size(grid,1)" and "size(grid,2)", respectively, where the intrinsic function size() gives the following array if the argument is "grid": size(grid) = [n_row   n_column]. 
% For a general A matrix:  size(A) = [size(A,1)   size(A,2)].

% Originally, we used the concatenated matrix grid_boundary=[grid grid grid; grid grid grid; grid grid grid] as a reference to apply the PBCs, but it was expensive in terms of memory.

% t is defined in order to index the number of time steps.
for t=1:steps

% First, we create the environment that will be updated at time t + 1 ("grid_next") according to the lattice at the previous generation or time t ("grid").
 grid_next=grid;
 
% If we used "grid" both as a reference and as the environment we change for the same time t, as the analysis of the neighborhood of each cell can only be computed individually, we would not follow "Conway's Game of Life" rule that states that, at each generation or time step, all the grid ought to be changed or updated  synchronously, and not cell by cell.

% We use i and j to index the grid spatially.
 % i goes from (1) to (n_row); i.e., from (1) to (size(grid,1)) 
 % j goes from (1) to (n_column); i.e., from (1) to (size(grid,2))
 
 % Matrix indexing starts from integer 1 by default. That is why we used i= 1:size(grid,1) (j= 1:size(grid,2)) instead of i= 0:(size(grid,1)-1) (j= 0:(size(grid,2)-1)).

 for i= 1:size(grid,1)                 % size(grid,1)=n_row
   for j= 1:size(grid,2)                % size(grid,2)=n_column
     x=0;                                % x = counter of alive "Moore neighbors"
    
    
    % For i=1 or size(grid,1) and/or j=1 or size(grid,2) -id est, when we are analyzing a cell on the border of the grid- PBCs have to be applied.
    
    % We implement PBCs using the intrincic function mod(a,b), which gives the reminder of a/b. Hence, it can be used to create "modulo operation".
    
    % As stated (code l. 75), since matrix indexing starts from integer 1, in order to prevent "mod" from starting the period from 0, instead of mod(a,b), we will use mod(a-1,b)+1, where b=size(grid,1) (b=size(grid,2)) if a=i (a=j).
  
    % There are 8 cells in the Moore neighborhood. Then, 8 conditions have to be fulfilled:
  
      if (grid([mod((i+1)-1,size(grid,1))+1],j)==0)      
        x=x+1;                                           
      endif
      if (grid([mod((i-1)-1,size(grid,1))+1],j)==0)
        x=x+1;
      endif
      if (grid(i,[mod((j+1)-1,size(grid,2))+1])==0)   
        x=x+1;
      endif
      if (grid(i,[mod((j-1)-1,size(grid,2))+1])==0)   
        x=x+1;
      endif
      if (grid([mod((i+1)-1,size(grid,1))+1],[mod((j+1)-1,size(grid,2))+1])==0)
        x=x+1;
      endif
      if (grid([mod((i+1)-1,size(grid,1))+1],[mod((j-1)-1,size(grid,2))+1])==0)    
        x=x+1;
      endif
      if (grid([mod((i-1)-1,size(grid,1))+1],[mod((j+1)-1,size(grid,2))+1])==0)   
        x=x+1;
      endif
      if (grid([mod((i-1)-1,size(grid,1))+1],[mod((j-1)-1,size(grid,2))+1])==0)
        x=x+1;
      endif

    % Uncomment the following to display the cell by cell analysis of the grid: (help for revision)
    %disp(['i= ', num2str(i),',j= ',num2str(j),',x= ',num2str(x)])
    
    
    % We first used:
    %if  (grid(i+1,j)==1) ||  (grid(i-1,j)==1) || (grid(i,j+1)==1) || ...       
    %    (grid(i,j-1)==1) || (grid(i+1,j+1)==1) || (grid(i+1,j-1)==1) || ...
    %    (grid(i-1,j+1)==1) || (grid(i-1,j-1)==1) 
    %    x=x+1;
    %endif  
    % But if we put this (| = or) (or, equivalently, if we use "elif"), we won't pass by all the conditions once one of them is fulfilled.
    % On the other hand, PBCs have to be  deployed via mod() intrinsic function, as mentioned: mod(a-1,b)+1, where b=size(grid,1) (b=size(grid,2)) if a=i (a=j).
     

    % GoL rules (see Introduction)
     if grid(i,j)==0 && (x<2 || x>3)           % "&" = "and " ;   "==" "= is equal to"
        grid_next(i,j)=1;   
     elseif grid(i,j)==1 && x==3
       grid_next(i,j)=0;    
     endif
 
   endfor % end the cycle relative to column index "j".                 
 endfor  % end the cycle relative to row index "i".

 
% ---------------------------------------------------------------------------------------
% ----------------------------------  DISPLAY ------------------------------------------- 
                      
  colormap gray;       
  imagesc(grid_next);
  axis equal tight     
  drawnow                    
  pause(0.1)  
 
 grid=grid_next;   % To use "grid" as the lattice at time t and "grid_next" as the lattice in the next time step t+1.
                    
endfor  % end the cycle relative to the number of time steps ("t").

\end{lstlisting}




\newpage
\section{\normalfont{Key concepts}} \label{Appendix_B}

\subsection{Qubit approach} \label{qubit_approach}
\emph{Qubit}s (or quantum bits \cite[p.~4, l.~2]{Nielsen}) are two-level quantum systems (TLS) $\in\mathcal{H}_2$, where $\mathcal{H}_2$ is the two-dimensional Hilbert subspace \cite[p.~43, l.~11-12]{Nielsen}, a complex vector space over the complex numbers $\mathbb{C}^2$, with inner product. Id est, a qubit takes two complex numbers to fully describe it. They can represent a 0, 1, as classical bits, but also a linear combination of both, which is a property known as \emph{superposition}. They constitute the minimal representative of a quantum mechanical system \cite[p.~80, l.~30-31]{Nielsen}. More generally, they are named \emph{qutrit}s for $\mathbb{C}^3$ and \emph{qudit}s for $\mathbb{C}^d$. They are usually described in the $\{\ket{0},\ket{1}\}$ basis, called \emph{computational basis} (or standard basis or Z basis), as the following vectors: $\,$ \cite[p.~xxix, l.~20-21]{Nielsen}
\begin{equation}
\ket{0}\doteq\begin{pmatrix}1\\0\end{pmatrix}\quad\textrm{and}\quad\ket{1}\doteq\begin{pmatrix}0\\1\end{pmatrix}\,\textrm{.}
\end{equation}
Defining basis kets (or \emph{measurement directions}, in a more quantum terminology) is a trick borrowed from linear algebra. Once whe have chosen the basis, any other vector can be constructed from a linear combination of these basis kets or vectors. Another example is the \emph{superposition basis} $\{\ket{+},\ket{-}\}$ $:$ $\ket{\pm}\equiv\frac{1}{\sqrt[]{2}}(\ket{0}\pm\ket{1})$

Qubits are decidedly real! They can be realized in many different physical systems such as a photon (a particle of light) with two different polarizations, as the alignment of a nuclear spin in a uniform magnetic field or as an electron orbiting a single atom with two possible states \cite[p.~14, l.~15-16]{Nielsen}. Accordingly, the \emph{wire} in the quantum circuit does not necessarily correspond to a physical one; instead, it could represent time evolution or the spatial propagation of physical particle such as a photon  \cite[p.~23, l.~1-3]{Nielsen}.

As a matter of fact, the quantum information processing physical schemes easiest to craft are the former, those relying on optical techniques: manipulations of photons by beamsplitters and mirrors. Despite the difficulty of producing single photons on demand and the fact that they do not directly interact with one another, but by the mediation of noise adding atoms, they are highly stable quantum information carriers \cite[p.~49, l.~8-21]{Nielsen}.

\emph{Ion traps} constitute an alternative approach. Here, a small number of charged atoms are retained in a certain space and photons manipulate the information, rather than store it \cite[p.~49, l.~23-29]{Nielsen}. Ref. \cite[p.~3, l.~ 52-54]{Bio_Cloning} affirms they are the most advanced experimental setup in terms of the time it takes the environment to decohere the prepared states (towards the steady states of the Lindbladian, the ancillary or blank states $\hat{\rho}_\textrm{A}=\ket{0}\bra{0}$, in this case. See Eq. (\ref{Lindblad_evol_infinity})) and the possible gate errors. This \emph{decoherence}, or distabilizing effects of environmental interaction, is the main form in which the imprecision in the manipulation of quantum setups comes and, consequently, a major experimental obstacle. The usual aim is to build systems that decohere slowly compared to the time required to do the computation. Most macroscopic systems, for example decohere so rapidly as to make quantum superposition effects practically unobservable.

 Finally, the last leading quantum platform is the \emph{Nuclear Magnetic Resonance} (NMR) system. It manipulates, using electromagnetic radiation, the quantum information stored in the \emph{nuclear spin} of atoms \cite[p.~49, l.~39-42]{Nielsen}. Obviously, each platform has its own properties, more or less advantageous depending on the quantum protocols to accommodate.\\

Quantum logic gates that form the mentioned quantum circuits can be described by two by two \emph{unitary} --being \emph{unitarity}, in order to conserve probabilities, the \emph{only} constraint on gates \cite[p.~18, l.~30]{Nielsen}\cite[p.~76, l.~19-20]{Deutsch}-- matrices if they act on a single qubit  \cite[p.~18, l.~22]{Nielsen}. Id est, qubits serve as information registers and, on the other hand, unitary operators process information and make up the time-evolution operator \cite[p.~67, Eq.~(2.1.5)]{Sakurai} derived from Schrödinger equations. They are to be thought abstractly, as they can be represented by the mentioned diverse physical apparatus ($1/2$-spins, photons, atoms, etc.).

A priori, similar as in conventional computation, any general $n$-qubit transformation operation could be constructed as a product of several elements of the universal set of gates formed by the CNOT gate between two qubits described in Section \ref{U_CNOT_theory_Appendix} and the single qubit rotations (two bit transformations) \cite[p.~22, l.~5-6]{Nielsen} \cite[p.~6, l.~25-27]{Shor}. The latter can be implemented by relatively simple physical systems \cite[p.~6, l.~17]{Shor}.  Nevertheless, in practice, limitations arise by the errors originated from the fact that quantum registers (qubits) and operations (gates decribed by unitary operators) are said to be an approximation (closed or totally isolated systems) of open quantum systems (Appendix \ref{open_quantum_system}). Moreover, unitary dynamics does not cover the complete spectra of possible processes. See Appendix \ref{open_quantum_system}, where we state that the evolution operator in the reduced subspace of an open quantum system is not unitary.\\



 Continuing with single qubits, one simple geometrical picture useful in thinking about them is the following representation, the so-called \emph{Bloch sphere}, a one-to-one correspondence or bijection between pure [mixed] single qubit states ($\mathbb{C}^3$) and the points on the surface of [inside] a unit sphere ($\mathbb{R}^3$) \cite[p.~15]{Nielsen}: 
\begin{figure}[H] 
	\centering
	\includegraphics[scale=0.12]{Images/Bloch_sphere.png}
	\caption{Bloch sphere representation of a \emph{qubit}.}
	  \label{fig:Bloch_sphere}
\end{figure}

%s51/2 spin to represent the state of a bit;why not?~Of course, there are plenty of practical reasonswhy not, but I will proceed anyway.!I have to choose a datarepresentation, but there is a very obvious one: the spin-upstateu"&may represent the logical FALSE or zero stateu0&,and the spin-down stateu#&may represent the TRUE or onestateu1&.

Then, if we suppose that the Bloch sphere represents a $s=1/2$ spin system (or any other two-state or two-level quantum system (TLS)), the spin-up state may represent the $\ket{0}$ bit , and, the spin-down state, the $\ket{1}$ bit. 

Experimentally, the multiqubit state $\ket{\psi}=\ket{0}^{\otimes n}=\ket{000...}$ is manufactured first putting the spins in a strong magnetic field which rises all the spins to the spin-up states $\ket{0}$, and then letting them cool down. But how can we experimentally deploy quantum logic gates? Let us start with the one-qubit rotations, which, in conjunction with CNOT gates, comprise the universal set of quantum gates. 

To get the spin-down states $\ket{1}$, in atomic physics experimental setups, the spins are illuminated with radiation connecting the lower state $\ket{1}$ with the upper state $\ket{0}$ \cite[p.~4602, l.~43-52]{DiVincenzo}. In other words, the radiation induces a Rabi oscillation between $\ket{1}$ and $\ket{0}$. Thus, if the radiation illuminating a qubit is left on half of the Rabi oscillation period we apply to its spin a $\pi$ tipping radiation pulse: for example, appying the radiation to the second qubit, $\ket{000...}\rightarrow\ket{010...}$ . If, on the other hand, we apply the radiation to the second qubit but only for a quarter of the Rabi oscillation (corresponding to a $\pi/2$ spin rotation) it evolves as $\ket{000...}\rightarrow\frac{1}{\sqrt[]{2}}(\ket{000...}+\ket{010...})$ $\,$ \cite[p.~4603, Eq.~(2)]{DiVincenzo}. This has no classical analog: a classical computer can be programmed (inefficiently, since it takes $2^n$ classical computer resources to represent $n$-qubit states) to \emph{represent} the latter superposition, but this is different from the conventional computer's memory actually \emph{being} in this superposition of qubits.

On the other hand, $\hat{U}_{C_{NOT}}$ is implemented engineering an interaction Hamiltonian $\hat{H}_{int}=\frac{\hbar}{2}\hat{\sigma}_z^i\hat{\sigma}_z^j$ which couples the control and target qubits and is turned on temporarily when the CNOT gate needs to act.

Any point on this radius 1 Bloch sphere can be defined via the polar, $\theta$, and azimuth, $\varphi$, angles (Eq. (\ref{Bloch})). Morever, in the same picture, an arbitrary density operator $\hat{\rho}$ for a mixed state can be written as
\begin{equation} \label{Nielsen_2175}
 \hat{\rho}=\frac{1}{2}(\hat{1}_2+\vec{r}\cdot\vec{\sigma})\,\textrm{,}
\end{equation}
where $\vec{r}=[\hat{\sigma}_i]_{\hat{\rho}}\,\vec{n}_i$ is a real three-dimensional vector known as the \emph{Bloch vector} or \emph{Polarization vector}, where $\vec{n}_i$ is the unit vector $\hat{x}$, $\hat{y}$, $\hat{z}$ for $i=1,2,3$, respectively \cite[p.~4, l.~31-32]{Ferraro}. Moreover, $0\leq|\vec{r}|\leq 1$, where the right equality holds for a pure ensemble \cite[p.~195, Eq.~(2.175)]{Nielsen}. Instead, for $\vec{r}=0$, the state is maximally disordered or mixed and lies in the center of the Bloch sphere, in analogy to maximally unpolarized light. See the proof in Appendix \ref{proof_Nielsen_2175}.\\

Moreover, the mentioned single qubit gates correspond to rotations and reflections of the Bloch sphere represented in Fig. \ref{fig:Bloch_sphere}. For instance, the action of the Hadamard gate, $\hat{U}_{\textrm{Had}}$ can be thought of as a $\pi$ rotation around the $	\frac{1}{\sqrt[]{2}}(\vec{x}+\vec{z})$ axis, which exchanges $\vec{x}$ and $\vec{z}$: $\,$\cite[p.~19, l.~11-14]{Nielsen}.

\begin{figure}[H] 
	\centering
	\includegraphics[scale=0.16  ]{Images/Nielsen_Fig_1_4.png}
	\caption{Hadamard gate acting on the input $\ket{0}$ to produce $(\ket{0}+\ket{1})/\sqrt[]{2}$, in the Bloch sphere representation.}
	  \label{fig:Nielsen_Fig_1_4}
\end{figure}

Apart from being valid only for single qubits, Fig. \ref{fig:Bloch_sphere} is a form of representing complex vectors in a visualizable way. Due to this simplification, misleading interpretations could come up. For instance, $\ket{0}$ and $\ket{1}$ might seem parallel to each other, whereas they are orthogonal, $\braket{0|1}=0$.\\

Even if experimentally we can only physically access the $\vec{z}$ \emph{measurement direction} of the Bloch sphere --i.e., we can only measure in the the computational basis $\{\ket{0},\ket{1}\}$--, for example, to measure as if we could directly access the superposition or X basis $\{\ket{\pm}\}$, we apply $\hat{U}_{\textrm{Had}}$ before measuring, so that what previously pointed along direction $\pm\vec{x}$ (or $\ket{\pm}$), now points along $\pm\vec{z}$ (or $\ket{0}$, $\ket{1}$) and vice versa: $\hat{M}_x\equiv\hat{U}_{\textrm{Had}}\,\hat{M}_z$, where $\hat{M}_i$ denotes measurement in the $\vec{i}$ direction. Finally, to measure in the circular or Y basis $\{\ket{+}_y,\ket{-}_y\}$ $:$ $\ket{\pm}_y=\frac{1}{\sqrt[]{2}}(\ket{0}\pm\ket{1})$, since
\begin{equation}
\ket{\pm}_y=\hat{S}\hat{U}_{\textrm{Had}}\begin{Bmatrix}\ket{0}\\\ket{1}\end{Bmatrix}\quad : \quad \hat{S}\doteq\begin{pmatrix}1&0\\0&i\end{pmatrix}\,\textrm{,}
\end{equation}
we have to apply $\hat{M}_y\equiv\hat{U}_{\textrm{Had}}\hat{S}^\dagger\hat{M}_z$, to remap the $\vec{z}$ and $\vec{y}$ directions.


Measuring in the computational basis, information about the qubit’s phase cannot be accessed: for example, for both $\ket{+}$ and $\ket{-}$ we obtain both the classical bits 0 or 1 with $\%50$ probability. Measuring in the superposition basis $\{\ket{\pm}\}$, however, we are able to distinguish if the output qubit is either $\ket{+}$ or $\ket{-}$!\\

Apart from Eq. (\ref{Nielsen_2175}), another convenient representation of a single-qubit state is $\ket{\psi}=\cos(\theta/2)\ket{0}+\sin(\theta/2)e^{i\varphi}\ket{1}\doteq\begin{pmatrix}\cos(\theta/2)\\\sin(\theta/2)e^{i\varphi}\end{pmatrix}$, where $\varphi\in[0,2\pi)$ and $\theta\in[0,\pi]$\\

 \noindent
{\color{black} \rule{\linewidth}{0.2mm}}
\emph{Proof:}
In this Bloch sphere representation of a qubit, $\hat{\vec{\sigma}}\cdot\hat{r}\ket{\hat{\vec{\sigma}}\cdot\hat{r};0}=+\ket{\hat{\vec{\sigma}}\cdot\hat{r};0}$ and $\hat{\vec{\sigma}}\cdot\hat{r}\ket{\hat{\vec{\sigma}}\cdot\hat{r};1}=-\ket{\hat{\vec{\sigma}}\cdot\hat{r};1}$ \cite[p.~xxix, l.~24]{Nielsen}, where $\hat{\sigma}_i$ are the Pauli matrices for $i=1,2,3$, and 1, 2, and 3 refer to x, y, and z, respectively  $\,\,\,$  \cite[p.~169, Eq.~(3.2.32)]{Sakurai}\cite[p.~65, Fig.~2.2]{Nielsen}.\\

 From Fig.\ref{fig:Bloch_sphere}, $\hat{r}=\frac{\vec{r}}{|\vec{r}|}=\frac{\vec{r}}{r}=\sin\theta\cos\varphi\,\hat{x}+\sin\theta\sin\varphi\,\hat{y}+\cos\theta\,\hat{z}$. So, $\hat{\vec{\sigma}}\cdot\hat{r}=(\hat{\sigma}_1\,\hat{x}+\hat{\sigma}_2\,\hat{y}+\hat{\sigma}_3\,\hat{z})\cdot(\sin\theta\cos\varphi\,\hat{x}+\sin\theta\sin\varphi\,\hat{y}+\cos\theta\,\hat{z})=\hat{\sigma}_1\sin\theta\cos\varphi+\hat{\sigma}_2\sin\theta\sin\varphi+\hat{\sigma}_3\cos\theta$. From the definition of the Pauli matrices \cite[p.~169, Eq.~(3.2.32)]{Sakurai}, in the $\{\ket{0},\ket{1}\}$ computational basis:
 
\begin{equation} 
\begin{split}
\hat{\vec{\sigma}}\cdot\hat{r} &=\hat{\sigma}_1\sin\theta\cos\varphi+\hat{\sigma}_2\sin\theta\sin\varphi+\hat{\sigma}_3\cos\theta\doteq\begin{pmatrix}0&1\\1&0\end{pmatrix}\sin\theta\cos\varphi+\begin{pmatrix}0&-i\\i&0\end{pmatrix}\sin\theta\sin\varphi+\begin{pmatrix}1&0\\0&-1\end{pmatrix}\cos\theta\\
 &=\begin{pmatrix}\cos\theta&\sin\theta\cos\varphi-i\,\sin\theta\sin\varphi\\\sin\theta\cos\varphi+i\,\sin\theta\sin\varphi&-\cos\theta\end{pmatrix}=\begin{pmatrix}\cos\theta&e^{-i\varphi}\sin\theta\\e^{i\varphi}\sin\theta&-\cos\theta\end{pmatrix}
\,\textrm{.}\end{split}
\end{equation}

In order to find the eigenvalues ($\lambda$) and the pertaining eigenvectors of the operator $\hat{\vec{\sigma}}\cdot\hat{r}$,

\begin{equation} \label{Bloch_eigenvalues}
\begin{split}
|\hat{\vec{\sigma}}\cdot\hat{r}-\lambda\hat{1}|
&\doteq\begin{vmatrix}\cos\theta-\lambda&e^{-i\varphi}\sin\theta\\e^{i\varphi}\sin\theta&-\cos\theta-\lambda\end{vmatrix}=(\cos\theta-\lambda)(-\cos\theta-\lambda)-\sin^2\theta=-\cos^2\theta-\lambda\cos\theta+\lambda\cos\theta+\lambda^2\\
&-\sin^2\theta=-\cos^2\theta-\sin^2\theta+\lambda^2=\lambda^2-1=0\,\,\leftrightarrow\,\,\lambda=\pm 1
\,\textrm{,}\end{split}
\end{equation}

as we could have directly infered from $\hat{\vec{\sigma}}\cdot\hat{r}\ket{\hat{\vec{\sigma}}\cdot\hat{r};0}=+\ket{\hat{\vec{\sigma}}\cdot\hat{r};0}=\lambda\ket{\hat{\vec{\sigma}}\cdot\hat{r};0}$ and $\hat{\vec{\sigma}}\cdot\hat{r}\ket{\hat{\vec{\sigma}}\cdot\hat{r};1}=-\ket{\hat{\vec{\sigma}}\cdot\hat{r};1}=\lambda\ket{\hat{\vec{\sigma}}\cdot\hat{r};1}$  $\,\,\,$ \cite[p.~xxix, l.~24]{Nielsen}  $\,\,\,$  $\leftrightarrow$ $\lambda=\pm 1$ .\\

If we substitute $\lambda=\pm 1$ in Eq. (\ref{Bloch_eigenvalues}),
\begin{equation} \label{Bloch_eigenvectors}
\begin{pmatrix}\cos\theta\mp 1&e^{-i\varphi}\sin\theta\\e^{i\varphi}\sin\theta&-\cos\theta\mp 1\end{pmatrix}\begin{pmatrix}c_1\\c_2\end{pmatrix}=0=\begin{pmatrix}(\cos\theta\mp 1)c_1+(e^{-i\varphi}\sin\theta)c_2\\(e^{i\varphi}\sin\theta)c_1+(-\cos\theta\mp 1)c_2\end{pmatrix}\,\textrm{.}
\end{equation}

From Eq. (\ref{Bloch_eigenvectors}a), $c_2=-\frac{(\cos\theta\mp 1)c_1}{e^{-i\varphi}\sin\theta}=\frac{\pm 1-\cos\theta}{\sin\theta}e^{i\varphi}c_1$. So, if we choose $c_1=\sin\theta$, in the $\{\ket{0},\ket{1}\}$ computational basis,
\begin{equation} \label{Bloch_eigenvectors2}
\ket{\hat{\vec{\sigma}}\cdot\hat{r};\begin{Bmatrix}0\\1\end{Bmatrix}}\doteq N\begin{pmatrix}\sin\theta\\(\pm 1-\cos\theta)e^{i\varphi}\end{pmatrix}\,\textrm{,}
\end{equation}

subject to the normalization condition
\begin{equation} \label{Block_normalization}
\begin{split}
\braket{\hat{\vec{\sigma}}\cdot\hat{r};\begin{Bmatrix}0\\1\end{Bmatrix}|\hat{\vec{\sigma}}\cdot\hat{r};\begin{Bmatrix}0\\1\end{Bmatrix}}
&=1\doteq N^*\begin{pmatrix}\sin\theta&(\pm 1-\cos\theta)e^{-i\varphi}\end{pmatrix} N\begin{pmatrix}\sin\theta\\(\pm 1-\cos\theta)e^{i\varphi}\end{pmatrix}\\
&=N^*N(\sin^2\theta+(\pm 1-\cos\theta)^2)=|N|^2(\sin^2\theta+(\pm 1-\cos\theta)^2)
\end{split}
\end{equation}

 $$\leftrightarrow\,\,\,|N|=\frac{1}{\sqrt[]{(\sin^2\theta+(\pm 1-\cos\theta)^2}}\,\,\,\leftrightarrow\,\,\,N=\frac{1}{\sqrt[]{(\sin^2\theta+(\pm 1-\cos\theta)^2}}e^{i\delta}\,\,\,:\,\,\,\delta\in\mathbb{R}\,\textrm{.}$$\\
 
We will choose the phase $\delta$ so that $N$ is real and positive. For example,  if we choose $\delta=0$, Eq. (\ref{Bloch_eigenvectors2}) becomes
\begin{equation} \label{Bloch_eigenvectors3}
\ket{\hat{\vec{\sigma}}\cdot\hat{r};\begin{Bmatrix}0\\1\end{Bmatrix}}\doteq \frac{1}{\sqrt[]{(\sin^2\theta+(\pm 1-\cos\theta)^2}}\begin{pmatrix}\sin\theta\\(\pm 1-\cos\theta)e^{i\varphi}\end{pmatrix}\,\textrm{.}
\end{equation}

\vspace{0.5cm}

The 2 equations we have for each eigenvalue $\lambda$ in Eq. (\ref{Bloch_eigenvectors}) should be equivalent. From the first one, Eq. (\ref{Bloch_eigenvectors}a), and the $\lambda=1$ case, $(\cos\theta- 1)c_1+(e^{-i\varphi}\sin\theta)c_2=0$ and, subject to the normalization condition in Eq. (\ref{Block_normalization}), $|c_1|^2+|c_2|^2=1$. So, $(\cos\theta-1)c_1+(e^{-i\varphi}\sin\theta)c_2=0$ $\leftrightarrow$ $c_2=\frac{1-\cos\theta}{\sin\theta}e^{i\varphi}c_1$. \\

Substituting this in $|c_1|^2+|c_2|^2=1$, $1=|c_1|^2+|\frac{1-\cos\theta}{\sin\theta}e^{i\varphi}c_1|^2=|c_1|^2(1+(\frac{1-\cos\theta}{\sin\theta})^2)=|c_1|^2\frac{\sin^2\theta+(1-\cos\theta)^2}{\sin^2\theta}$ $\leftrightarrow$ $|c_1|=\frac{\sin\theta}{\sqrt[]{\sin^2\theta+(1-\cos\theta)^2}}$ $\leftrightarrow$ $c_1=\frac{\sin\theta}{\sqrt[]{\sin^2\theta+(1-\cos\theta)^2}}e^{\delta}$ $:$ $\delta\in\mathbb{R}$.\\

\vspace{0.5cm}
 We choose, as in Eq. (\ref{Bloch_eigenvectors3}), $\delta=0$,
\begin{equation}
\begin{split}
 c_1 
 &=\frac{\sin\theta}{\sqrt[]{\sin^2\theta+(1-\cos\theta)^2}}=\frac{2\sin(\theta/2)\cos(\theta/2)}{\sqrt[]{(2\sin(\theta/2)\cos(\theta/2))^2+(2\sin^2(\theta/2))^2}}=\frac{2\sin(\theta/2)\cos(\theta/2)}{\sqrt[]{4\sin^2(\theta/2)(\cos^2(\theta/2)+\sin^2(\theta/2))}}\\
 &=\frac{2\sin(\theta/2)\cos(\theta/2)}{2\sin(\theta/2)}=\cos(\theta/2)\,\textrm{,}
\end{split}
\end{equation} 
and, $c_2=\frac{1-\cos\theta}{\sin\theta}e^{i\varphi}c_1=\frac{1-\cos\theta}{\sin\theta}e^{i\varphi}\cos(\theta/2)=\frac{2\sin^2(\theta/2)}{2\sin(\theta/2)\cos(\theta/2)}e^{i\varphi}\cos(\theta/2)=\sin(\theta/2)e^{i\varphi}\,\textrm{.}$

\vspace{1cm}
Thus, the desired normalized eigenket that represents a qubit in the Bloch sphere in Fig. \ref{fig:Bloch_sphere} is
\begin{equation} \label{Bloch}
\ket{\hat{\vec{\sigma}}\cdot\hat{r};0}=\cos(\theta/2)\ket{0}+\sin(\theta/2)e^{i\varphi}\ket{1}\doteq\begin{pmatrix}\cos(\theta/2)\\\sin(\theta/2)e^{i\varphi}\end{pmatrix}\,\textrm{,}
\end{equation}

where Eq. (\ref{Bloch}) agrees Eq. (1.4) in Ref. \cite[p.~15]{Nielsen}. QED $\blacksquare$

\noindent
{\color{black} \rule{\linewidth}{0.2mm}}

\vspace{1cm}

For $\varphi=0$ and $\theta=0,\pi$ we obtain

\begin{equation} 
\hat{\vec{\sigma}}\cdot\hat{r}|_{\theta=0,\pi}=\hat{\sigma}_1\sin \begin{Bmatrix}0\\\pi\end{Bmatrix}\cos 0+\hat{\sigma}_2\sin\begin{Bmatrix}0\\\pi\end{Bmatrix} \sin 0+\hat{\sigma}_3\cos\begin{Bmatrix}0\\\pi\end{Bmatrix}=\pm\hat{\sigma}_3\,\textrm{,}
\end{equation}

\begin{equation} 
\textrm{and,}\quad\ket{\pm\hat{\sigma}_3;0}\doteq\begin{Bmatrix}\begin{pmatrix}\cos(0/2)\\\sin(0/2)e^{i0}\end{pmatrix}\\\begin{pmatrix}\cos(\pi/2)\\\sin(\pi/2)e^{i0}\end{pmatrix}\end{Bmatrix}=\begin{Bmatrix}\begin{pmatrix}1\\0\end{pmatrix}\\\begin{pmatrix}0\\1\end{pmatrix}\end{Bmatrix}\doteq \begin{Bmatrix}\ket{0}\\\ket{1}\end{Bmatrix}\,\textrm{,}
\end{equation}

which clearly agrees Fig. \ref{fig:Bloch_sphere}!\\

Another useful example corresponds to $\theta=\pi/2$ and $\varphi=\begin{Bmatrix}0\\\pi\end{Bmatrix}$. From Eq. (\ref{Bloch}),
\begin{equation} 
\ket{\pm}=\cos((\pi/2)/2)\ket{0}+\sin((\pi/2)/2)e^{i\begin{Bmatrix}0\\\pi\end{Bmatrix}}\ket{1}=\frac{\ket{0}\pm\ket{1}}{\sqrt[]{2}}\textrm{.}
\end{equation}
These states lie in the \emph{equator} of the Bloch sphere.





\subsection{No-cloning theorem} \label{No-cloning theorem}

	It is a no-go theorem that asserts that there are no physical means by which quantum information encoded in an arbitrary unknown \emph{pure} quantum state can be copied, if it belongs to a \emph{nonorthogonal} set. For mixed states, see the \emph{no-broadcasting theorem}, Appendix \ref{No-broadcasting theorem}.%, such as single photons with polarization directions $0$, $\pi/4$ and $\pi/2$.\\
	
It arouse in the year 1982, as the most relevant drawback that the quantum nature of information entails. It is remarkably curious that, given the relevance and simplicity of the no-cloning theorem, it was not discovered much earlier. %from the interest in whether it might be possible to use quantum effects to signal faster than light, which was not permitted in the framework of Einstein's theory of relativity.

%It turned out that this problem revolved around the capacity of \emph{cloning} unknown quantum states, because if perfect cloning was possible, a plausible argument could be made for the possibility of faster-than-light communication: for instance, using the FLASH scheme which deals with Third Kind measurements -- (wrong) new kind of measurement introduced in Herbert's paper, named after Pauli's First and Second Kind measurements -- that \emph{duplicate} exactly the measured state \cite[p.~1178, l.~24-27]{FLASH}. If cloning were possible, then quantum effects like Herbert's Third Kind measurements could be used in order to signal faster than light. \cite[p.~2-3]{Nielsen}\\

\subsubsection{General no-cloning theorem}

The \emph{no-cloning theorem} states that there is no unitary ($\hat{U}\hat{U}^\dagger=\hat{U}^\dagger\hat{U}=\hat{1}$) transformation $\hat{U}$ that can perform $\ket{\psi 0}\,\rightarrow\,\ket{\psi\psi}$ for $\forall\ket{\psi}$  $\,\,\,$ \cite[p.~39, l.~28-31]{Mermin}. This no-go theorem is an immediate consequence of quantum physics limitation to \textbf{linearity} \cite[p.~1, l.~33]{QAL_IBM}. Our cloning device must act linearly because time-dependent Schrödinger equation, which describes the evolution of unitary operators $\hat{U}$, is linear as well \cite[p.~429, footnote~12]{Nielsen}. If  $\,\,\,$  $\,\,\,$ \cite[p.~39, Eq.~(2.8)]{Mermin}

\begin{equation} \label{Mermin2.8}
\hat{U}\ket{\psi 0}=\hat{U}\ket{\psi\psi}=\hat{U}\ket{\psi}^{\otimes 2}
\quad\mathrm{and}\quad
\hat{U}\ket{\phi 0}=\hat{U}\ket{\phi \phi}=\hat{U}\ket{\phi}^{\otimes 2}\textrm{,}
\end{equation}

where $\ket{0}$ is a state of the target qubit, then, from linearity,

\begin{equation} \label{Mermin2.9}
\hat{U}(a\ket{\psi}+b\ket{\phi})\ket{0}\numeq{\textrm{lin.}}a\hat{U}\ket{\psi 0}+b\hat{U}\ket{\phi 0}\numeq{\ref{Mermin2.8}}a\ket{\psi\psi}+b\ket{\phi\phi}\,\textrm{,}
\end{equation}    

or, from a different approach, taking the whole linear combination of $\ket{\psi}$ and $\ket{\phi}$ as the arbitrary input, it should give $\,\,\,$ \cite[p.~429, Eq.~(12.17)]{Griffiths}
\begin{equation} \label{Mermin2.10}
\hat{U}(a\ket{\psi}+b\ket{\phi})\ket{0}\numeq{\ref{Mermin2.8}}(a\ket{\psi}+b\ket{\phi})(a\ket{\psi}+b\ket{\phi})=a^2\ket{\psi\psi}+ab\,[\,\ket{\psi\phi}+\ket{\phi\psi}\,]+b^2\ket{\phi\phi}\,\textrm{.}
\end{equation}

Thus, (\ref{Mermin2.9})$=$(\ref{Mermin2.10}) $\leftrightarrow$ $a=0$ or $b=0$. That is, if, and only if, the input is either $\ket{\phi}$ (if $a=0$) or $\ket{\psi}$ (if $b=0$), but no a linear combination of them.

It turns out that the linear behavior used in the first step of Eq. (\ref{Mermin2.9}) is a general property of quantum mechanics. Besides that, nonlinear behavior can lead to paradoxes such as the aforementioned faster-than light communication \cite[p.~18, l.~7-10]{Nielsen}.

With the aim of illustrating why quantum superpositions cannot be cloned by using a real quantum gate, we may choose the CNOT gate -- so that $\hat{U}=\hat{U}_{C_{NOT}}$, see Eq. (\ref{U_CNOT}) -- and consider the task of duplicating a qubit in the particular unknown state $(a\ket{0}+b\ket{1})$. That is, the input state of Eq. (\ref{Mermin2.8}-\ref{Mermin2.9}) but in the particular case $\ket{\psi}=\ket{0}$ and $\ket{\phi}=\ket{1}$.  

If the target qubit is blank, the control qubit can be seemed as cloned into there after applying the CNOT gate: $\hat{U}_{C_{NOT}}\ket{x0}=\ket{xx}$ $:$ $x\in\{0,1\}$. In this CNOT approach, $(a\ket{0}+b\ket{1})$ contains the \emph{control} qubits, and the \emph{target} is $\ket{0}$. Then Eq. (\ref{Mermin2.8}) becomes $\hat{U}_{C_{NOT}}(a\ket{0}+b\ket{1})\ket{0}=a\,\hat{U}_{C_{NOT}}\ket{00}+b\,\hat{U}_{C_{NOT}}\ket{10}=a\ket{00}+b\ket{11}$; i.e., the superposition $(a\ket{0}+b\ket{1})$ is transformed into the unnormalized entangled state (Appendix \ref{Entanglement}) $a\ket{00}+b\ket{11}$. Aside from that, from Eq. (\ref{Mermin2.8}), if $(a\ket{0}+b\ket{1})$ is successfully copied into \emph{target} qubit $\ket{0}$, $\hat{U}(a\ket{0}+b\ket{1})\ket{0}=(a\ket{0}+b\ket{1})(a\ket{0}+b\ket{1})=a\ket{00}+ab\ket{01}+ab\ket{10}+ab\ket{11}$ and we see once again that $\hat{U}$ (here, $\hat{U}_{C_{NOT}}$) does not copy the unknown input quantum state unless  $a=0$ or $b=0$  $\,\,\,$ \cite[p.~24, l.~8-19]{Nielsen}.\\ 

\subsubsection{No-cloning theorem for approximate cloning}

In addition, even the cloning to a reasonable degree of approximation is impossible \cite[p.~40, l.~6-7]{Mermin}. Let us suppose that an unitary operation $\hat{U}$ clones \emph{approximately} both $\ket{\psi}$ and $\ket{\phi}$:
\begin{equation} \label{Mermin2.11}
\hat{U}(\ket{\psi 0})\approx\ket{\psi\psi}\quad\textrm{and}\quad\hat{U}(\ket{\phi 0})\approx\ket{\phi\phi}\,\textrm{.}
\end{equation}
We will introduce now the relation between unitary operatons $\hat{U}$ and inner products. Inner products are $(.\,,.):\,\mathcal{H}\times\mathcal{H}\rightarrow\mathbb{C}$ maps, where $\mathcal{H}$ is the Hilbert space, a vector space over $\mathbb{C}$ (complex vector space) equipped with inner product \cite[p.~80, l.~15-16]{Nielsen}. Id est, the inner product is the dot product generalized to the $n$-dimensional complex vector space.

Unitary operations $\hat{U}$ preserve inner products $(.\,,.)$. That is, the inner product of $\hat{U}\ket{\psi}$ and $\hat{U}\ket{\phi}$ gives the same result as the inner product of $\ket{\psi}$ and $\ket{\phi}$: respectively, $(\hat{U}\ket{\psi},\hat{U}\ket{\phi})=(\hat{U}\ket{\psi})^\dagger(\hat{U}\ket{\phi})\numeq{1}(\bra{\psi}\hat{U}^\dagger)(\hat{U}\ket{\phi})=\bra{\psi}\hat{U}^\dagger\hat{U}\ket{\phi}=\bra{\psi}\hat{1}\ket{\phi}=\braket{\psi|\phi}\numeq{1}(\ket{\psi})^\dagger(\ket{\phi})=(\ket{\psi},\ket{\phi})$, where in ($1$) we use \emph{dual correspondence} (DC) definition $\hat{X}\ket{\alpha}\xleftrightarrow{\text{DC}}\bra{\alpha}\hat{X}^\dagger$  $\,\,\,\,$   \cite[p.~15, Eq.~(1.2.24)]{Sakurai}. Moreover, the inner product of a tensor product of states $\ket{\psi}\otimes\ket{\phi}\equiv\ket{\psi}\ket{\phi}$ is the (ordinary) product of their inner products: $(\ket{\alpha}\ket{\psi},\ket{\beta}\ket{\phi})=(\ket{\alpha}\ket{\psi})^\dagger(\ket{\beta}\ket{\phi})\numeq{1}(\bra{\psi}\bra{\alpha})(\ket{\beta}\ket{\phi})=\bra{\psi}\braket{\alpha|\beta}\ket{\phi}=\braket{\alpha|\beta}\braket{\psi|\phi}$. Since normalization, $\braket{0|0}=1$. Thus, if we substitute $\ket{\alpha}=\ket{\beta}=\hat{U}\ket{0}$:
\begin{equation} \label{Mermin2.12a}
\begin{split}
&(\hat{U}\ket{\psi}\ket{0},\hat{U}\ket{\phi}\ket{0})=
(\hat{U}\ket{\psi}\ket{0})^\dagger(\hat{U}\ket{\phi}\ket{0})\numeq{1}(\bra{0}\bra{\psi}\hat{U}^\dagger)(\hat{U}\ket{\phi}\ket{0})=\bra{0}\bra{\psi}\hat{U}^\dagger\hat{U}\ket{\phi}\ket{0}=\bra{0}\bra{\psi}\hat{1}\ket{\phi}\ket{0}=\\
&\bra{0}\braket{\psi|\phi}\ket{0}=\braket{\psi|\phi}\braket{0|0}=\braket{\psi|\phi}\,1=\braket{\psi|\phi}
\,\textrm{,}\end{split}
\end{equation}
\begin{equation} \label{Mermin2.12b}
\textrm{or, }\quad
\begin{split}
&(\hat{U}\ket{\psi}\ket{0},\hat{U}\ket{\phi}\ket{0})=(\hat{U}\ket{\psi}\ket{0})^\dagger(\hat{U}\ket{\phi}\ket{0})\,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{(\ref{Mermin2.11})}}}}{\approx}}}\,\,(\hat{U}\ket{\psi}\ket{\psi})^\dagger(\hat{U}\ket{\phi}\ket{\phi})\numeq{1}(\bra{\psi}\bra{\psi}\hat{U}^\dagger)(\hat{U}\ket{\phi}\ket{\phi})=\\
&\bra{\psi}\bra{\psi}\hat{U}^\dagger\hat{U}\ket{\phi}\ket{\phi}=\bra{\psi}\bra{\psi}\hat{1}\ket{\phi}\ket{\phi}=\bra{\psi}\braket{\psi|\phi}\ket{\phi}=(\braket{\psi|\phi})^2
\end{split}
\end{equation}

Thus, (\ref{Mermin2.12a})$\approx$(\ref{Mermin2.12b}) $\leftrightarrow$ $\braket{\psi|\phi}\approx(\braket{\psi|\phi})^2$ $\leftrightarrow$ $\braket{\psi|\phi}\approx0,1$ (i.e., almost orthogonal or the same state $\ket{\psi}\approx\ket{\phi}$, respectively). In all other cases at least one of the two states will not be copied well \cite[p.~40]{Mermin}. In essence, thus, the no-cloning theorem prevents just \emph{nonorthogonal} states from being copied.\\

But, if the universe is quantum mechanical \cite[p.~468, l.~6]{Feynman} \cite[p.~3, l.~25]{Shor}, why can classical information be copied? If classical information is thought as orthogonal quantum states, the apparent paradox between the ability to copy classical information bits and the no-cloning theorem, raised because classical systems must obey quantum mechanics \cite[p.~29, l.~4-6 \& p.~30, l.~1-2 \& 8-9]{Nielsen} in the context of \emph{correspondence principle}, is resolved.\\

%It is remarkably curious that, given the relevance and simplicity of the no-cloning theorem, it was not discovered much earlier.  We had to wait until the spark needed to find it ignited: Herbert's FLASH scheme's heretic idea of faster than light communication \cite{FLASH}.  \footnote{Herbert's paper, \cite{FLASH}, is mentioned in this work only in order to disclose that it brought the idea that no-cloning theorem had to exist. It is considered wrong and inadequate, so we have not analyzed it.}\\


\subsection{No-broadcasting theorem} \label{No-broadcasting theorem}
We have already explained standard the no-cloning theorem, which is applied to pure states. On the other hand, mixed states, rather than copied, can not be broadcast  \cite[p.~1, l.~3]{No-broadcasting}. Let as define \emph{broadcasting}:

Let us have a bipartite quantum system, formed by $A$, prepared in a state of the set $\{\hat{\sigma}_i\}$, and $B$, a blank state $\hat{\rho}_A$. We say a quantum operation $\hat{U}$ broadcasts the set of states $\{\hat{\sigma}_i\}$ if $\hat{U}(\hat{\sigma}_i\otimes\hat{\rho}_A)=\hat{\rho}_i^{\textrm{out}}$, where $\hat{\rho}_i^{\textrm{out}}$ satisfies $\textrm{Tr}_{A}\hat{\rho}_i^{\textrm{out}}=\textrm{Tr}_{B}\hat{\rho}_i^{\textrm{out}}=\hat{\sigma}_i$, $\forall i$.

The \emph{no-broadcasting theorem} claims a set of states $\{\hat{\sigma}_i\}$ is broadcastable if and only if its states commute. Let us suppose $\{\hat{\sigma}_i\}$ s formed by $\hat{\sigma}_1$ and $\hat{\sigma}_2$. If $[\hat{\sigma}_1,\hat{\sigma}_1]=0$, they can be expressed in the same orthonormal basis $\{\ket{a}\}$ \cite[p.~30, l.~5]{Sakurai}, they can be diagonalized in the same basis: $\hat{\sigma}_i=\sum_i\,\lambda_{i,a}\ket{a}\bra{a}$ : $i=1,2$. Duplication of orthogonal states is not forbidden by the no-cloning theorem, so $\hat{U}$ can clone states in the mentioned orthonormal basis $\{\ket{a}\}$: $\hat{U}(\hat{\sigma}_i\otimes\hat{\rho}_A)=\hat{U}(\sum_i\,\lambda_{i,a}\ket{a}\bra{a}\otimes\ket{0}\bra{0})=\hat{U}(\sum_i\,\lambda_{i,a}\ket{a0}\bra{a0})=\sum_i\,\lambda_{i,a}\ket{aa}\bra{aa}\equiv\hat{\rho}_i^{\textrm{out}}$. Then,
\begin{equation}
\begin{split}
\textrm{Tr}_{A}\hat{\rho}_i^{\textrm{out}}
&=\textrm{Tr}_{A}[\sum_i\,\lambda_{i,a}\ket{aa}\bra{aa}]=\textrm{Tr}_{A}[\sum_i\,\lambda_{i,a}(\ket{a}\bra{a})_A\otimes(\ket{a}\bra{a})_B]=\sum_i\,(\ket{a}\bra{a})_B\lambda_{i,a}\textrm{Tr}[(\ket{a}\bra{a})_A]\\
&=\sum_i\,(\ket{a}\bra{a})\lambda_{i,a}\textrm{Tr}[\braket{a|a}_A]=\sum_i\,(\ket{a}\bra{a})\lambda_{i,a}=\hat{\sigma}_i\,\textrm{,}
\end{split}
\end{equation}

\begin{equation}
\begin{split}
\textrm{and}\quad\textrm{Tr}_{B}\hat{\rho}_i^{\textrm{out}}
&=\textrm{Tr}_{B}[\sum_i\,\lambda_{i,a}\ket{aa}\bra{aa}]=\textrm{Tr}_{B}[\sum_i\,\lambda_{i,a}(\ket{a}\bra{a})_A\otimes(\ket{a}\bra{a})_B]=\sum_i\,(\ket{a}\bra{a})_A\lambda_{i,a}\textrm{Tr}[(\ket{a}\bra{a})_B]\\
&=\sum_i\,(\ket{a}\bra{a})\lambda_{i,a}\textrm{Tr}[\braket{a|a}_B]=\sum_i\,(\ket{a}\bra{a})\lambda_{i,a}=\hat{\sigma}_i\,:\,i=1,2\,\textrm{.}
\end{split}
\end{equation}
Id est, $\hat{\sigma}_1$ and $\hat{\sigma}_2$ are broadcast by $\hat{U}$.\\

%The \emph{relative entropy} of a positive operator $\hat{A}$ with respect to a positive operator $\hat{B}$ is defined by $S(\hat{A}||\hat{B})=\textrm{Tr}(\hat{A}\,\ln\frac{\hat{A}}{\hat{B}})$ \cite[p.~xxx, l.~7-8]{Nielsen}.


\subsection{Cloning of observables} \label{cloning_of_observables}
An orthogonal coding may be devised with a view to overcome the limitations posed by the no-cloning theorem. This requires additional control, because environment's propagation degrades the orthogonality of input quantum signals \cite[p.~1, l.~5-8]{Ferraro}. Nonetheless, broadcasting information encoded in the \emph{statistics} of sets of \emph{observables}, independently on the orthogonality on the input quantum state, does not precise any control \cite[p.~1, l.~9-18]{Ferraro}. By the \emph{cloning of the statistics} we mean, for any \emph{single}-qubit observable $\hat{A}$ ($\hat{\sigma}_z$, in our QAL model), the cloning of its expectation value $\braket{\hat{A}}$ \cite[p.~2, l.~25-26]{Ferraro}. More rigorously speaking, we consider that an observable $\hat{A}$ has been cloned if a measurement of $\hat{A}$ on either the two output qubits $\hat{\rho}_1$ and $\hat{\rho}_2$ gives the same as on the input qubit in the unknown state $\hat{\rho}_0$, $\forall\hat{\rho}_0$: $\,\,$ \cite[p.~2, Eq.~(1)]{Ferraro}
\begin{equation}
\hat{A}\textrm{ cloned}\leftrightarrow\braket{\hat{A}}_{\hat{\rho}_0}\numeq{{\color{purple}1}} \braket{\hat{A}_1\otimes\hat{1}_2}_{\hat{\rho}_3}\numeq{{\color{orange}2}} \braket{\hat{1}_1\otimes\hat{A}_2}_{\hat{\rho}_3}\,\textrm{,}
\end{equation}
where $\hat{\rho}_3=\hat{U}(\hat{\rho}_0\otimes\hat{\rho}_A)\hat{U}^\dagger$ is the state of the mentioned two qubits after the copying operation \cite[p.~2, l.~16]{Ferraro}. $\hat{\rho}_A$ is the probe qubit ($\ket{0}\bra{0}$, in our model), whose state is known \cite[p.~2, l.~8-9 \& 30-33]{Ferraro}. Changing the variables $\hat{A}\to\hat{\sigma}_z$, $0\to g_0$, $1\to g_1$, $2\to p_1$, $3\to 1$ and $\hat{U}=\hat{U}_{C_{NOT}}$ \cite[p.~3, l.~38-40]{Ferraro} we recover our cloning protocol, Eq. (\ref{preservation_condition}), and equality $({\color{purple}1})$ [$({\color{orange}2})$] represents the {\color{purple}genotype creation} (\ref{genotype_replication}) [{\color{orange}phenotype creation} (\ref{phenotype_creation})] of Fig. \ref{fig:Self_replication}.\\


\subsection{Controlled-NOT or CNOT quantum logic gate ($\hat{U}_{C_{NOT}}$)} \label{U_CNOT_theory_Appendix}

The \emph{controlled}-NOT or CNOT gate is the quintessential multi-qubit quantum logic gate. It has two input qubits: the first is \emph{control} qubit, and, the second, the \emph{target} \cite[p.~20, l.~28-29]{Nielsen}. The target qubit is flipped if the control qubit is 1. In the $\{\ket{0},\ket{1}\}\otimes\{\ket{0},\ket{1}\}=\{\ket{00},\ket{01},\ket{10},\ket{11}\}$ basis,
$$\hat{U}_{C_{NOT}}\ket{00}\doteq \begin{pmatrix} \hat{1}_2 & \\ &\hat{\sigma}_x \end{pmatrix}\begin{pmatrix} 1\\0\end{pmatrix}\otimes\begin{pmatrix} 1\\0\end{pmatrix} =
\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\begin{pmatrix}1\\0\\0\\0\end{pmatrix}=\begin{pmatrix}1\\0\\0\\0\end{pmatrix}\doteq\ket{00}\,\textrm{,}$$
$$\textrm{and, in the same manner:}\quad\hat{U}_{C_{NOT}}\ket{01}=\ket{01}\textrm{,}\quad\hat{U}_{C_{NOT}}\ket{10}=\ket{11}\textrm{, and}\quad\hat{U}_{C_{NOT}}\ket{11}=\ket{10}\,\textrm{.}$$

In the matrix form of quantum logic gates, the rows (columns) correspond to input (output) basis vectors. Id est, the $(i,j)$ entry gives the coefficient of the $j$th basis vector in the corresponding output of the gate, when the $i$th basis vector is input.

Requiring state transformations to be represented by unitary matrices ensures that summing the probability over all possible outcomes yields 1 for any time $t$. Moreover, the definition of quantum circuits allows only \emph{local} unitary operators, that is, unitary matrices which act on a restricted number of qubits. \cite[p.~6, l.~11-12]{Shor} \cite[p.~88, l.~1]{Deutsch}

Experimentally, $2$-qubit gates $\hat{U}_{ij}$ perform a unitary transformation $\hat{U}_j$ on the $j$th target physical subsystem conditioned upon the state $\Lambda_i=\ket{i}\bra{i}$ of the $i$th control subsystem: $\hat{U}_{ij}=\sum_{i,j}\,\Lambda_i\otimes\hat{U}_j$. The simplest operation of this sort is the CNOT gate: $\hat{U}_{C_{NOT}}\equiv\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x$.\\

If we consider the CNOT gate as the quantum analog of the classical XOR gate, in the sense that both input qubits are \emph{XOR}ed and stored in the output target qubit, its action can be summarized as $\hat{U}_{C_{NOT}}\ket{x,y}=\ket{x,x\oplus y}$, where $\oplus$ is addition modulo 2 $\,\,\,$  \cite[p.~22, Eq.~(1.18)]{Nielsen}: $a\oplus b=b\oplus a$, $a\oplus b \oplus a=b$ and $a\oplus b \oplus b=a$. In this case, $a=0$ and $b=1$ or vice versa. Thus, $0\oplus 1=1\oplus 0=1$, $0\oplus 1\oplus 0=1$ and $1\oplus 0\oplus 1=1\oplus 1=0$. 

The CNOT is a two-qubit entangling gate, and can also be considered a \emph{non-perturbing measurement gate}, in the sense that, if the target qubit is zero, it performs a perfectly accurate measurement of the control qubit. \cite[p.~75, l.~12-14]{Deutsch}

\begin{figure}[H] 
	\centering
	\includegraphics[scale=0.10]{Images/CNOT.png}
	\caption{schematic representation of CNOT gate. The control qubit is indicated by the line with the black dot.}
	  \label{fig:CNOT}
\end{figure}
As we stated for the single qubit case, $\hat{U}_{C_{NOT}}$ is unitary. In fact, unitarity is the requirement that the norm of the vectors (single qubits) in the Bloch sphere be preserved --i.e., unitary matrices leave the length of a complex vector unchanged \cite[l.~4]{Unitary Matrix}--  and then the probability is conserved \cite[p.~21, l.~12]{Nielsen}. On top of this, because of the fact that the inverse of a unitary matrix is also a unitary matrix, unitary matrices --unitary quantum gates, here--  are \emph{always} invertible \cite[l.~10]{Unitary Matrix}. That is, a quantum gate can always be inverted by another quantum gate \cite[p.~21, l.~21-23]{Nielsen}. In this sense, quantum logic gates are \emph{reversible} because, given the output, the input is uniquely determined and can be recovered, no information is ever erased during the computation. Hence, we can say gates follow the laws of physics, since they are reversible \cite[p.~8, l.~5-6]{Shor}, with the possible exception of quantum measurements that collapse the wave function to the eigenket of the output observable \cite[p.~157, l.~1-2]{Nielsen}.



\subsection{Partial quantum cloning} \label{partial_quantum_cloning}

	It consists in the copy of partial quantum information of a quantum state from a given arbitrary one \cite[p.~1, l.~15-16]{Bio_Cloning}, using unitary measurements and unitary operations, but the copy ought to be obtained in a different physical register. Quantum mechanics forbids \emph{perfect} cloning (\ref{No-cloning theorem}), but permits solutions for partial cloning. Here, what is copied is not the whole state, but the expectation value of a set of observables that commute.\\
	
	An interesting example is the cloning of the statistics related to observables \cite{Ferraro}. Nevertheless, it is not possible to clone noncommuting observables with the same unitary operator.\\

In the presented model, partial quantum cloning, which, as mentioned, does not contradict the no-cloning theorem (\ref{No-cloning theorem}), is used as a \emph{self-replication} protocol, stablishing a powerful simile with what happens in biological systems. For instance, in DNA replication, information is not perfectly duplicated into the following generations, only sequences of bases are copied. \cite[p.~1, l.~25-28]{Bio_Cloning}\\

\noindent
{\color{red} \rule{\linewidth}{0.5mm} }
BESTE LEKU BATEAN JARTZEKO
\begin{itemize}
\item Random rotations in the qubit in which genotype is encoded are used to simulate \emph{mutations}.
\item \emph{interactions} among artificial living entities are controlled operations that involve 2 individuals (4 qubits).
\end{itemize}
\noindent
{\color{red} \rule{\linewidth}{0.5mm} }

\newpage

\section{\normalfont{Calculations}}

\subsection{Density operator ($\hat{\rho}$) approach \normalfont{for Eq. (\ref{Pr._alive}-\ref{Pr._dead})}} \label{density_operator_approach}
In order to calculate Eq. (\ref{Pr._alive}-\ref{Pr._dead}), we could have also used the \emph{density operator}, the sum over pure states $\hat{\rho}\equiv\sum_iw_i\ket{\alpha^{(i)}}\bra{\alpha^{(i)}}$  $\,\,\,$   \cite[p.~181, Eq.~(3.4.7)]{Sakurai}, where $w_i$ is the weight or probabilistic distribution with $\sum_i\,w_i=1$. We are in a \emph{pure ensemble}, a collection of identically prepared physical systems, on which a great number of measurements are to be performed in order to determine Eq. (\ref{Pr._alive}-\ref{Pr._dead}), all characterized by the same ket $\ket{\alpha}$ $\,\,\,$ \cite[p.~24, l.~12-15]{Sakurai}. Then, $w_i=1$ for $i=n$ and $w_i=0$ for all other conceivable state kets. Thus, the density operator corresponding to a pure state such as ours can written as $\hat{\rho}=\ket{\alpha^{(n)}}\bra{\alpha^{(n)}}$  $\,\,\,$  \cite[p.~182, Eq.~(3.4.12)]{Sakurai}. In this particular case, $\ket{\alpha^{(n)}}=\ket{\psi}$ (Eq. (\ref{Eq.1})), and, in the $\{\ket{1},\ket{0}\}$ basis,
\begin{equation} \label{eq2.4}
\hat{\rho}=\ket{\psi}\bra{\psi}\doteq\begin{pmatrix} a \\ b \end{pmatrix}\begin{pmatrix} a^*&b^*  \end{pmatrix}=\begin{pmatrix} |a|^2&ab^* \\ a^*b&|b|^2 \end{pmatrix}\textrm{.}
\end{equation}

The density operator $\hat{\rho}$ must satisfy the following results: \cite[p.~134, Eq.~(4.2.23.1-3)]{Shankar} \cite[p.~101, Theo.~2.5]{Shankar}
\begin{enumerate}
\item The density operator $\hat{\rho}$ must be Hermitian: $\hat{\rho}=\hat{\rho}^\dagger$ $\leftrightarrow$ $\hat{\rho}^\dagger\doteq \begin{pmatrix} (|a|^2)^*&(ab^*)^* \\ (a^*b)^*&(|b|^2)^* \end{pmatrix}^T=\begin{pmatrix} |a|^2&a^*b \\ ab^*&|b|^2 \end{pmatrix}^T =\begin{pmatrix} |a|^2&ab^* \\ a^*b&|b|^2 \end{pmatrix}\doteq\hat{\rho}\textrm{,}$ where the adjoint (or conjugate transpose) is obtained by both transposing and complex conjugating \cite[p.~18, l.~28]{Nielsen}, and the conjugate and transpose operations commute ($(\hat{A}^*)^T=(\hat{A}^T)^*$).\\

Clearly, due to $\hat{\rho}$'s Hermiticity --in particular, all Hermitian and all unitary matrices are normal--, it is also \emph{normal}: it commutes with its Hermitian conjugate or, equivalently, $\hat{\rho}\hat{\rho}^\dagger=\hat{\rho}^\dagger\hat{\rho}$. From the \emph{spectral decomposition} theorem \cite[p.~72, Theo.~2.1]{Nielsen} we know that every normal operator is diagonalizable (its eigenvectors span the space). Let us consider that $\{\ket{j}\}$ is the just mentioned orthonormal basis. Therefore, the density operator can be represented as $\hat{\rho}=\sum_j\,\lambda_j\,\ket{j}\bra{j}$, where $\lambda_j$ are its real non-negative eigenvalues \cite[p.~101, Eq.~(2.157)]{Nielsen}. The latter is related to the following condition 3.

\item The normalization condition leads to: $\textrm{Tr}\hat{\rho}=1$. Proof: 

\begin{equation} \label{trace_normalization}
\begin{split}
\textrm{Tr}\hat{\rho}
&=\textrm{Tr}(\sum_iw_i\ket{\alpha^{(i)}}\bra{\alpha^{(i)}})\numeq{1}\sum_iw_i\,\textrm{Tr}(\ket{\alpha^{(i)}}\bra{\alpha^{(i)}})\numeq{2}\sum_iw_i\,\sum_j\braket{j|\alpha^{(i)}}\braket{\alpha^{(i)}|j}\\
&=\sum_iw_i\,\sum_j\braket{\alpha^{(i)}|j}\braket{j|\alpha^{(i)}}=\sum_iw_i\,\braket{\alpha^{(i)}|\hat{1}|\alpha^{(i)}}=\sum_iw_i\,\braket{\alpha^{(i)}|\alpha^{(i)}}=\sum_iw_i\numeq{3}1\,\textrm{,}
\end{split}
\end{equation}

where in ($1$) we used $\textrm{Tr}(\textrm{k}\hat{A})=\textrm{k}\,\textrm{Tr}(\hat{A})$ $\,\,\,$; in ($2$), $\textrm{Tr}(\hat{X})\equiv\sum_{a^\prime}\braket{a^\prime|\hat{X}|a^\prime}$ $\,\,\,$  \cite[p.~37, Eq.~(1.5.14)]{Sakurai}; and, in $(3)$, Ref. \cite[p.~108, Eq.~(3.4.5)]{Sakurai}.\\

In this instance,  $\textrm{Tr}\hat{\rho}\doteq \textrm{Tr}\begin{pmatrix} |a|^2&ab^* \\ a^*b&|b|^2 \end{pmatrix}=|a|^2+|b|^2=1$, where the last equality holds from the normalization condition of Eq. (\ref{Eq.1}).
\item The density operator $\hat{\rho}$ must have positive or null eigenvalues - or, equivalently, $\hat{\rho}$ ought to be a positive semidefinite matrix, $\hat{\rho}\geq 0$ -, so that (\emph{von Neumann}) \emph{entropy} $S(\hat{\rho})\equiv-\textrm{k}\,\textrm{Tr}(\hat{\rho}\,\textrm{ln}\hat{\rho})$ $\,\,\,$  \cite[p.~187, Eq.~(3.4.35-36) \& (3.4.41)]{Sakurai} can be defined, where $\textrm{k}$ is the Boltzmann constant. Proof:\\

For an arbitrary vector $\ket{\varphi}$,  $\,\,\,$ \cite[p.~191, Eq.~(2.156)]{Nielsen}
\begin{equation}
\braket{\varphi|\hat{\rho}|\varphi}=\braket{\varphi|(\sum_iw_i\ket{\alpha^{(i)}}\bra{\alpha^{(i)}})|\varphi}=\sum_iw_i\,\braket{\varphi|\alpha^{(i)}}\braket{\alpha^{(i)}|\varphi}=\sum_iw_i\,|\braket{\varphi|\alpha^{(i)}}|^2\geq 0
\end{equation}


We will prove that $\hat{\rho}$ is positive semidefinite ($\hat{\rho}\geq 0$) in this particular case; id est, that all its eigenvalues, $\lambda$, are non-negative:

$|\hat{\rho}-\lambda\hat{1}|=0=\begin{vmatrix} |a|^2-\lambda&ab^* \\ a^*b&|b|^2-\lambda \end{vmatrix}=(|a|^2-\lambda)(|b|^2-\lambda)-|a|^2|b|^2=|a|^2|b|^2-\lambda(|a|^2+|b|^2)+\lambda^2-|a|^2|b|^2=\lambda^2-\lambda=\lambda(\lambda-1)=0$ $\leftrightarrow$ $\lambda=0,1$ $\geq 0\,\,\,$ QED.\\

Concretely, if we use the basis in which $\hat{\rho}$ is diagonal,  $\,\,\,$  \cite[p.~187 Eq.~(3.4.36)]{Sakurai}, \footnote{In Information Theory, the expression in the diagonal basis is called the \emph{Shannon entropy}, with the log in base 2.}
\begin{equation} \label{Entropy}
S = -\textrm{k}\,\textrm{Tr}(\hat{\rho}\,\textrm{ln}\hat{\rho}) \doteq -k\,\sum_k \rho_{kk}^{\textrm{diag}}\,\textrm{ln}\rho_{kk}^{\textrm{diag}}\textrm{.}
\end{equation}

Recalling that the matrix representation is diagonal when its eigenfunctions are used as the base kets \cite[p.~22, l.~3-5 \& p.~36, l.~5-7]{Sakurai}, the diagonal elements in this basis are its eigenvalues $\lambda=0,1$: $\hat{\rho}\doteq\begin{pmatrix} 0& \\ &1 \end{pmatrix}$. Hence,

$S = -\textrm{k}\,\textrm{Tr}(\hat{\rho}\,\textrm{ln}\hat{\rho}) \doteq -k\,\sum_k \rho_{kk}^{\textrm{diag}}\,\textrm{ln}\rho_{kk}^{\textrm{diag}}=-k(0\ln(0)+1\ln(1))=-k(0+0)=0\textrm{,}$

as it should be for a pure ensemble \cite[p.~187, Eq.~(3.4.38)]{Sakurai}. As it can be seen, even though $\ln(0)$ diverges to $-\infty$, $0\ln(0)$ is well behaved. In general, $S\in[0,k\,\ln(d)]$, where $d$ is the dimension of the Hilbert space  $\,\,\,$  \cite[p.~187, Eq.~(3.4.37)]{Sakurai}. Simply stated, entropy is a measure of the disorder or mixedness: $S=0$ for pure states and $S=k\,\ln(d)$ for maximally mixed states of diagonal form $\hat{\rho}=\frac{\hat{1}_d}{d}$.



  
\item For a pure ensemble, the density operator $\hat{\rho}$ is idempotent; that is, $\hat{\rho}^2=\hat{\rho}$ $\,\,\,$ \cite[p.~182, Eq.~(3.4.13)]{Sakurai}. Thus, for a pure ensemble only, we have $\textrm{Tr}\hat{\rho}^2=\textrm{Tr}\hat{\rho}\numeq{\ref{trace_normalization}}1$, where the last equality follows from the normalization condition of Eq. (\ref{Eq.1}) $\,\,\,$  \cite[p.~182, Eq.~(3.4.15)]{Sakurai}. Proof:\\

 $\hat{\rho}^2\doteq \begin{pmatrix} |a|^2&ab^* \\ a^*b&|b|^2 \end{pmatrix}\begin{pmatrix} |a|^2&ab^* \\ a^*b&|b|^2 \end{pmatrix}=\begin{pmatrix} |a|^2(|a|^2+|b|^2)&ab^*(|a|^2+|b|^2) \\ a^*b(|a|^2+|b|^2)&|b|^2(|a|^2+|b|^2) \end{pmatrix}=\begin{pmatrix} |a|^2&ab^* \\ a^*b&|b|^2 \end{pmatrix}\doteq\hat{\rho}\,\textrm{.}$
\end{enumerate}

\vspace{0.5cm}

Then probability of measuring the cell as \emph{alive} or \emph{dead}, as we previously calculated in Eq. (\ref{Pr._alive}-\ref{Pr._dead}),
\begin{equation} \label{Pr._alive_with_rho}
\begin{split}
\textrm{Pr.}_{\ket{\psi}} (\ket{1}) & =\textrm{Pr.}_{\hat{\rho}}(\ket{1})\equiv \textrm{Tr}(\hat{\rho}\,\hat{\Lambda}_{\ket{1}}) = \textrm{Tr}(\hat{\rho}\,\ket{1}\bra{1}) \doteq \textrm{Tr}\left(\hat{\rho}\,\begin{pmatrix}1\\0\end{pmatrix}\begin{pmatrix}1&0\end{pmatrix}\right)\\
& =\textrm{Tr}\left(\begin{pmatrix} |a|^2&ab^* \\ a^*b&|b|^2 \end{pmatrix}\begin{pmatrix}1&0\\0&0\end{pmatrix}\right)=\textrm{Tr}\begin{pmatrix} |a|^2&0 \\ a^*b&0 \end{pmatrix}=|a|^2\,\textrm{,}
\end{split}
\end{equation}
\begin{equation} \label{Pr._dead_with_rho}
\begin{split}
\textrm{Pr.}_{\ket{\psi}} (\ket{0}) & =\textrm{Pr.}_{\hat{\rho}}(\ket{0})\equiv \textrm{Tr}(\hat{\rho}\,\hat{\Lambda}_{\ket{0}}) = \textrm{Tr}(\hat{\rho}\,\ket{0}\bra{0}) \doteq \textrm{Tr}\left(\hat{\rho}\,\begin{pmatrix}0\\1\end{pmatrix}\begin{pmatrix}0&1\end{pmatrix}\right)\\
& =\textrm{Tr}\left(\begin{pmatrix} |a|^2&ab^* \\ a^*b&|b|^2 \end{pmatrix}\begin{pmatrix}0&0\\0&1\end{pmatrix}\right)=\textrm{Tr}\begin{pmatrix} 0&ab^* \\ 0&|b|^2 \end{pmatrix}=|b|^2\,\textrm{,}
\end{split}
\end{equation}

where $\hat{\Lambda}_{\ket{\phi}}\equiv\ket{\phi}\bra{\phi}$ is the \emph{projection operator} along the ket $\ket{\phi}$, which selects that portion of the ket $\ket{\psi}$ (from $\hat{\rho}=\ket{\psi}\bra{\psi}$) parallel to $\ket{\phi}$  $\,\,\,$ \cite[p.~19, Eq.~(1.3.15)]{Sakurai}. Moreover, the probability ($\textrm{Pr.}$) of measuring a general ensemble (mixed or pure), characterized by the density operator $\hat{\rho}$, in the state $\phi$ is defined in terms of the projection operator $\hat{\Lambda}$ as $\textrm{Pr.}_{\hat{\rho}}(\ket{\phi})\equiv \textrm{Tr}(\hat{\rho}\,\hat{\Lambda}_{\ket{\phi}})$ $\,\,\,$  \cite[p.~134, l.~4]{Shankar}\cite[p.~102, Eq.~(2.159)]{Nielsen}.


\subsection{General density operator properties of $\hat{\rho}_g$}  \label{rho_g_properties}

We will verify that Eq. (\ref{AL_in_QT_Eq_3a}) obeys the properties of the $\hat{\rho}$ density operators \cite[p.~134, Eq.~(4.2.23.1-3)]{Shankar}, previously satisfied by Eq. (\ref{eq2.4}):

\begin{enumerate}
\item The density operator $\hat{\rho}$ must be Hermitian: $\hat{\rho}=\hat{\rho}^\dagger$ $\leftrightarrow$ $\hat{\rho}_g^\dagger\doteq \begin{pmatrix} (a)^*&(b-ic)^* \\ (b+ic)^*&(1-a)^* \end{pmatrix}^T=\begin{pmatrix} a^*&b^*+ic^* \\ b^*-ic^*&1-a^* \end{pmatrix}^T =\begin{pmatrix} a^*&b^*-ic^* \\ b^*+ic^*&1-a^* \end{pmatrix}\doteq\hat{\rho}_g$ $\leftrightarrow$ $a,b,c\in\mathbb{R}$, so that $(a^*,b^*,c^*)=(a,b,c)$. 
\item From the normalization condition: $\textrm{Tr}\hat{\rho}=1$ $\leftrightarrow$  $\textrm{Tr}\hat{\rho}_g\doteq \textrm{Tr}\begin{pmatrix}a&b-ic\\b+ic&1-a\end{pmatrix}=a+1-a=1$ .
\item The density operator $\hat{\rho}$ must have positive or null eigenvalues - or, equivalently, $\hat{\rho}$ must be a positive semidefinite matrix, $\hat{\rho}\geq 0$:\\

$|\hat{\rho}_g-\lambda\hat{1}|=0=\begin{vmatrix} a-\lambda&b-ic \\ b+ic&1-a-\lambda \end{vmatrix}=(a-\lambda)(1-a-\lambda)-(b+ic)(b-ic)=a-a^2-a\lambda-\lambda+a\lambda+\lambda^2-b^2-c^2=\lambda^2-\lambda+a(1-a)-(b^2+c^2)$ $\rightarrow$ $\lambda=\frac{1}{2}(1\pm\sqrt{1+4(a(a-1)+b^2+c^2)})$ $\geq 0\,\,\,$ .\\
\end{enumerate}


\vspace{1cm}
\subsection{\normalfont{Why $\hat{U}=\hat{U}_{C_{NOT}}$ in the partial quantum cloning operation, in order to preserve $\hat{\sigma}_z$?}}   \label{why_U_CNOT_proof}

We will derive that, if the observable whose expectation value we want to preserve is $\hat{\sigma}_z$, then $\hat{U}=\hat{U}_{C_{NOT}}$ in Eq. (\ref{rho_old_to_new}).

Let us suppose we have a unitary operator of the following form, in the $\{ \ket{0}, \ket{1} \}$ basis:
\begin{equation} \label{general_copying_unitary_op}
\hat{U}\doteq \begin{pmatrix} A&e&f&g\\ e^*&B&h&i\\ f^*&h^*&C&j\\ g^*&i^*&j^*&d\end{pmatrix}\quad :\,A,B,C,d\in\mathbb{R}\,\textrm{.}
\end{equation}




 For $\hat{\rho}_{g_0}=(\ref{AL_in_QT_Eq_3a})$, $\braket{\hat{\sigma}_z}_{g_0} \numeq{\textrm{\ref{sigma_z}}} 2a-1$. We want Eq. (\ref{preservation_condition}) to be satisfied. Then, 

\begin{equation} \label{3_2_satisfied}
\begin{cases}
\braket{\hat{\sigma}_z\otimes\hat{1}_2}_{\hat{\rho}_1}
 =2a-1\\
 \braket{\hat{1}_2\otimes\hat{\sigma}_z}_{\hat{\rho}_1}
 =2a-1
\end{cases}
\end{equation}
where
\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}}
% https://tex.stackexchange.com/questions/43065/matrices-too-big-to-fit-the-width-of-a-page

\newenvironment{mpmatrix}{\begin{medsize}\begin{pmatrix}}%
{\end{pmatrix}\end{medsize}}%
% https://tex.stackexchange.com/questions/166378/big-matrix-in-latex
\begin{equation} \label{hypothesis_U}
\begin{split}
&\hat{\rho}_{1}=\hat{U}\,(\hat{\rho}_{g_0}\otimes\hat{\rho}_A)\,\hat{U}^\dagger\numeq{\textrm{\ref{rho_0_Appendix}-\ref{general_copying_unitary_op}}} \hat{U}\begin{pmatrix}a&0&b-ic&0\\0&0&0&0\\b+ic&0&1-a&0\\0&0&0&0\end{pmatrix}  \begin{pmatrix} A&e&f&g\\ e^*&B&h&i\\ f^*&h^*&C&j\\ g^*&i^*&j^*&d\end{pmatrix}\\
&=\begin{pmatrix}
      A&e&f&g\\
       e^*&B&h&i\\
        f^*&h^*&C&j\\
         g^*&i^*&j^*&D
  \end{pmatrix} \begin{mpmatrix} aA+f^*(b-ic)&ae+h^*(b-ic)&af+C(b-ic)&ag+j(b-ic)\\ 0&0&0&0\\ A(b+ic)+f^*(1-a)&e(b+ic)+h^*(1-a)&f(b+ic)+C(1-a)&g(b+ic)+j(1-a)\\ 0&0&0&0\end{mpmatrix}\\
&= \left(
    \scalemath{0.5}{
    \begin{array}{cccc}
     aA^2+2A\textrm{Re}(f(b+ic))+|f|^2(1-a)\textrm{;}\,&Aae+Ah^*(b-ic)+ef(b+ic)+fh^*(1-a)\textrm{;}\,&Aaf+AC(b-ic)+f^2(b+ic)+fC(1-a)\textrm{;}\,&Aag+Aj(b-ic)+fg(b+ic)+fj(1-a)\textrm{;}\,\\
      e^*aA+e^*f^*(b-ic)+hA(b+ic)+hf^*(1-a)\textrm{;}\,&a|e|^2+2Re(he(b+ic))+|h|^2(1-a)\textrm{;}\,&e^*af+e^*C(b-ic)+hf(b+ic)+hC(1-a)\textrm{;}\,&e^*ag+e^*j(b-ic)+hg(b+ic)+hj(1-a)\textrm{;}\,\\
      f^*aA+(f^*)^2(b-ic)+CA(b+ic)+Cf^*(1-a)\textrm{;}\,&f^*ae+f^*h^*(b-ic)+Ce(b+ic)+Ch^*(1-a)\textrm{;}\,&a|f|^2+2C\textrm{Re}(f(b+ic))+C^2(1-a)\textrm{;}\,&f^*ag+f^*j(b-ic)+Cg(b+ic)+Cj(1-a)\textrm{;}\,\\
        g^*aA+g^*f^*(b-ic)+j^*A(b+ic)+j^*f^*(1-a)\textrm{;}\,&g^*ae+g^*h^*(b-ic)+j^*e(b+ic)+j^*h^*(1-a)\textrm{;}\,&g^*af+g^*C(b-ic)+j^*f(b+ic)+j^*C(1-a)\textrm{;}\,&a|g|^2+2\textrm{Re}(gj^*(b+ic))+|j|^2(1-a)\textrm{;}\,
     \end{array}
    }
  \right)\\
\end{split}
\end{equation}\\

\noindent $\bullet$ Normalization condition for density operators, $\textrm{Tr}\,\hat{\rho}_1 = 1$, is obeyed if, and only if,
\begin{equation} \label{Tr_rho1_hypothe}
\begin{split}
1
&=\left[aA^2+2A\textrm{Re}(f(b+ic))+|f|^2(1-a)\right] + \left[a|e|^2+2Re(he(b+ic))+|h|^2(1-a)\right]\\
&	+  \left[a|f|^2+2C\textrm{Re}(f(b+ic))+C^2(1-a)\right] +\left[a|g|^2+2\textrm{Re}(gj^*(b+ic))+|j|^2(1-a)\right]
\end{split}
\end{equation}

\noindent $\bullet$ From Eq. (\ref{3_2_satisfied}a),
\begin{equation}  \label{2a-1_hypothesis_1}
\begin{split}
2a-1
&	=\braket{\hat{\sigma}_z\otimes\hat{1}_2}_{\hat{\rho}_1} =   \textrm{Tr}\left(\hat{\rho}_1\begin{pmatrix}1&&&\\ &1&&\\ &&-1&\\ &&&-1\end{pmatrix} \right)\\
&	\numeq{1} \left[aA^2+2A\textrm{Re}(f(b+ic))+|f|^2(1-a)\right] + \left[a|e|^2+2Re(he(b+ic))+|h|^2(1-a)\right]\\
&	-  \left[a|f|^2+2C\textrm{Re}(f(b+ic))+C^2(1-a)\right] -\left[a|g|^2+2\textrm{Re}(gj^*(b+ic))+|j|^2(1-a)\right]\\
&	\numeq{\textrm{\ref{Tr_rho1_hypothe}}} 2\left[aA^2+2A\textrm{Re}(f(b+ic))+|f|^2(1-a)\right] + 2\left[a|e|^2+2Re(he(b+ic))+|h|^2(1-a)\right] -1\\
&	\leftrightarrow a= \left[aA^2+2A\textrm{Re}(f(b+ic))+|f|^2(1-a)\right] + \left[a|e|^2+2Re(he(b+ic))+|h|^2(1-a)\right]\,.
\end{split}
\end{equation}
where in $(1)$ we used Eq. (\ref{hypothesis_U}) and the fact that we are only interested in its diagonal elements. This is because multiplying by $\hat{\sigma}_z\otimes\hat{1}_2$ just makes Eq. (\ref{hypothesis_U}) change in sign and we are evaluating the trace, the sum of the diagonal elements, of this matrix product.\\

\noindent $\bullet$ From Eq. (\ref{3_2_satisfied}b),
\begin{equation} \label{2a-1_hypothesis_2}
\begin{split}
2a-1
&	=\braket{\hat{1}_2\otimes\hat{\sigma}_z}_{\hat{\rho}_1} =   \textrm{Tr}\left(\hat{\rho}_1\begin{pmatrix}1&&&\\ &-1&&\\ &&1&\\ &&&-1\end{pmatrix} \right)\\
&	\numeq{\textrm{\ref{hypothesis_U}}} \left[aA^2+2A\textrm{Re}(f(b+ic))+|f|^2(1-a)\right] - \left[a|e|^2+2Re(he(b+ic))+|h|^2(1-a)\right]\\
&	+\left[a|f|^2+2C\textrm{Re}(f(b+ic))+C^2(1-a)\right] -\left[a|g|^2+2\textrm{Re}(gj^*(b+ic))+|j|^2(1-a)\right]\\
&	\numeq{\textrm{\ref{Tr_rho1_hypothe}}} 2\left[aA^2+2A\textrm{Re}(f(b+ic))+|f|^2(1-a)\right] +2\left[a|f|^2+2C\textrm{Re}(f(b+ic))+C^2(1-a)\right]-1\\
&	\leftrightarrow a=\left[aA^2+2A\textrm{Re}(f(b+ic))+|f|^2(1-a)\right] +\left[a|f|^2+2C\textrm{Re}(f(b+ic))+C^2(1-a)\right]
\end{split} 
\end{equation}

\noindent $\bullet$ $(\textrm{\ref{2a-1_hypothesis_1}}) - (\textrm{\ref{2a-1_hypothesis_2}}) = a-a = 0 = \left[a|e|^2+2Re(he(b+ic))+|h|^2(1-a)\right] - \left[a|f|^2+2C\textrm{Re}(f(b+ic))+C^2(1-a)\right]$. Then, Eq. (\ref{Tr_rho1_hypothe}), 
\begin{equation}
\begin{split}
1
&=\left[aA^2+2A\textrm{Re}(f(b+ic))+|f|^2(1-a)\right] + 2\left[a|e|^2+2Re(he(b+ic))+|h|^2(1-a)\right]\\
&	+\left[a|g|^2+2\textrm{Re}(gj^*(b+ic))+|j|^2(1-a)\right] \,\,\leftrightarrow\,\, e,f,g,h=0\textrm{ (to remove $b,c$) and } A=j=1
\end{split}
\end{equation}
Now, from Eq. (\ref{2a-1_hypothesis_2}), $a=a-C^2(1-a)\,\,\leftrightarrow\,\, C=0$.\\

Hence, Eq. (\ref{general_copying_unitary_op}), 
\begin{equation} \label{U_CNOT_proof}
\hat{U}\doteq \begin{pmatrix} A&e&f&g\\ e^*&B&h&i\\ f^*&h^*&C&j\\ g^*&i^*&j^*&d\end{pmatrix}=\begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix}\equiv \hat{U}_{C_{NOT}}
\end{equation}





\vspace{1cm}
\subsection{\normalfont{Calculations of $\hat{\rho}_{g_1}$, Eq. (\ref{rho_0}), and $\hat{U}_{C_{NOT}}$, Eq. (\ref{U_CNOT}).}}  \label{rho_0_and_U_CNOT}

\begin{equation} \label{rho_0_Appendix}
\begin{split}
\hat{\rho}_{g_1}
&\equiv\hat{U}(\hat{\rho}_{g_0}\otimes\hat{\rho}_A)\hat{U}^\dagger=\hat{U}(\hat{\rho}_{g_0}\otimes\ket{0}\bra{0})\hat{U}^\dagger\doteq\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\left(\begin{pmatrix}a&b-ic\\b+ic&1-a\end{pmatrix}\otimes\begin{pmatrix}1&0\\0&0\end{pmatrix}\right)\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}^T\\
&=\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\begin{pmatrix}a\begin{pmatrix}1&0\\0&0\end{pmatrix}&(b-ic)\begin{pmatrix}1&0\\0&0\end{pmatrix}\\(b+ic)\begin{pmatrix}1&0\\0&0\end{pmatrix}&(1-a)\begin{pmatrix}1&0\\0&0\end{pmatrix}\end{pmatrix}\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\\
&=\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\begin{pmatrix}a&0&b-ic&0\\0&0&0&0\\b+ic&0&1-a&0\\0&0&0&0\end{pmatrix}\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}=\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\b+ic&0&0&1-a\\0&0&0&0\end{pmatrix}\\
&=\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}
\,\textrm{,}\end{split}
\end{equation}
\begin{equation} \label{U_CNOT_Appendix}
\begin{split}
\hat{U}
&\numeq{\textrm{\ref{why_U_CNOT2}}}\hat{U}_{C_{NOT}}\equiv\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x\doteq \begin{pmatrix}1&0\\0&0\end{pmatrix}\otimes\begin{pmatrix}1&0\\0&1\end{pmatrix}+\begin{pmatrix}0&0\\0&1\end{pmatrix}\otimes\begin{pmatrix}0&1\\1&0\end{pmatrix} \\
&=\begin{pmatrix}1\begin{pmatrix}1&0\\0&1\end{pmatrix}&0\begin{pmatrix}1&0\\0&1\end{pmatrix}\\0\begin{pmatrix}1&0\\0&1\end{pmatrix}&0\begin{pmatrix}1&0\\0&1\end{pmatrix}\end{pmatrix}+\begin{pmatrix}0\begin{pmatrix}0&1\\1&0\end{pmatrix}&0\begin{pmatrix}0&1\\1&0\end{pmatrix}\\0\begin{pmatrix}0&1\\1&0\end{pmatrix}&1\begin{pmatrix}0&1\\1&0\end{pmatrix}\end{pmatrix}=\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&0\\0&0&0&0\end{pmatrix}+\begin{pmatrix}0&0&0&0\\0&0&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\\
&=\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\,\textrm{.}
\end{split}
\end{equation}
where the partial cloning operation for the two qubits implied is the CNOT gate ($\hat{U}=\hat{U}_{C_{NOT}}$) because of Appendix \ref{why_U_CNOT_proof}.






\vspace{1cm}
\subsection{\normalfont{Calculations of Eq. (\ref{sigmaz_otimes_one}-\ref{sigmay_otimes_one})}} \label{sigma_otimes_one_appendix}

\begin{equation} \label{sigmaz_otimes_one_appendix}
\begin{split}
 \bullet\,\,\braket{\hat{\sigma}_z}_{g_1}
 &= \braket{ \left(\hat{\sigma}_z\right)_{g_1}\otimes \hat{1}_{p_0}}_{\hat{\rho}_1} \equiv\braket{\hat{\sigma}_z\otimes\hat{1}_2}_{\hat{\rho}_1}=\textrm{Tr}(\hat{\rho}_{1}(\hat{\sigma}_z\otimes\hat{1}_2))\doteq \textrm{Tr}\begin{pmatrix}\hat{\rho}_{1}\begin{pmatrix}\begin{pmatrix}1&0\\0&-1\end{pmatrix}\otimes\begin{pmatrix}1&0\\0&1\end{pmatrix}\end{pmatrix}\end{pmatrix}\\
 &=\textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&-1&0\\0&0&0&-1\end{pmatrix}\end{pmatrix}=\textrm{Tr}\begin{pmatrix}a&0&0&ic-b\\0&0&0&0\\0&0&0&0\\b+ic&0&0&a-1\end{pmatrix}=2a-1\,\textrm{.}
\end{split}
\end{equation}
\begin{equation} \label{sigmaz_otimes_one_appendix2}
\begin{split}
 \bullet\,\,\braket{\hat{\sigma}_z}_{p_0}(t_0)
 &=\braket{\hat{1}_{g_1}\otimes\left(\hat{\sigma}_z\right)_{p_0}}_{\hat{\rho}_1} \equiv\braket{\hat{1}_2\otimes\hat{\sigma}_z}_{\hat{\rho}_1}=\textrm{Tr}(\hat{\rho}_{1}(\hat{1}_2\otimes\hat{\sigma}_z))\doteq \textrm{Tr}\begin{pmatrix}\hat{\rho}_{1}\begin{pmatrix}\begin{pmatrix}1&0\\0&1\end{pmatrix}\otimes\begin{pmatrix}1&0\\0&-1\end{pmatrix}\end{pmatrix}\end{pmatrix}\\
 &=\textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}\begin{pmatrix}1&0&0&0\\0&-1&0&0\\0&0&1&0\\0&0&0&-1\end{pmatrix}\end{pmatrix}=\textrm{Tr}\begin{pmatrix}a&0&0&ic-b\\0&0&0&0\\0&0&0&0\\b+ic&0&0&a-1\end{pmatrix}=2a-1\,\textrm{.}
\end{split}
\end{equation}
\begin{equation} \label{sigmax_otimes_one_appendix}
\begin{split}
 \bullet\,\,\braket{\hat{\sigma}_x}_{g_1}
 &= \braket{ \left(\hat{\sigma}_x\right)_{g_1}\otimes \hat{1}_{p_0}}_{\hat{\rho}_1} \equiv\braket{\hat{\sigma}_x\otimes\hat{1}_2}_{\hat{\rho}_1}=\textrm{Tr}(\hat{\rho}_{1}(\hat{\sigma}_x\otimes\hat{1}_2))\doteq \textrm{Tr}\begin{pmatrix}\hat{\rho}_{1}\begin{pmatrix}\begin{pmatrix}0&1\\1&0\end{pmatrix}\otimes\begin{pmatrix}1&0\\0&1\end{pmatrix}\end{pmatrix}\end{pmatrix}\\
 &=\textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}\begin{pmatrix}0&0&1&0\\0&0&0&1\\1&0&0&0\\0&1&0&0\end{pmatrix}\end{pmatrix}=\textrm{Tr}\begin{pmatrix}0&b-ic&a&0\\0&0&0&0\\0&0&0&0\\0&1-a&b+ic&0\end{pmatrix}=0\,\textrm{.}
\end{split} 
\end{equation}
\begin{equation} \label{sigmax_otimes_one_appendix2}
\begin{split}
 \bullet\,\,\braket{\hat{\sigma}_x}_{p_0}(t_0)
 &=\braket{\hat{1}_{g_1}\otimes\left(\hat{\sigma}_x\right)_{p_0}}_{\hat{\rho}_1} \equiv\braket{\hat{1}_2\otimes\hat{\sigma}_x}_{\hat{\rho}_1}=\textrm{Tr}(\hat{\rho}_{1}(\hat{1}_2\otimes\hat{\sigma}_x))\doteq \textrm{Tr}\begin{pmatrix}\hat{\rho}_{1}\begin{pmatrix}\begin{pmatrix}1&0\\0&1\end{pmatrix}\otimes\begin{pmatrix}0&1\\1&0\end{pmatrix}\end{pmatrix}\end{pmatrix}\\
 &=\textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}\begin{pmatrix}0&1&0&0\\1&0&0&0\\0&0&0&1\\0&0&1&0\end{pmatrix}\end{pmatrix}=\textrm{Tr}\begin{pmatrix}0&a&b-ic&0\\0&0&0&0\\0&0&0&0\\0&b+ic&1-a&0\end{pmatrix}=0\,\textrm{.}
\end{split}
\end{equation}
\begin{equation} \label{sigmay_otimes_one_appendix}
\begin{split}
 \bullet\,\,\braket{\hat{\sigma}_y}_{g_1}
 &= \braket{ \left(\hat{\sigma}_y\right)_{g_1}\otimes \hat{1}_{p_0}}_{\hat{\rho}_1} \equiv\braket{\hat{\sigma}_y\otimes\hat{1}_2}_{\hat{\rho}_1}=\textrm{Tr}(\hat{\rho}_{1}(\hat{\sigma}_y\otimes\hat{1}_2))\doteq \textrm{Tr}\begin{pmatrix}\hat{\rho}_{1}\begin{pmatrix}\begin{pmatrix}0&-i\\i&0\end{pmatrix}\otimes\begin{pmatrix}1&0\\0&1\end{pmatrix}\end{pmatrix}\end{pmatrix}\\
 &=\textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}\begin{pmatrix}0&0&-i&0\\0&0&0&-i\\i&0&0&0\\0&i&0&0\end{pmatrix}\end{pmatrix}=\textrm{Tr}\begin{pmatrix}0&c+ib&-ai&0\\0&0&0&0\\0&0&0&0\\0&i-ai&c-ib&0\end{pmatrix}=0\,\textrm{.}
\end{split}
\end{equation}
\begin{equation} \label{sigmay_otimes_one_appendix2}
\begin{split}
 \bullet\,\,\braket{\hat{\sigma}_y}_{p_0}(t_0)
 &=\braket{\hat{1}_{g_1}\otimes\left(\hat{\sigma}_y\right)_{p_0}}_{\hat{\rho}_1} \equiv\braket{\hat{1}_2\otimes\hat{\sigma}_y}_{\hat{\rho}_1}=\textrm{Tr}(\hat{\rho}_{1}(\hat{1}_2\otimes\hat{\sigma}_y))\doteq \textrm{Tr}\begin{pmatrix}\hat{\rho}_{1}\begin{pmatrix}\begin{pmatrix}1&0\\0&1\end{pmatrix}\otimes\begin{pmatrix}0&-i\\i&0\end{pmatrix}\end{pmatrix}\end{pmatrix}\\
 &=\textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}\begin{pmatrix}0&-i&0&0\\i&0&0&0\\0&0&0&-i\\0&0&i&0\end{pmatrix}\end{pmatrix}=\textrm{Tr}\begin{pmatrix}0&-ai&c+ib&0\\0&0&0&0\\0&0&0&0\\0&c-ib&i-ai&0\end{pmatrix}=0\,\textrm{.}
\end{split}
\end{equation}

\vspace{1cm}
\subsection{\normalfont{Calculations of $\hat{\rho}_{p_1}(t)$, Eq. (\ref{rho_1_lindblad}).}} \label{lindbladian_calculations}
Here, we use $\hat{\sigma}=\hat{1}_2\otimes\ket{0}\bra{1}$ instead of $\hat{\sigma}=\ket{0}\bra{1}$ in Eq. (\ref{rho_1_lindblad}) in order to act just on the second subspace, on the phenotype qubit. This is because, stated in a general form, $(\hat{A}\otimes\hat{B})(\hat{C}\otimes\hat{D})=(\hat{A}\hat{C})\otimes(\hat{B}\hat{D})$. Then, we define $\hat{\mathcal{O}}_A\otimes\hat{1}_B$ ($\hat{1}_A\otimes\hat{\mathcal{O}}_B$) as an operator which acts only on subspace $A$ ($B$). In spite of dropping the superindex to avoid cumbersome notation, rigurously $\hat{\sigma}=\hat{1}_2\otimes\ket{0}\bra{1}$ would be $\hat{\sigma}^p$, where $p$ denotes that it acts on the phenotype subspace.
\begin{equation}
\hat{\sigma}=\hat{1}_2\otimes\ket{0}\bra{1}\doteq \begin{pmatrix}1&0\\0&1\end{pmatrix}\otimes\begin{pmatrix}0&1\\0&0\end{pmatrix}=\begin{pmatrix}1\begin{pmatrix}0&1\\0&0\end{pmatrix}&0\begin{pmatrix}0&1\\0&0\end{pmatrix}\\0\begin{pmatrix}0&1\\0&0\end{pmatrix}&1\begin{pmatrix}0&1\\0&0\end{pmatrix}\end{pmatrix}=\begin{pmatrix}0&1&&\\0&0&&\\&&0&1\\&&0&0\end{pmatrix}\,\textrm{,}
\end{equation}
\begin{equation} \label{sigma_dagger}
\textrm{and}\quad\hat{\sigma}^\dagger=(\hat{1}_2\otimes\ket{0}\bra{1})^\dagger\numeq{\textrm{1}}(\hat{1}_2)^\dagger\otimes(\ket{0}\bra{1})^\dagger\numeq{\textrm{2}}\,\hat{1}_2\otimes\ket{1}\bra{0}\doteq \begin{pmatrix}1&0\\0&1\end{pmatrix}\otimes\begin{pmatrix}0&0\\1&0\end{pmatrix}=\begin{pmatrix}0&0&&\\1&0&&\\&&0&0\\&&1&0\end{pmatrix}\,\textrm{,}
\end{equation}
where in equality (\ref{sigma_dagger}(1)) we used Ref. \cite[p.~74, Eq.~(2.53)]{Nielsen}: $(\hat{A}\otimes\hat{B})^T=\hat{A}^T\otimes\hat{B}^T$, and $(\hat{A}+\hat{B})^*=\hat{A}^*\otimes\hat{B}^*$. Therefore, since $\hat{A}^\dagger\equiv(\hat{A}^*)^T\equiv(\hat{A}^T)^*$, $(\hat{A}+\hat{B})^\dagger=\hat{A}^\dagger\otimes\hat{B}^\dagger$. We additionally used, in equality (\ref{sigma_dagger}(2)),  $(\hat{1}_2)^\dagger\doteq\begin{pmatrix}1&0\\0&1\end{pmatrix}^\dagger=\begin{pmatrix}1&0\\0&1\end{pmatrix}\doteq\hat{1}_2$. Then, 

\begin{equation} \label{lindblad_calc}
\begin{split}
\hat{\dot{\rho}}_{p_0}
&=\lambda\left(\hat{\sigma}\hat{\rho}_{p_0}\hat{\sigma}^\dagger - \frac{1}{2}\hat{\sigma}^\dagger \hat{\sigma}\hat{\rho}_{p_0}-\frac{1}{2}\hat{\rho}_{p_0}\hat{\sigma}^\dagger\hat{\sigma}\right)\doteq \lambda\hat{\sigma}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}\begin{pmatrix}0&0&&\\1&0&&\\&&0&0\\&&1&0\end{pmatrix}\\
&-\lambda\frac{1}{2}\hat{\sigma}^\dagger\begin{pmatrix}0&1&&\\0&0&&\\&&0&1\\&&0&0\end{pmatrix}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}-\lambda\frac{1}{2}\hat{\rho}_{p_0}\begin{pmatrix}0&0&&\\1&0&&\\&&0&0\\&&1&0\end{pmatrix}\begin{pmatrix}0&1&&\\0&0&&\\&&0&1\\&&0&0\end{pmatrix}\\
&=\lambda\begin{pmatrix}0&1&&\\0&0&&\\&&0&1\\&&0&0\end{pmatrix}\begin{pmatrix}0&0&b-ic&0\\0&0&0&0\\0&0&0&0\\0&0&1-a&0\end{pmatrix}-\lambda\frac{1}{2}\begin{pmatrix}0&0&&\\1&0&&\\&&0&0\\&&1&0\end{pmatrix}\begin{pmatrix}0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\\0&0&0&0\end{pmatrix}\\
&-\lambda\frac{1}{2}\begin{pmatrix}a&0&0&b-ic\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}\begin{pmatrix}0&0&&\\0&1&&\\&&0&0\\&&0&1\end{pmatrix}=\lambda\begin{pmatrix}0&0&0&0\\0&0&0&0\\0&0&1-a&0\\0&0&0&0\end{pmatrix}-\lambda\frac{1}{2}\begin{pmatrix}0&0&0&0\\0&0&0&0\\0&0&0&0\\b+ic&0&0&1-a\end{pmatrix}\\
&-\lambda\frac{1}{2}\begin{pmatrix}0&0&0&b-ic\\0&0&0&0\\0&0&0&0\\0&0&0&1-a\end{pmatrix}=-\lambda\frac{1}{2}\begin{pmatrix}0&0&0&b-ic\\0&0&0&0\\0&0&-2(1-a)&0\\b+ic&0&0&2(1-a)\end{pmatrix}
\end{split}
\end{equation}

Then, we solve Eq. (\ref{lindblad_calc}) element by element in order to obtain Eq. (\ref{rho_g1(t)})

\begin{equation} \label{rho_11}
\bullet\,\frac{d}{dt}(\hat{\rho}_{p_0}(t))_{11}=0\rightarrow(\hat{\rho}_{p_0}(t))_{11}=C_1 \xrightarrow{t=0} (\hat{\rho}_{p_0}(t=0))_{11}=C_1\numeq{\textrm{\ref{pheno_t0}}}a\rightarrow\,\,\,\,\,\,\,(\hat{\rho}_{p_0}(t))_{11}=a
\end{equation}

\begin{equation} 
\begin{split}
\bullet\,\frac{d}{dt}(\hat{\rho}_{p_0}(t))_{\begin{Bmatrix}14\\41\end{Bmatrix}}=-\lambda\frac{1}{2}(b\mp ic)\rightarrow
&(\hat{\rho}_{p_0}(t))_{\begin{Bmatrix}14\\41\end{Bmatrix}}=-\lambda\frac{1}{2}(b\mp ic)t+C_2 \xrightarrow{t=0} (\hat{\rho}_{p_0}(t=0))_{\begin{Bmatrix}14\\41\end{Bmatrix}}=C_2\numeq{\textrm{\ref{pheno_t0}}}b\mp ic\rightarrow\\
&(\hat{\rho}_{p_0}(t))_{\begin{Bmatrix}14\\41\end{Bmatrix}}=(b\mp ic)(-\lambda\frac{t}{2}+1)\overbrace{\approx}^{\lambda<<1}(b\mp ic)e^{-\lambda\frac{t}{2}}
\end{split}
\end{equation}

\begin{equation} 
\begin{split}
\bullet\,
&\frac{d}{dt}(\hat{\rho}_{p_0}(t))_{44}=-\lambda(1-a)\rightarrow(\hat{\rho}_{p_0}(t))_{44}=-\lambda(1-a)t+C_4 \xrightarrow{t=0} (\hat{\rho}_{p_0}(t=0))_{44}=C_4\numeq{\textrm{\ref{pheno_t0}}}1-a\rightarrow\\
&(\hat{\rho}_{p_0}(t))_{44}=(1-\lambda\,t)(1-a)=\underbrace{\approx}_{\lambda<<1}e^{-\lambda\,t}(1-a)
\end{split}
\end{equation}

\begin{equation} 
\begin{split}
\bullet\,
&\frac{d}{dt}(\hat{\rho}_{p_0}(t))_{33}=\lambda(1-a)\rightarrow(\hat{\rho}_{p_0}(t))_{33}=\lambda(1-a)t+C_3 \xrightarrow{t=0} (\hat{\rho}_{p_0}(t=0))_{33}=C_3\numeq{\textrm{\ref{pheno_t0}}}0\rightarrow\\
&(\hat{\rho}_{p_0}(t))_{33}=\lambda(1-a)t=(1-1+\lambda\,t)(1-a)=(1-(1-\lambda\,t))(1-a)\underbrace{\approx}_{\lambda<<1}(1-e^{-\lambda\,t})(1-a)
\end{split}
\end{equation}


$\bullet$ Otherwise, (for $(\hat{\rho}_{p_0}(t))_{ij}$ : $ij=12,13,21,22,23,24,31,32,34,42,43$)
\begin{equation} \label{rho_otherwise}
\frac{d}{dt}(\hat{\rho}_{p_0}(t))_{ij}=0\rightarrow(\hat{\rho}_{p_0}(t))_{ij}=C_5 \xrightarrow{t=0} (\hat{\rho}_{p_0}(t=0))_{ij}=C_5\numeq{\textrm{\ref{pheno_t0}}}0\rightarrow\,\,\,\,\,\,\,(\hat{\rho}_{p_0}(t))_{ij}=0
\end{equation}


\vspace{1cm}
\subsection{\normalfont{Calculations of Eq. (\ref{sigma_otimes_one(t)}-\ref{sigma_otimes_one(t)2})}} 

\begin{equation} \label{sigmaz_otimes_one(t)_appendix}
\begin{split}
 \bullet\,\,\braket{\hat{\sigma}_z}_{g_1}
 &= \braket{ \left(\hat{\sigma}_z\right)_{g_1}\otimes \hat{1}_{p_0}}_{\hat{\rho}_1\,(t)} \equiv\braket{\hat{\sigma}_z\otimes\hat{1}_2}_{\hat{\rho}_1\,(t)}=\textrm{Tr}(\hat{\rho}_{1}(t)\,(\hat{\sigma}_z\otimes\hat{1}_2))\doteq \textrm{Tr}\begin{pmatrix}\hat{\rho}_{1}(t)\,\begin{pmatrix}\begin{pmatrix}1&0\\0&-1\end{pmatrix}\otimes\begin{pmatrix}1&0\\0&1\end{pmatrix}\end{pmatrix}\end{pmatrix}\\
 & \numeq{\textrm{\ref{rho_g1(t)}}} \textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&0&0&(b-ic)e^{-\lambda t/2}\\0&0&0&0 \\ 0&0&(1-a)(1-e^{-\lambda t})&0 \\ (b+ic)e^{-\lambda t/2}&0&0&(1-a)e^{-\lambda t} \end{pmatrix}\begin{pmatrix}1&0&0&0\\0&1&0&0\\0&0&-1&0\\0&0&0&-1\end{pmatrix}\end{pmatrix}\\
 &=\textrm{Tr}\begin{pmatrix}a&0&0&(ic-b)e^{-\lambda t/2}\\0&0&0&0\\0&0&(a-1)(1-e^{-\lambda t})&0\\(b+ic)e^{-\lambda t/2}&0&0&(a-1)e^{-\lambda t}\end{pmatrix}\\
 &=a+a-ae^{-\lambda t}-1+e^{-\lambda t}+ae^{-\lambda t}-e^{-\lambda t}=2a-1\,\neq\braket{\hat{\sigma}_z}_{g_1}(t)\,\textrm{.}
\end{split}
\end{equation}
\begin{equation} \label{sigma_p0(t)}
\begin{split}
 \bullet\,\,\braket{\hat{\sigma}_z}_{p_0}(t)
 &= \braket{\hat{1}_{g_1}\otimes\left(\hat{\sigma}_z\right)_{p_0}}_{\hat{\rho}_1\,(t)}\equiv\braket{\hat{1}_2\otimes\hat{\sigma}_z}_{\hat{\rho}_1\,(t)}=\textrm{Tr}(\hat{\rho}_{1}(t)\,(\hat{1}_2\otimes\hat{\sigma}_z))\doteq \textrm{Tr}\begin{pmatrix}\hat{\rho}_{1}(t)\,\begin{pmatrix}\begin{pmatrix}1&0\\0&1\end{pmatrix}\otimes\begin{pmatrix}1&0\\0&-1\end{pmatrix}\end{pmatrix}\end{pmatrix}\\
 &\numeq{\textrm{\ref{rho_g1(t)}}} \textrm{Tr}\begin{pmatrix}\begin{pmatrix}a&0&0&(b-ic)e^{-\lambda t/2}\\0&0&0&0 \\ 0&0&(1-a)(1-e^{-\lambda t})&0 \\ (b+ic)e^{-\lambda t/2}&0&0&(1-a)e^{-\lambda t} \end{pmatrix}\begin{pmatrix}1&0&0&0\\0&-1&0&0\\0&0&1&0\\0&0&0&-1\end{pmatrix}\end{pmatrix}\\
 &=\textrm{Tr}\begin{pmatrix}a&0&0&(ic-b)e^{-\lambda t/2}\\0&0&0&0 \\ 0&0&(1-a)(1-e^{-\lambda t})&0 \\ (b+ic)e^{-\lambda t/2}&0&0&(a-1)e^{-\lambda t} \end{pmatrix}\\
 &=a+1-e^{-\lambda t}-a+ae^{-\lambda t}+ae^{-\lambda t}-e^{-\lambda t}=1+2e^{-\lambda t}(a-1)\,\textrm{.}
\end{split}
\end{equation}




\vspace{0.5cm}
\subsection{ \normalfont{Operator function} $f(\hat{A})$, \normalfont{Calculations of Eq. (\ref{sqrt_sigma_x})}} 

Finding the square root of an operator $\hat{A}$ can be thought as the function $f(\hat{A})=\sqrt[]{\hat{A}}$. The map $f:\,\mathbb{C}^n\to\mathbb{C}^n$, where $n=\dim(\hat{A})$, applied on matrix $\hat{A}$ acts on its eigenvalues $\lambda_{\hat{A}}$. If the operator is normal, $[\hat{A},\hat{A}^\dagger]=0$ (or a subclass of normal operators, such as Hermitian ones), by the spectral decomposition theorem \cite[p.~72, Theo.~2.1]{Nielsen}, it has a diagonal representation, $\hat{A}=D_{\hat{A}}$; id est, if the only non-zero elements are in the diagonal and correspond to the eigenvalues $\lambda_{\hat{A}}$. In this diagonal form $f$ acts directly on the diagonal elements: if $\hat{A}\doteq\hat{D}_{\hat{A}}\equiv \sum_i^{n}\,\lambda_i\ket{e_i}\bra{e_i}$, $f(\hat{A})\equiv\sum_i^n\,f(\lambda_i)\ket{e_i}\bra{e_i}$  This is the reason why will first represent the operators in the basis they are diagonal, in the basis formed by their eigenvectors.\\

We will calculate the square root of a $\hat{\sigma}_x$, $\sqrt[]{\hat{\sigma}_x}$:\\

\noindent $\bullet$ We first diagonalize $\hat{\sigma}_x$. To this effect, we find its eigenvalues $\lambda$:
\begin{equation}
0=\det\left( \hat{\sigma}_x -\hat{1}_2 \lambda \right) \doteq \begin{vmatrix}
-\lambda&1\\1&-\lambda
\end{vmatrix} = \lambda^2-1\,\leftrightarrow\, \lambda=\pm 1
\end{equation}

Then, its eigenvectors are
\begin{equation}
\begin{pmatrix}\mp 1&1\\1&\mp1\end{pmatrix} \begin{pmatrix}a\\b\end{pmatrix}=0\,\leftrightarrow\,\pm a=b\,\rightarrow\, \ket{\pm}\doteq \frac{1}{\sqrt[]{2}}\begin{pmatrix}1\\\pm 1\end{pmatrix}\,\textrm{.}
\end{equation}

Then, $\hat{\sigma}_x$ is diagonal in the basis formed by its eigenvectors $\{\ket{\pm}\}$ , $\hat{\sigma}_x\doteq  \begin{pmatrix}1&\\&-1\end{pmatrix}$. Stated in another manner, the matrix 
\begin{equation} 
\hat{U}\equiv \begin{pmatrix} \ket{e_1}&\ket{e_2}&\dots&\ket{e_n}
\end{pmatrix} \doteq\begin{pmatrix} \ket{+} & \ket{-}\end{pmatrix} = \frac{1}{\sqrt[]{2}}\begin{pmatrix} 1&1\\1&-1 \end{pmatrix}
\end{equation}
diagonalizes $\hat{\sigma}_x$: $\hat{U}^{-1}\,\hat{\sigma}_x\,\hat{U}=\hat{D}_{\hat{\sigma}_x}$, where $\ket{e_i}$ are the eigenvectors, $n=\dim(\hat{\sigma}_x)$, and $\hat{D}_{\hat{\sigma}_x}\equiv \sum_i^n\,\lambda_i \ket{e_i}\bra{e_i}$ is the diagonal form of $\hat{\sigma}_x$:
\begin{equation} \label{diagonal_sigma_x}
\begin{split}
\hat{D}_{\hat{\sigma}_x}
&	= \hat{U}^{-1}\,\hat{\sigma}_x\,\hat{U} \doteq  \hat{U}^{-1}\,\begin{pmatrix}&1\\1&\end{pmatrix} \,\frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\1&-1\end{pmatrix} \numeq{\textrm{\ref{U_inverse}}} \frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\1&-1\end{pmatrix} \frac{1}{\sqrt[]{2}}\begin{pmatrix}1&-1\\1&1\end{pmatrix}\\
&	= \frac{1}{2}\begin{pmatrix}2&\\&-2\end{pmatrix} = \begin{pmatrix}1&\\&-1\end{pmatrix}\,,
\end{split}
\end{equation}
\begin{equation} \label{U_inverse}
\textrm{where}\quad\hat{U}^{-1}=\frac{\left(adj(\hat{U})\right)^T}{\det(\hat{U})} = -\frac{1}{\sqrt[]{2}}\begin{pmatrix}(-1)^{1+1}(-1)&(-1)^{1+2}\\(-1)^{2+1}&(-1)^{2+2} \end{pmatrix}^T = \frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\1&-1\end{pmatrix}\doteq \hat{U}\,.
\end{equation}

\noindent $\bullet$ $\hat{D}_{\hat{\sigma}_x}=\hat{U}^{-1}\,\hat{\sigma}_x\,\hat{U}= \hat{U}^{-1}\,\sqrt[]{\hat{\sigma}_x}\,\,\sqrt[]{\hat{\sigma}_x}\,\hat{U} = \hat{U}^{-1}\,\sqrt[]{\hat{\sigma}_x}\,\hat{U}\,\hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U} = (\hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U})^2$. Obviously, $[\hat{D}_{\hat{\sigma}_x}, \hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U}]= [(\hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U})^2, \hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U}] = 0$. Thus, $\hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U}$ is diagonal, as well.  \emph{Proof}:
\begin{equation}
\begin{split}
[\hat{D}_{\hat{\sigma}_x}, \hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U}]
& \doteq \begin{pmatrix}1&\\&-1\end{pmatrix} \begin{pmatrix}a&b\\c&d\end{pmatrix} - \begin{pmatrix}a&b\\c&d\end{pmatrix} \begin{pmatrix}1&\\&-1\end{pmatrix} = \begin{pmatrix}a&b\\-c&-d\end{pmatrix} - \begin{pmatrix}a&-b\\c&-d\end{pmatrix}\\
&= \begin{pmatrix}0&2b\\-2c&0\end{pmatrix} = 0 \,\leftrightarrow \, c,d=0 \,\,\,\Rightarrow \,\,\,  \hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U} \doteq \begin{pmatrix}a&\\&d\end{pmatrix}\,\textrm{. QED}
\end{split}
\end{equation}

\noindent $\bullet$ Then, 
\begin{equation} 
\begin{split}
\hat{D}_{\hat{\sigma}_x} 
&	= (\hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U})^2 \doteq \begin{pmatrix}a&\\&d\end{pmatrix} \begin{pmatrix}a&\\&d\end{pmatrix} = \begin{pmatrix}a^2&\\&d^2\end{pmatrix} \numeq{\textrm{\ref{diagonal_sigma_x}}} \begin{pmatrix}1&\\&-1\end{pmatrix} \,\,\, \rightarrow \\
&	\hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U} \doteq \begin{pmatrix}a&\\&d\end{pmatrix} = \begin{pmatrix}\pm\,\,\sqrt[]{1}&\\&\pm\,\,\sqrt[]{-1}\end{pmatrix} = \begin{pmatrix}\pm\,\,1&\\&\pm\,\,i\end{pmatrix}\,\,\,\,\,\,\rightarrow \textrm{move back to the original basis:}\\
&	\sqrt[]{\hat{\sigma}_x} = \hat{U}\,(\hat{U}^{-1}\sqrt[]{\hat{\sigma}_x}\,\hat{U})\,\hat{U}^{-1} \doteq \hat{U}\, \begin{pmatrix}\pm\,\,1&\\&\pm\,\,i\end{pmatrix} \,\hat{U}^{-1} \numeq{\textrm{\ref{U_inverse}}} \frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\1&-1\end{pmatrix}\, \begin{pmatrix}\pm\,\,1&\\&\pm\,\,i\end{pmatrix}\\
&	\frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\1&-1\end{pmatrix} = \frac{1}{2}\,\begin{pmatrix}1&1\\1&-1\end{pmatrix}\,\begin{pmatrix}\pm 1&\pm 1\\\pm i&\mp i\end{pmatrix}=\frac{1}{2}\begin{pmatrix}\pm(1+i)&\pm(1-i)\\\pm(1-i)&\pm(1+i)\end{pmatrix}\,\textrm{.}
\end{split}
\end{equation}
We will choose the positive case, in the $\,{\ket{0},\ket{1}\,}$ basis,
\begin{equation} \label{proof_sqrt_sigma_x}
\sqrt[]{\hat{\sigma}_x} \doteq \frac{1}{2}\begin{pmatrix}1+i&1-i\\1-i&1+i\end{pmatrix}\,\textrm{.}
\end{equation} 

It can be checked as follows: 
\begin{equation}
\begin{split}
\left(\sqrt[]{\hat{\sigma}_x}\right)^2
&	\doteq \frac{1}{2}\begin{pmatrix}1+i&1-i\\1-i&1+i\end{pmatrix}\,\frac{1}{2}\begin{pmatrix}1+i&1-i\\1-i&1+i\end{pmatrix} = \frac{1}{4} \begin{pmatrix}(1+i)^2+(1-i)^2&2|1+i|^2\\2|1+i|^2&(1+i)^2+(1-i)^2\end{pmatrix}\\
&	= \frac{1}{4} \begin{pmatrix}(1-1+2i)+(1-1-2i)&4\\4&(1-1+2i)+(1-1-2i)\end{pmatrix} =\begin{pmatrix}&1\\1&\end{pmatrix} \doteq \hat{\sigma}_x\,.
\end{split}
\end{equation}





\vspace{0.5cm}
\subsection{\normalfont{Calculations of Eq. (\ref{controlled_not_root})}} \label{sqrt_sigma_z}

The square root of a $\hat{\sigma}_z$ and $\sqrt[]{\hat{\sigma}_z}$ can be calculated as follows:\\

\noindent $\bullet$ For $\hat{\sigma}_z$, 

$\diamond$ We first diagonalize $\hat{\sigma}_z$. It is already diagonal. Its eigenvalues are $\lambda=1,-1$ and, the corresponding eigenvectors, $\ket{0}$ and $\ket{1}$, respectively. Thus, the matrix 
\begin{equation} \label{basis_sigma_z}
\hat{U}\doteq\begin{pmatrix} \ket{0} & \ket{1}\end{pmatrix} = \begin{pmatrix} 1&0\\0&1 \end{pmatrix}
\end{equation}
diagonalizes $\hat{\sigma}_z$: $\hat{U}^{-1}\,\hat{\sigma}_z\,\hat{U}=\hat{D}_{\hat{\sigma}_z}$, where $\hat{D}_{\hat{\sigma}_z}$ is the diagonal form of $\hat{\sigma}_z$. Since $\hat{\sigma}_z$ is already diagonal, or, thought in another manner, since we already are in the basis formed by eigenvectors, $\hat{U}=\hat{U}^{-1}=\hat{1}_2$, as it can also be seen from Eq. (\ref{basis_sigma_z}).\\

$\diamond$ $\hat{D}_{\hat{\sigma}_z}=\hat{U}^{-1}\,\hat{\sigma}_z\,\hat{U}= \hat{U}^{-1}\,\sqrt[]{\hat{\sigma}_z}\,\,\sqrt[]{\hat{\sigma}_z}\,\hat{U} = \hat{U}^{-1}\,\sqrt[]{\hat{\sigma}_z}\,\hat{U}\,\hat{U}^{-1}\sqrt[]{\hat{\sigma}_z}\,\hat{U} = (\hat{U}^{-1}\sqrt[]{\hat{\sigma}_z}\,\hat{U})^2$. 

$\diamond$ Then, 
\begin{equation} \label{sigma_z_square_root}
\begin{split}
\hat{D}_{\hat{\sigma}_z} 
&	= (\hat{U}^{-1}\sqrt[]{\hat{\sigma}_z}\,\hat{U})^2 \doteq \begin{pmatrix}a&\\&d\end{pmatrix} \begin{pmatrix}a&\\&d\end{pmatrix} = \begin{pmatrix}a^2&\\&d^2\end{pmatrix} = \hat{\sigma}_z \doteq \begin{pmatrix}1&\\&-1\end{pmatrix} \,\,\, \rightarrow \\
&	\hat{U}^{-1}\sqrt[]{\hat{\sigma}_z}\,\hat{U} \doteq \begin{pmatrix}a&\\&d\end{pmatrix} = \begin{pmatrix}\pm\,\,\sqrt[]{1}&\\&\pm\,\,\sqrt[]{-1}\end{pmatrix} = \begin{pmatrix}\pm\,\,1&\\&\pm\,\,i\end{pmatrix}\,\,\,\,\,\,\rightarrow \\
&	\sqrt[]{\hat{\sigma}_z} = \hat{U}\,(\hat{U}^{-1}\sqrt[]{\hat{\sigma}_z}\,\hat{U})\,\hat{U}^{-1} \doteq \hat{U}\, \begin{pmatrix}\pm\,\,1&\\&\pm\,\,i\end{pmatrix} \,\hat{U}^{-1} = \hat{1}_2\, \begin{pmatrix}\pm\,\,1&\\&\pm\,\,i\end{pmatrix} \,\hat{1}_2\,\textrm{.}
\end{split}
\end{equation}
We will choose the positive case: $\sqrt[]{\hat{\sigma}_z} \numeq{\textrm{\ref{sigma_z_square_root}}} \begin{pmatrix} 1&\\&i\end{pmatrix}\textrm{.}$

\noindent $\bullet$ For $\sqrt[]{\hat{\sigma}_z}$, 

$\diamond$ $\sqrt[]{\hat{\sigma}_z}$ is diagonal. Thus, again, $\hat{U}=\hat{1}_2$ and 
$\hat{U}^{-1}\,\sqrt[]{\hat{\sigma}_z}\,\hat{U}=\hat{D}_{\sqrt[]{\hat{\sigma}_z}}$ and  $\hat{U}=\hat{U}^{-1}=\hat{1}_2$.

$\diamond$ $\hat{D}_{\sqrt[]{\hat{\sigma}_z}}=\hat{U}^{-1}\,\sqrt[]{\hat{\sigma}_z}\,\hat{U}= \hat{U}^{-1}\,\sqrt[4]{\hat{\sigma}_z}\,\,\sqrt[4]{\hat{\sigma}_z}\,\hat{U} = \hat{U}^{-1}\,\sqrt[4]{\hat{\sigma}_z}\,\hat{U}\,\hat{U}^{-1}\sqrt[4]{\hat{\sigma}_z}\,\hat{U} = (\hat{U}^{-1}\sqrt[4]{\hat{\sigma}_z}\,\hat{U})^2$.

$\diamond$ Then, 
\begin{equation} \label{sigma_z_square_root_4}
\begin{split}
\hat{D}_{\sqrt[]{\hat{\sigma}_z}} 
&	= (\hat{U}^{-1}\sqrt[4]{\hat{\sigma}_z}\,\hat{U})^2 \doteq \begin{pmatrix}a&\\&d\end{pmatrix} \begin{pmatrix}a&\\&d\end{pmatrix} = \begin{pmatrix}a^2&\\&d^2\end{pmatrix} = \sqrt[]{\hat{\sigma}_z} \doteq \begin{pmatrix}1&\\&i\end{pmatrix} \,\,\, \rightarrow \\
&	\hat{U}^{-1}\sqrt[4]{\hat{\sigma}_z}\,\hat{U} \doteq \begin{pmatrix}a&\\&d\end{pmatrix} = \begin{pmatrix}\pm\,\,\sqrt[]{1}&\\&\pm\,\,\sqrt[]{i}\end{pmatrix} = \begin{pmatrix}\pm\,\,1&\\&\pm\,\,\sqrt[]{i}\end{pmatrix}\,\,\,\,\,\,\rightarrow \\
&	\sqrt[4]{\hat{\sigma}_z} = \hat{U}\,(\hat{U}^{-1}\sqrt[]{\hat{\sigma}_z}\,\hat{U})\,\hat{U}^{-1} \doteq \hat{U}\, \begin{pmatrix}\pm\,\,1&\\&\pm\,\,\sqrt[]{i}\end{pmatrix} \,\hat{U}^{-1} = \hat{1}_2\,\begin{pmatrix}\pm\,\,1&\\&\pm\,\,\sqrt[]{i}\end{pmatrix} \,\hat{1}_2.
\end{split}
\end{equation}Again, we will choose the positive case: $\sqrt[4]{\hat{\sigma}_z} \numeq{\textrm{\ref{sigma_z_square_root_4}}} \begin{pmatrix} 1&\\&\sqrt[]{i}\end{pmatrix}$ or $\sqrt[4]{\hat{\sigma}_z} \doteq \begin{pmatrix} 1&\\&\frac{1+i}{\sqrt[]{2}}\end{pmatrix}$.

\vspace{1cm}
\noindent $\bullet$ IBM's QC provides, among other, the following unitary operators: $\,$ [\href{https://quantumexperience.ng.bluemix.net/qx/editor}{IBM}, Gates, Help]
\begin{equation} \label{IBM_u_gates}
\hat{u}_2 (\varphi,\lambda)\doteq \frac{1}{\sqrt[]{2}}\begin{pmatrix} 1&-e^{i\lambda}\\e^{i\varphi}&e^{i(\varphi+\lambda)} \end{pmatrix} \quad \textrm{and} \quad \hat{u}_3 (\theta,\varphi,\lambda)\doteq \frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\theta}{2}&-e^{i\lambda}\sin\frac{\theta}{2}\\e^{i\varphi}\sin\frac{\theta}{2}&e^{i(\varphi+\lambda)}\cos\frac{\theta}{2} \end{pmatrix}\,\textrm{.}
\end{equation}



\noindent $\bullet$ Thus, for $i>j$, Eq. (\ref{controlled_not_root}) is
\noindent
{\color{red} \rule{\linewidth}{0.5mm} }

\begin{equation} \label{proof_controlled_not_root}
\begin{split}
\hat{C}_{ij}
&	= \left( \sqrt[4]{\hat{\sigma}_z}\otimes\sqrt[]{\hat{\sigma}_z}\, \hat{u}_3(-\frac{\pi}{4},0,0) \right)\,\hat{U}_{ij}\, \left(\hat{1}_2\otimes\hat{u}_3(\frac{\pi}{4},0,0)\right)\,\hat{U}_{ij}\,	\left(\hat{1}_2\otimes(\sqrt[]{\hat{\sigma}_z})^\dagger\right)\\
&	\numeq{\textrm{\ref{sigma_z_square_root}-\ref{IBM_u_gates}}} \,\,\, \left( \sqrt[4]{\hat{\sigma}_z}\otimes\begin{pmatrix}1&\\&i\end{pmatrix}\, \frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}&\sin\frac{\pi}{8}\\-\sin\frac{\pi}{8}&\cos\frac{\pi}{8} \end{pmatrix}  \right)\,\hat{U}_{ij}\, \left(\hat{1}_2\otimes\hat{u}_3(\frac{\pi}{4},0,0)\right)\,\hat{U}_{ij}\,	\left(\hat{1}_2\otimes(\sqrt[]{\hat{\sigma}_z})^\dagger\right)\\
&	= \left( \sqrt[4]{\hat{\sigma}_z}\otimes\frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}&\sin\frac{\pi}{8}\\-i\sin\frac{\pi}{8}&i\cos\frac{\pi}{8} \end{pmatrix}  \right)\,\hat{U}_{ij}\, \left(\hat{1}_2\otimes\hat{u}_3(\frac{\pi}{4},0,0)\right)\,\hat{U}_{ij}\,	\left(\hat{1}_2\otimes(\sqrt[]{\hat{\sigma}_z})^\dagger\right)\\
&	\numeq{\textrm{\ref{U_CNOT_32}}} \frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}&\sin\frac{\pi}{8}&&\\-i\sin\frac{\pi}{8}&i\cos\frac{\pi}{8}&&\\ &&\frac{1+i}{\sqrt[]{2}} \begin{pmatrix} \cos\frac{\pi}{8}&\sin\frac{\pi}{8}\\-i\sin\frac{\pi}{8}&i\cos\frac{\pi}{8} \end{pmatrix} \end{pmatrix} \begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix}\, \left(\hat{1}_2\otimes\hat{u}_3(\frac{\pi}{4},0,0)\right)\, \\
&	\begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix} \begin{pmatrix} 1&&&\\ &-i&&\\ &&1&\\ &&&-i \end{pmatrix} \\
&   = \frac{1}{\sqrt[]{2}}\, \begin{pmatrix} \cos\frac{\pi}{8}&\sin\frac{\pi}{8}&&\\-i\sin\frac{\pi}{8}&i\cos\frac{\pi}{8}&&\\ &&\frac{1+i}{\sqrt[]{2}} \begin{pmatrix} \sin\frac{\pi}{8}&\cos\frac{\pi}{8}\\i\cos\frac{\pi}{8}&-i\sin\frac{\pi}{8} \end{pmatrix} \end{pmatrix}\, \frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}&-\sin\frac{\pi}{8}&&\\ \sin\frac{\pi}{8}&\cos\frac{\pi}{8}&&\\ &&\cos\frac{\pi}{8}&-\sin\frac{\pi}{8}\\ &&\sin\frac{\pi}{8}&\cos\frac{\pi}{8} \end{pmatrix}\\
&   \begin{pmatrix} 1&&&\\ &-i&&\\ &&&-i\\ &&1&\end{pmatrix} = \frac{1}{\sqrt[]{2}}\, \begin{pmatrix} \cos\frac{\pi}{8}&\sin\frac{\pi}{8}&&\\-i\sin\frac{\pi}{8}&i\cos\frac{\pi}{8}&&\\ &&\frac{1+i}{\sqrt[]{2}} \begin{pmatrix} \sin\frac{\pi}{8}&\cos\frac{\pi}{8}\\i\cos\frac{\pi}{8}&-i\sin\frac{\pi}{8} \end{pmatrix} \end{pmatrix}\\
&	\frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}&i\sin\frac{\pi}{8}&&\\ \sin\frac{\pi}{8}&-i\cos\frac{\pi}{8}&&\\ &&-\sin\frac{\pi}{8}&-i\cos\frac{\pi}{8}\\ &&\cos\frac{\pi}{8}&-i\sin\frac{\pi}{8} \end{pmatrix} = \frac{1}{2} \begin{pmatrix} 1&&&\\&1&&\\ &&\frac{1+i}{\sqrt[]{2}} \begin{pmatrix} \cos^2\frac{\pi}{8}-\sin^2\frac{\pi}{8}&-2i\cos\frac{\pi}{8}\sin\frac{\pi}{8}\\-2i\cos\frac{\pi}{8}\sin\frac{\pi}{8}&\cos^2\frac{\pi}{8}-\sin^2\frac{\pi}{8} \end{pmatrix} \end{pmatrix}\\
&	= \frac{1}{2} \begin{pmatrix} 1&&&\\&1&&\\ && \frac{1+i}{\sqrt[]{2}} \begin{pmatrix} \cos\frac{\pi}{4}&-\sin\frac{\pi}{4}\\-\sin\frac{\pi}{4}&\cos\frac{\pi}{4} \end{pmatrix} \end{pmatrix} = \frac{1}{2} \begin{pmatrix} 1&&&\\&1&&\\ &&\frac{1+i}{2} \begin{pmatrix} 1&-1\\-1&1 \end{pmatrix} \end{pmatrix}\,\textrm{.}
\end{split} 
\end{equation}
\noindent
{\color{red} \rule{\linewidth}{0.5mm} }







\vspace{1cm}
\subsection{\normalfont{Proof of Eq. (\ref{U_10 U_21})}} \label{U_10 U_21 proof}

We will prove
\begin{equation}
 \hat{U}_{C_{NOT}}=\hat{U}_{ij}\,\textrm{ : } \,i,j=0,1,2,3\,\,\,\textrm{and}\,\,\,i>j\textrm{.}
\end{equation} 
Using the qubit order of IBM's computer, Eq. (\ref{qubit_order}). For example, for $i=2$ and $j=1$, 
\begin{equation} \label{U_CNOT_32}
\begin{split}
&	\hat{U}_{21}\left(a\ket{00}+b\ket{01}+c\ket{10}+d\ket{11} \right)=a\ket{00}+b\ket{01}+c\ket{11}+d\ket{10}\,\doteq\\
&	\hat{U}_{21}\begin{pmatrix}a\\ b\\ c\\ d\end{pmatrix} = \begin{pmatrix}a\\ b\\ d\\ c\end{pmatrix}\leftrightarrow \hat{U}_{21}\doteq \begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix}= \begin{pmatrix}\hat{1}_2&\\&\hat{\sigma}_x\end{pmatrix}\equiv \hat{U}_{C_{\hat{\sigma}_x}}=\hat{U}_{C_{NOT}}=\hat{U}_{ij}\,\textrm{. QED}
\end{split}
\end{equation}

On the other hand, for $\hat{U}_{ji}$ $:$ $i>j$, and $i=2$ and $j=1$, as well,
\begin{equation} \label{U_CNOT_23}
\begin{split}
&	\hat{U}_{12}\left(a\ket{00}+b\ket{01}+c\ket{10}+d\ket{11} \right)=a\ket{00}+b\ket{11}+c\ket{10}+d\ket{01}\,\doteq\\
&	\hat{U}_{12}\begin{pmatrix}a\\ b\\ c\\ d\end{pmatrix} = \begin{pmatrix}a\\ d\\ c\\ b\end{pmatrix}\leftrightarrow \hat{U}_{12}\doteq \begin{pmatrix} 1&&&\\ &&&1\\ &&1&\\ &1&&\end{pmatrix}=\hat{U}_{ji}\,\textrm{,}
\end{split}
\end{equation}
where $\ket{xy}\equiv\ket{x}_2\ket{y}_1$ $:$ $x,y\in\{0,1\}$.




\vspace{1cm}
\subsection{\normalfont{Proof of Eq. (\ref{swap})}} \label{swap_proof}

Equation (\ref{swap}) must be obeyed for $\forall i,j$. This equivalent to $S_{ij}$ and $S_{ji}$ agreeing Ref. \cite[p.~xxxi, l.~2]{Nielsen} for, e. g., $i>j$:

\begin{equation} \label{swap_proof_eq}
\begin{split}
\hat{S}_{ij}
&	=\hat{U}_{ij}\,\hat{U}_{ji}\,\hat{U}_{ij} \numeq{\textrm{\ref{U_CNOT_32}-\ref{U_CNOT_23}}} \begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix}\, \begin{pmatrix}1&&&\\ &&&1\\ &&1&\\ &1&&\end{pmatrix}\,\hat{U}_{ij}= \begin{pmatrix} 1&&&\\ &&&1\\ &1&&\\ &&1&\end{pmatrix}\begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix}\\
&	= \begin{pmatrix} 1&&&\\ &&1&\\ &1&&\\ &&&1\end{pmatrix}\,\textrm{,}\quad \textrm{and} 
\end{split}
\end{equation}

\begin{equation} \label{swap_23}
\begin{split}
\hat{S}_{ji}
&	= \hat{U}_{ji}\,\hat{U}_{ij}\,\hat{U}_{ji}\numeq{\textrm{\ref{U_CNOT_32}-\ref{U_CNOT_23}}}\,\, \begin{pmatrix} 1&&&\\ &&&1\\ &&1&\\ &1&&\end{pmatrix}  \begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix} \hat{U}_{ji} =\begin{pmatrix}1&&&\\ &&1&\\ &&&1\\ &1&&\end{pmatrix} \begin{pmatrix} 1&&&\\ &&&1\\ &&1&\\ &1&&\end{pmatrix}\\
& = \begin{pmatrix}1&&&\\ &&1&\\ &1&&\\ &&&1\end{pmatrix}\,\textrm{. QED}
\end{split}
\end{equation}

Experimentally Eq. (\ref{swap_proof_eq}-\ref{swap_23}) have to be implemented as Eq. (\ref{S_ij}-\ref{S_ji}), respectively.





\vspace{1cm}
\subsection{\normalfont{Proof of Eq. (\ref{interaction_operator}) and Eq. (\ref{psi_t_f})}} \label{U_I_gates}

\begin{equation} \label{psi_t3}
\begin{split}
\bullet\,\ket{\psi(t_3)}
&	\numeq{\textrm{\ref{interaction_operator}}} \hat{S}_{21}\ket{\psi(t_2)}\\
&	\numeq{\textrm{\ref{psi_t2}}} \hat{S}_{21}\frac{1}{2} (\cos\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0000} + \cos\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{0110}\\
&	+\sin\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{1001} +\sin\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1111})\\
&	\numeq{\textrm{\ref{swap_23}}} \begin{pmatrix}1&&&\\ &&1&\\ &1&&\\ &&&1\end{pmatrix}\, \frac{1}{2} (\cos\frac{\pi}{8}\cos\frac{3\pi}{8}\begin{pmatrix}1\\ 0\\ 0\\ 0\\ \end{pmatrix}\otimes\ket{00} + \cos\frac{\pi}{8}\sin\frac{3\pi}{8}\begin{pmatrix}0\\ 1\\ 0\\ 0\\ \end{pmatrix}\otimes\ket{10}\\
&	+\sin\frac{\pi}{8}\cos\frac{3\pi}{8}\begin{pmatrix}0\\ 0\\ 1\\ 0\\ \end{pmatrix}\otimes\ket{01} +\sin\frac{\pi}{8}\sin\frac{3\pi}{8}\begin{pmatrix}0\\ 0\\ 0\\ 1\\ \end{pmatrix}\otimes\ket{11}) = \frac{1}{2} (\cos\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0000}\\
&+ \cos\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1010} +\sin\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0101} +\sin\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1111})\,,
\end{split}
\end{equation}
which can only be experimentally implemented via the following gates: 
\begin{equation}
\hat{S}_{21} \numeq{\textrm{\ref{S_ij}}} \hat{U}_{21}\,(\hat{U}_{\textrm{Had}}^{\otimes 2}\,\hat{U}_{21}\,\hat{U}_{\textrm{Had}}^{\otimes 2})\,\hat{U}_{21}\,.
\end{equation}

\vspace{0.15cm}
\begin{equation} \label{psi_t4}
\begin{split}
\bullet\,\ket{\psi(t_4)}
&	\numeq{\textrm{\ref{interaction_operator}}}  \hat{U}_{32}\ket{\psi(t_3)}\\
& \numeq{\textrm{\ref{psi_t3}}} \hat{U}_{32}\,\frac{1}{2} (\cos\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0000} + \cos\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1010} +\sin\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0101} +\sin\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1111})\\
&	\numeq{\textrm{\ref{U_CNOT_32}}} \begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix} \,\frac{1}{2} (\cos\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{00}\otimes \begin{pmatrix}1\\0\\0\\0\end{pmatrix} + \cos\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{10}\otimes \begin{pmatrix}0\\0\\1\\0\end{pmatrix} \\
&	+\sin\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{01}\otimes \begin{pmatrix}0\\1\\0\\0\end{pmatrix}+\sin\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{11}\otimes \begin{pmatrix}0\\0\\0\\1\end{pmatrix}) =\frac{1}{2} (\cos\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0000}\\
&	+ \cos\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1011} +\sin\frac{\pi}{8}\cos\frac{3\pi}{8}\ket{0101} +\sin\frac{\pi}{8}\sin\frac{3\pi}{8}\ket{1110})\,.
\end{split}
\end{equation}


\noindent $\bullet$ From Eq. (\ref{interaction_operator}), 
\begin{equation} \label{F_operator}
\begin{split}
\hat{F}
&	\equiv\hat{U}_{01}\,\hat{C}_{10}\,\hat{C}_{20}\,\hat{U}_{21}\,\hat{C}_{10}^\dagger\,\hat{U}_{01}\,\hat{U}_{21} \numeq{\textrm{\ref{U_CNOT_32}-\ref{U_CNOT_23}}} \hat{U}_{01}\,\hat{C}_{10}\,\hat{C}_{20}\,\hat{U}_{21}\,\hat{C}_{10}^\dagger\,\begin{pmatrix} 1&&&\\ &&&1\\ &&1&\\ &1&&\end{pmatrix}\begin{pmatrix} 1&&&\\ &1&&\\ &&&1\\ &&1&\end{pmatrix}\\
&	\numeq{\textrm{\ref{controlled_not_root}}} \hat{U}_{01}\,\hat{C}_{10}\,\hat{C}_{20}\,\hat{U}_{21}\,\begin{pmatrix}1&&&\\ &1&&\\ &&\frac{1}{2}\begin{pmatrix} 1+i & 1-i \\ 1-i & 1+i
\end{pmatrix}\end{pmatrix}^ \dagger\,\begin{pmatrix} 1&&&\\&&1&\\ &&&1\\ &1&&\end{pmatrix}\\
&	=\hat{U}_{01}\,\hat{C}_{10}\,\hat{C}_{20}\,\hat{U}_{21}\,\begin{pmatrix}1&&&\\ &1&&\\ &&\frac{1}{2}\begin{pmatrix} 1-i & 1+i \\ 1+i & 1-i
\end{pmatrix}\end{pmatrix}\,\begin{pmatrix} 1&&&\\&&1&\\ &&&1\\ &1&&\end{pmatrix}\\
&	\numeq{\textrm{\ref{U_CNOT_32}}} \hat{U}_{01}\,\hat{C}_{10}\,\hat{C}_{20}\,\begin{pmatrix} 1&&&\\&1&&\\ &&&1\\ &&1&\end{pmatrix}\,\begin{pmatrix}1&&&\\ &&1&\\ 0&\frac{1}{2}(1+i)&0&\frac{1}{2}(1-i)\\0&\frac{1}{2}(1-i)&0&\frac{1}{2}(1+i)\end{pmatrix}\\
&	\numeq{\textrm{\ref{controlled_not_root}}} \hat{U}_{01}\,\hat{C}_{10}\begin{pmatrix}1&&&\\ &1&&\\ &&\frac{1}{2}\begin{pmatrix} 1+i & 1-i \\ 1-i & 1+i
\end{pmatrix}\end{pmatrix}\,\begin{pmatrix}1&&&\\ &&1&\\ 0&\frac{1}{2}(1-i)&0&\frac{1}{2}(1+i)\\0&\frac{1}{2}(1+i)&0&\frac{1}{2}(1-i)\end{pmatrix}\\
&	\numeq{\textrm{\ref{controlled_not_root}}} \hat{U}_{01}\,\hat{C}_{10}\,\begin{pmatrix}1&&&\\ &&1&\\0&\frac{1}{2}(1+i)(1-i)&0&\frac{(1+i)^2+(1-i)^2}{4}\\0&\frac{(1+i)^2+(1-i)^2}{4}&0&\frac{1}{2}(1+i)(1-i)\end{pmatrix}\\
&	\numeq{3}\hat{U}_{01}\,\begin{pmatrix}1&&&\\ &1&&\\ &&\frac{1}{2}\begin{pmatrix} 1+i & 1-i \\ 1-i & 1+i
\end{pmatrix}\end{pmatrix}\,\begin{pmatrix}1&&&\\ &&1&\\0&1&0&0\\0&0&0&1\end{pmatrix}\\
&	\numeq{\textrm{\ref{U_CNOT_23}}} \begin{pmatrix} 1&&&\\ &&&1\\ &&1&\\ &1&&\end{pmatrix}\,\begin{pmatrix}1&&&\\ &&1&\\ 0&\frac{1}{2}(1+i)&0&\frac{1}{2}(1-i)\\0&\frac{1}{2}(1-i)&0&\frac{1}{2}(1+i)\end{pmatrix} = \begin{pmatrix}1&&&\\0&\frac{1}{2}(1-i)&0&\frac{1}{2}(1+i)\\0&\frac{1}{2}(1+i)&0&\frac{1}{2}(1-i)\\&&1&\end{pmatrix}\,,
\end{split}
\end{equation}
where from $(3)$ we can infer
\begin{equation}
\hat{C}_{20}\,\hat{U}_{21}\,\hat{C}_{10}^\dagger\,\hat{U}_{01}\,\hat{U}_{21}=\begin{pmatrix}1&&&\\ &&1&\\0&1&0&0\\0&0&0&1\end{pmatrix}\numeq{\textrm{\ref{swap_proof_eq}}}\hat{S}_{ij}\,.
\end{equation}
Moreover, $\hat{U}_{01}$ has to be deployed as $\hat{U}_{01}\numeq{\textrm{\ref{U_CNOT_12}}} \hat{U}_{\textrm{Had}}^{\otimes 2}\,\hat{U}_{10}\,\hat{U}_{\textrm{Had}}^{\otimes 2}$;  $\hat{C}_{10}$ and $\hat{C}_{20}$, as Eq. (\ref{controlled_not_root}), for $(i,j)=(1,0)$ and $(i,j)=(2,0)$, respectively, and $\hat{C}_{10}^\dagger$,

\begin{equation}
\begin{split}
\hat{C}_{10}^\dagger
&	\numeq{\textrm{\ref{controlled_not_root}}}
\left[  \left( \sqrt[4]{\hat{\sigma}_z}\otimes\sqrt[]{\hat{\sigma}_z}\, \hat{u}_3(-\frac{\pi}{4},0,0) \right)\,\hat{U}_{ij}\, \left(\hat{1}_2\otimes\hat{u}_3(\frac{\pi}{4},0,0)\right)\,\hat{U}_{ij}\,	\left(\hat{1}_2\otimes(\sqrt[]{\hat{\sigma}_z})^\dagger\right)\right]^\dagger\\
&	\numeq{1}\left[\left(\hat{1}_2\otimes\hat{u}_3(\frac{\pi}{4},0,0)\right)\,\hat{U}_{ij}\,	\left(\hat{1}_2\otimes(\sqrt[]{\hat{\sigma}_z})^\dagger\right)\right]^\dagger \,\,\,\left[  \left( \sqrt[4]{\hat{\sigma}_z}\otimes\sqrt[]{\hat{\sigma}_z}\, \hat{u}_3(-\frac{\pi}{4},0,0) \right)\,\hat{U}_{ij}\right]^\dagger\\
&	\numeq{1} \left[\hat{U}_{ij}\,	\left(\hat{1}_2\otimes(\sqrt[]{\hat{\sigma}_z})^\dagger\right)\right]^\dagger\,\left(\hat{1}_2\otimes\hat{u}_3(\frac{\pi}{4},0,0)\right)^\dagger\,\,\left[\hat{U}_{ij}\right]^\dagger\,\left( \sqrt[4]{\hat{\sigma}_z}\otimes\sqrt[]{\hat{\sigma}_z}\, \hat{u}_3(-\frac{\pi}{4},0,0) \right)^\dagger\\
&	\numeq{1} \left(\hat{1}_2\otimes(\sqrt[]{\hat{\sigma}_z})^\dagger\,\right)^\dagger\,\left[\hat{U}_{ij}\right]^\dagger\,\left(\hat{1}_2\otimes\hat{u}_3(\frac{\pi}{4},0,0)\right)^\dagger\,\,\left[\hat{U}_{ij}\right]^\dagger\,\left( \sqrt[4]{\hat{\sigma}_z}\otimes\sqrt[]{\hat{\sigma}_z}\, \hat{u}_3(-\frac{\pi}{4},0,0) \right)^\dagger\\
&	\numeq{2} \left(\hat{1}_2\otimes\sqrt[]{\hat{\sigma}_z}\right)\,\hat{U}_{ij}\,\left(\hat{1}_2\otimes\hat{u}_3^\dagger(\frac{\pi}{4},0,0)\right)\,\,\hat{U}_{ij}\,\left( \left[\sqrt[4]{\hat{\sigma}_z}\right]^\dagger\otimes \hat{u}_3^\dagger(-\frac{\pi}{4},0,0)\,\left[\sqrt[]{\hat{\sigma}_z}\right]^\dagger \right)\\
&	=\left(\hat{1}_2\otimes\sqrt[]{\hat{\sigma}_z}\right)\,\hat{U}_{ij}\,\left(\hat{1}_2\otimes\hat{u}_3(-\frac{\pi}{4},0,0)\right)\,\,\hat{U}_{ij}\,\left( \left[\sqrt[4]{\hat{\sigma}_z}\right]^\dagger\otimes \hat{u}_3(+\frac{\pi}{4},0,0)\,\left[\sqrt[]{\hat{\sigma}_z}\right]^\dagger \right)\,,
\end{split}
\end{equation}
where, for $i>j$, $\hat{U}_{10}=\hat{U}_{ij}$. In $(1)$, we used $\left(\hat{A}\hat{B}\right)^\dagger=\hat{B}^\dagger\hat{A}^\dagger$. In $(2)$, $\hat{1}_2^\dagger=\hat{1}_2$, $\hat{U}_{ij}^\dagger=\hat{U}_{ij}$ ($\hat{U}_{C_{NOT}}^\dagger = \hat{U}_{C_{NOT}}$), $\left(\hat{A}^\dagger\right)^\dagger=\hat{A}$ and $\left( \hat{A}\otimes\hat{B}\right)^\dagger=\hat{A}^\dagger\otimes\hat{B}^\dagger$. The latter comes from Ref. \cite[p.~74, Eq.~(2.53)]{Nielsen}: $(\hat{A}\otimes\hat{B})^T=\hat{A}^T\otimes\hat{B}^T$, and $(\hat{A}\otimes\hat{B})^*=\hat{A}^*\otimes\hat{B}^*$. Then, since $\hat{A}^\dagger\equiv(\hat{A}^*)^T\equiv(\hat{A}^T)^*$, $(\hat{A}\otimes\hat{B})^\dagger=\hat{A}^\dagger\otimes\hat{B}^\dagger$.

Furthermore, 
\begin{equation}
\sqrt[]{\sigma}_z\,\hat{u}_3(-\frac{\pi}{4},0,0) \numeq{\textrm{\ref{sigma_z_square_root}-\ref{IBM_u_gates}}}  \begin{pmatrix}1&\\&i\end{pmatrix}\,\frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{-\pi/4}{2}&-\sin\frac{-\pi/4}{2}\\\sin\frac{-\pi/4}{2}&\cos\frac{-\pi/4}{2} \end{pmatrix} = \frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}&\sin\frac{\pi}{8}\\-i\sin\frac{\pi}{8}&i\cos\frac{\pi}{8} \end{pmatrix}
\end{equation}

\begin{equation}
\hat{u}_3 (\theta=\frac{\pi}{4},\varphi=0,\lambda=\pi)\doteq \frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi/4}{2}&-e^{i\pi}\sin\frac{\pi/4}{2}\\e^{i\,0}\sin\frac{\pi/4}{2}&e^{i(0+\pi)}\cos\frac{\pi/4}{2} \end{pmatrix} = \frac{1}{\sqrt[]{2}}\begin{pmatrix} \cos\frac{\pi}{8}&\sin\frac{\pi}{8}\\ \sin\frac{\pi}{8}&-\cos\frac{\pi}{8} \end{pmatrix}
\end{equation}

\begin{equation}
\left[\sqrt[]{\sigma}_z\,\hat{u}_3(-\frac{\pi}{4},0,0)\right]^\dagger = 
\end{equation}


\vspace{0.60cm}
Hence, 
\begin{equation} \label{psi_t5}
\begin{split}
\ket{\psi(t_5)}
&	\numeq{\textrm{\ref{interaction_operator}}}  \hat{F}\ket{\psi(t_4)}\\
& \numeq{\textrm{\ref{F_operator}}}
\end{split}
\end{equation}











\vspace{1cm}
\subsection{\normalfont{Proof of Eq. (\ref{Nielsen_2175})}} \label{proof_Nielsen_2175}

From Eq. (\ref{Bloch}) we have, in the $\{\ket{0},\ket{1}\}$ basis, $\ket{\psi}=\cos(\theta/2)\ket{0}+\sin(\theta/2)e^{i\varphi}\ket{1}\doteq\begin{pmatrix}\cos(\theta/2)\\\sin(\theta/2)e^{i\varphi}\end{pmatrix}$.\\

\begin{itemize}
\item The density matrix for a pure ensemble is $\hat{\rho}=\ket{\psi}\bra{\psi}$  $\,\,\,$ \cite[p.~182, Eq.~(3.4.12)]{Sakurai}. Hence, 
\begin{equation} \label{C1}
\hat{\rho}=\ket{\psi}\bra{\psi}\doteq\begin{pmatrix}\cos(\theta/2)\\\sin(\theta/2)e^{i\varphi}\end{pmatrix}\begin{pmatrix}\cos(\theta/2)&\sin(\theta/2)e^{-i\varphi}\end{pmatrix}=\begin{pmatrix}\cos^2(\theta/2)&\cos(\theta/2)\sin(\theta/2)e^{-i\varphi}\\ \cos(\theta/2)\sin(\theta/2)e^{i\varphi}&\sin^2(\theta/2)\end{pmatrix}\,\textrm{.}
\end{equation}
\item From Eq. (\ref{Nielsen_2175}), 
\begin{equation} \label{C2}
\begin{split}
\hat{\rho}
&=\frac{1}{2}(\hat{1}_2+\vec{r}\cdot\vec{\sigma})=\frac{1}{2}(\hat{1}_2+(r_1,r_2,r_3)\cdot(\sigma_1,\sigma_2,\sigma_3))\doteq\frac{1}{2}\begin{pmatrix}1&0\\0&1\end{pmatrix}+\frac{1}{2}\,r_1\begin{pmatrix}0&1\\1&0\end{pmatrix}+\frac{1}{2}\,r_2\begin{pmatrix}0&-i\\i&0\end{pmatrix}\\
&+\frac{1}{2}\,r_3\begin{pmatrix}1&0\\0&-1\end{pmatrix}=\frac{1}{2}\begin{pmatrix}
1+r_3 & r_1-i\,r_2\\r_1+i\,r_2 & 1-r_3
\end{pmatrix}\,\textrm{.}
\end{split}
\end{equation}
\end{itemize}

From (\ref{C1})$=$(\ref{C2}) we obtain
\begin{equation} \label{C3}
\cos^2(\theta/2)=\frac{1}{2}(1+r_3)\textrm{,}\quad\cos(\theta/2)\sin(\theta/2)e^{-i\varphi}=\frac{1}{2}(r_1-i\,r_2)\textrm{,}
\end{equation}
\begin{equation} \label{C4}
\cos(\theta/2)\sin(\theta/2)e^{i\varphi}=\frac{1}{2}(r_1+i\,r_2)\quad\textrm{and}\quad\sin^2(\theta/2)=\frac{1}{2}(1-r_3)
\end{equation}

\begin{itemize}
\item (\ref{C3}b)$+$(\ref{C4}a)$=\cos(\theta/2)\sin(\theta/2)e^{-i\varphi}+\cos(\theta/2)\sin(\theta/2)e^{i\varphi}=\frac{1}{2}(r_1-i\,r_2)+\frac{1}{2}(r_1+i\,r_2)$ $\leftrightarrow$ 

$r_1=\cos(\theta/2)\sin(\theta/2)\,2\,\cos(\varphi)$.

\item (\ref{C3}b)$-$(\ref{C4}a)$=\cos(\theta/2)\sin(\theta/2)e^{-i\varphi}-\cos(\theta/2)\sin(\theta/2)e^{i\varphi}=\frac{1}{2}(r_1-i\,r_2)+\frac{1}{2}(r_1-i\,r_2)$ $\leftrightarrow$ 

$-i\,r_2=\cos(\theta/2)\sin(\theta/2)\,(-2i\,\sin(\varphi))$ $\leftrightarrow$ $\,r_2=\cos(\theta/2)\sin(\theta/2)\,2\,\sin(\varphi)$.

\item (\ref{C3}a)$-$(\ref{C4}b)$=\cos^2(\theta/2)-\sin^2(\theta/2)=\frac{1}{2}(1+r_3)-\frac{1}{2}(1-r_3)$ $\leftrightarrow$ $r_3=\cos^2(\theta/2)-\sin^2(\theta/2)$.\\
\end{itemize}

Therefore, as stated for pure states, 
\begin{equation}
\begin{split}
|\vec{r}|^2
&=r_1^2+r_2^2+r_3^2=(\cos^2(\theta/2)\sin^2(\theta/2)\,4\,\cos^2(\varphi))+(\cos^2(\theta/2)\sin^2(\theta/2)\,4\,\sin^2(\varphi))\\
&+(\cos^4(\theta/2)+\sin^4(\theta/2)-2\cos^2(\theta/2)\sin^2(\theta/2))=4\,\cos^2(\theta/2)\sin^2(\theta/2)+(\cos^4(\theta/2)+\sin^4(\theta/2)\\
&-2\cos^2(\theta/2)\sin^2(\theta/2))=(\cos^2(\theta/2)\sin^2(\theta/2))^2=1^2=1\,\leftrightarrow\,|\vec{r}|=+\sqrt[]{1}=1
\end{split}
\end{equation}








\newpage


\section{Open Quantum Systems} \label{open_quantum_system}

Let us consider an open quantum system: a system A and the external environment or bath B continuously interacting with it.  
\begin{itemize}
\item We say that the \uline{initial state} of the system $A$ and the environment $B$ is \emph{uncorrelated} if it can be written as a product like $\hat{\rho}_{AB}(t=t_0)=\hat{\rho}_A(t_0)\,\otimes\,\hat{\rho}_B(t_0)$. The  total  Hilbert  space  is  thus $\mathcal{H}_{AB}=\mathcal{H}_A\otimes\mathcal{H}_B$, where $\hat{\rho}_i\in\mathcal{H}_i$ $:$ $i=AB,A,B$. $B$ stands for bath or environment, the group of every region within the Hilbert space $\mathcal{H}_{AB}$ that is not the subsystem of interest.
\item Any evolution in quantum mechanics can be represented by unitary operators. E.g., the joint $t$ evolution for the  total  system (system $A$ $+$ environment $B$) is $\hat{\rho}_{AB}(t)=\hat{U}_{AB}(t,t_0)\,\,\hat{\rho}_{AB}(t_0)\,\,\hat{U}_{AB}^\dagger(t,t_0)$ $\,\,\,$ $:$ $\hat{U}_{AB}\hat{U}_{AB}^\dagger=\hat{U}_{AB}^\dagger\hat{U}_{AB}=\hat{1}_{AB}$ $\,\,$ \cite[p.~1076, l.~85-86]{Lloyd}.

The most general representation of any evolution has the form of a \emph{quantum channel} $\hat{\rho}_{AB}^\prime=\sum_k\hat{M}_{k}\hat{\rho}_{AB}\hat{M}_{k}^\dagger$, where the set of operators $\{\hat{M}_{k}\}$, known as \emph{Kraus} operators, satisfies $\sum_k\hat{M}_{k}\hat{M}_{k}^\dagger=\hat{1}$. If there is only one $\hat{M}_{k}$, the usual unitarity condition $\hat{M}_{k}\hat{M}_{k}^\dagger=\hat{1}$ is recovered. As in here, environment or baths are also called \emph{channel}s, borrowing this notation from the theory of quantum information and communications.

This \emph{quantum channel}, \emph{Kraus} or CPTP map is the most general $\hat{\rho}(t)\,\to\,\hat{\rho}(t)$ map that preserves the trace, $\textrm{Tr}[\hat{\rho}(t)]=1$, and positivity, $\hat{\rho}(t)\geq 0$, $\forall t$.

\item If we are only interested in the evolution of the system A on its own, we can perform a \emph{partial trace} over system B. That is, we partially trace over the constituents we do not want to measure and we obtain the \emph{reduced} density matrix $\hat{\rho}_A=\textrm{Tr}_B\,(\hat{\rho}_{AB})$. $\,\,\,$ \cite[p.~105, Eq.~(2.177-2.178)]{Nielsen}

Partially tracing is similar to integrating the \emph{Wigner function} with respect to the variables we want to disregard. The Wigner function $W(\vec{x},\vec{p})$ is a reexpression of the density operator $\hat{\rho}$. \cite[p.~478, l.~1]{Feynman} For instance, for a single particle, $W(\vec{x},\vec{p}) = \int\,\rho(x+\frac{y}{2},x-\frac{y}{2})\,\,e^{ipy}\,dy$. Hence, if $W(\vec{x},\vec{p})$ is the \emph{probability} that our particle is measured in the  $\vec{x}$ position and the $\vec{p}$ momentum, per $d\vec{x}$ and $d\vec{p}$; then $\int W(\vec{x},\vec{p})\,d\vec{p}$ $\,\,$ ($\int W(\vec{x},\vec{p})\,d\vec{x}$) is the probability of finding it at $\vec{x}$ ($\vec{p}$). \\

\begin{itemize}
\item[$\diamond$] As mentioned, the evolution operator for the complete AB system, $\hat{U}_{AB}$, is unitary. Notwithstanding, the effective one in the reduced subspace A, $\hat{U}_A$, is not.
\item[$\diamond$] At least the notion of quantum state is preserved, since $\hat{U}_A$ forms a completely positive ($\hat{\rho}_A\geq 0$) and trace preserving ($\textrm{Tr}\,\hat{\rho}_A=1$) map (CPTP).
\end{itemize}

If the $A$ and $B$ were initially uncorrelated --so that, as mentioned, $\hat{\rho}_{AB}(t=t_0)=\hat{\rho}_A(t_0)\,\otimes\,\hat{\rho}_B(t_0)$--, The time-evolved reduced density operator is $\hat{\rho}_A(t)=\mathcal{L}(t)[\hat{\rho}_A(t_0)]$. $\mathcal{L}(t)$ is a trace preserving (TP) linear operator, the Liouvillian, in our case, since we have chosen the Lindblad master equation to describe the environment, or, more precisely, the aspects of the environment's behaviour that affect the system \cite[p.~1076, l.~94-95]{Lloyd}. Equating $\hat{\rho}_A(t)=\mathcal{L}(t)[\hat{\rho}_A(t_0)]$ and $\hat{\rho}_A(t)=\textrm{Tr}_B[\hat{\rho}_{AB}(t)]=\textrm{Tr}_B[\hat{U}_{AB}(t,t_0)\,\,\hat{\rho}_{AB}(t_0)\,\,\hat{U}_{AB}^\dagger(t,t_0)] \,\,\,\,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{uncorr.}}}}{=}}}\,\,\,\,\, \textrm{Tr}_B[\hat{U}_{AB}(t,t_0)\,\,\left(\hat{\rho}_A(t_0)\,\otimes\,\hat{\rho}_B(t_0)\right)\,\,\hat{U}_{AB}^\dagger(t,t_0)]$, it is clear that $\mathcal{L}(t)$ depends only on $\hat{U}_{AB}(t,t_0)$ and $\hat{\rho}_B(t_0)$.
\end{itemize}

\section{Quantum Liouville equation}
\emph{Liouville's theorem} states that the phase-space distribution function $\rho=\rho(p_i,q_i; t)$ is constant in time $t$:
\begin{equation} \label{Liouville theorem}
\dot{\rho}=\frac{dp}{dt}=0=\frac{\partial\rho}{\partial t}+\sum_{i=1}^{n}\left( \frac{\partial\rho}{\partial p_i}\dot{p}_i+\frac{\partial\rho}{\partial q_i}\dot{q}_i \right)\,\,\textrm{,}
\end{equation}
where $p_i$, conjugate momenta, and $q_i$ --the usual Cartesian coordinates, for instance-- are the canonical coordinates, and $n$, the degrees of freedom of the state space of the system. It can be restated in terms of the \emph{Poisson bracket} $\,$ \cite[p.~49, Eq.~(1.6.48)]{Sakurai}
\begin{equation} \label{poisson braket}
\left\lbrace f,g \right\rbrace_{q,p}\equiv\sum_{i=1}^N\,\left( \frac{\partial f}{\partial q_i}\frac{\partial g}{\partial p_i}-\frac{\partial f}{\partial p_i}\frac{\partial g}{\partial q_i} \right)
\end{equation}

\emph{Hamilton's equation of motion} can be written in terms of the Poisson braket, using $df=\sum_{i=1}^n\frac{\partial f}{\partial x_i}dx_i$,
% https://wikimedia.org/api/rest_v1/media/math/render/svg/61fbb7ca18d6b3741b83175c7a439449ea7d0538
\begin{equation} \label{hamilton eq motion}
\frac{d}{dt}f(p,q,t)=\frac{\partial f}{\partial p}\frac{dp}{dt}+\frac{\partial f}{\partial q}\frac{dq}{dt}+ \frac{\partial f}{\partial t}\frac{dt}{dt}=\frac{\partial f}{\partial p}\dot{p}+\frac{\partial f}{\partial q}\dot{q}+ \frac{\partial f}{\partial t}\,\textrm{.}
\end{equation}

If we define \emph{Hamilton's equations}
\begin{equation} \label{hamilton equations}
\dot{p}=\frac{dp}{dt}\equiv-\frac{\partial H}{\partial q}\,\textrm{,}\quad \textrm{and}\quad\frac{dq}{dt}=\dot{q}\equiv+\frac{\partial H}{\partial p}\,\textrm{,}
\end{equation}
where $H=H(q,p,t)$ is the Hamiltonian. Then, Eq. (\ref{hamilton eq motion}) becomes
\begin{equation} \label{hamilton with poisson}
\frac{d}{dt}f(p,q,t)=\frac{\partial f}{\partial p}\dot{p}+\frac{\partial f}{\partial q}\dot{q}+ \frac{\partial f}{\partial t}\numeq{\textrm{\ref{hamilton equations}}}\frac{\partial f}{\partial p}\left(-\frac{\partial H}{\partial q}\right)+\frac{\partial f}{\partial q}\frac{\partial H}{\partial p}+ \frac{\partial f}{\partial t}\numeq{\textrm{\ref{poisson braket}}}\left\lbrace f,H \right\rbrace_{q,p}+ \frac{\partial f}{\partial t}\,\textrm{.}
\end{equation}

Thus, Eq. (\ref{Liouville theorem}) becomes
\begin{equation} \label{Liouville equation}
\dot{\rho}=\frac{dp}{dt}=0=\frac{\partial\rho}{\partial t}+\sum_{i=1}^{n}\left( \frac{\partial\rho}{\partial p_i}\dot{p}_i+\frac{\partial\rho}{\partial q_i}\dot{q}_i \right)\numeq{\textrm{\ref{hamilton with poisson}}}\frac{\partial\rho}{\partial t}+\left\lbrace \rho,H \right\rbrace_{q,p}\quad\rightarrow\quad\frac{\partial\rho}{\partial t}=-\left\lbrace \rho,H \right\rbrace_{q,p}\,\textrm{.}
\end{equation}

The \emph{quantum Liouville equation} describes the $t$ evolution of a mixed state $\hat{\rho}$. It can be derived by replacing classical Poisson brackets by commutators, as follows: $\{.\,,.\}\,\rightarrow\,\frac{[\,.\,,\,.\,]}{i\hbar}$. Accordingly, $\,\,\,$ \cite[p.~185, Eq.~(3.4.29)]{Sakurai}

\begin{equation} \label{quantum liouville}
\frac{\partial\rho}{\partial t}=-\left\lbrace \rho,H \right\rbrace_{q,p}\quad\rightarrow\quad\frac{\partial\hat{\rho}}{\partial t}=-\frac{1}{i\hbar}[\hat{\rho},\hat{H}]
\end{equation}

For pure states $\hat{\rho}=\ket{\psi}\bra{\psi}$, Eq. (\ref{quantum liouville}) is equivalent to the Schrödinger equation $\frac{\partial\ket{\psi}}{\partial t}=\frac{1}{i\hbar}\hat{H}\ket{\psi}$.

\section{Master equations}
\href{https://en.wikipedia.org/wiki/Master_equation}{\emph{Master equation}}s are a system of first order differential equations that describe the $t$ evolution of a system: $\frac{d\vec{x}}{dt}=\mathbf{A}\,\vec{x}$, where $\vec{x}$ is a column matrix (vector) and $\mathbf{A}$ is the so-called matrix of \emph{connections}. When $\mathbf{A}\neq\mathbf{A}(t)$, the process is \emph{Markovian}, memoryless or local in time (its evolution does not depend on the past).

\emph{Quantum master equations} describe the $t$ evolution of a density operator $\hat{\rho}$.  They are \emph{not} a master equation in the \emph{usual} sense: usual master equations determine the $t$ evolution probabilities (diagonal elements of $\hat{\rho}$), but quantum master equations also govern off-diagonal elements of $\hat{\rho}$, which represent  \emph{quantum coherence} between states. The just mentioned \emph{coherence} is a basis dependent concept. The system-environment interaction singles out a specific basis. In our case, the Linblad equation choses the computational basis, as mentioned. We say a state is \emph{incoherent} if it is diagonal in the given basis.

On the other hand, the interaction process between the system and its environment is known as \emph{decoherence}. Through this events (Section \ref{environment}) the system looses its coherence (off-diagonal elements).


In principle, the master equation approach is equivalent to the Schrödinger picture or Heisenberg picture. However, it allows more easily the inclusion of incoherences, which, as said, represent environmental interactions or decoherence.

\subsection{Lindbladian}
\label{lindblad_appendix}

The Lindbladian, GKSL equation or Lindblad master equation is an approximate \emph{quantum master equation}. Any $t$ evolution satisfying the below conditions can be written in terms of the Lindbladian:
% https://www.youtube.com/watch?v=g4X7Pu32qwU
\begin{enumerate}
\item The $t$ evolution of the system can be described by a \textbf{linear} operator $\mathcal{L}$ (Liouvillian) such that: $\hat{\rho}(t)=e^{\mathcal{L}t}\,\hat{\rho}(t_0=0)$
\item $\mathcal{L}$ is a CPTP (Completely Positive Trace-Preserving) map (i.e., physical) such that $\hat{\rho}(t_0=0)\geq 0\,\rightarrow\,\hat{\rho}(t)\geq 0$ 
\item The bath's (the environment, here) description is approximate and assumed to be \emph{Markovian} (does not depend on the preceding events, but on the present state only): $\hat{\rho}(t+\tau)=e^{\mathcal{L}\,t}\hat{\rho}(\tau)=e^{\mathcal{L}\,t}e^{\mathcal{L}\,\tau}\hat{\rho}(0)$.
\end{enumerate}

 The Lindbladian, in diagonal form, for a system described by the   density operator $\hat{\rho}$ is
 \begin{equation} \label{Lindblad_general_form}
\dot{\hat{\rho}}=\frac{d}{dt}\hat{\rho}(t)=\mathcal{L}[\hat{\rho}(t)]\equiv-\frac{i}{\hbar}[\hat{H},\hat{\rho}(t)]+\sum_{i}\,\lambda_i\left(\hat{L}_i\,\hat{\rho}(t)\,\hat{L}_i^\dagger -\frac{1}{2}\left\lbrace\hat{L}_i^\dagger\,\hat{L}_i,\,\hat{\rho}(t)\right\rbrace\right)
\end{equation}
where
\begin{itemize}
\item $\lambda_i$ $\geq 0$ $:$ $i=1,...,n^2-1$ are the eigenvalues.
\item $\hat{L}_i$ is the \emph{Lindblad} or \emph{jump} operator.
\item $\{\hat{L}_i^\dagger\,\hat{L}_i,\,\hat{\rho}(t)\}=\hat{L}_i^\dagger\,\hat{L}_i\,\hat{\rho}(t)+\hat{\rho}(t)\,\hat{L}_i^\dagger\,\hat{L}_i$ is the anticommutator. 
\end{itemize} 

If $\lambda_i=0$ $\,$ $\forall i$ $\rightarrow$ $\dot{\hat{\rho}}=-\frac{i}{\hbar}[\hat{H},\hat{\rho}]$, we obtain the \emph{quantum Liouville equation} (Eq. (\ref{quantum liouville})) \cite[p.~185, Eq.~(3.4.29)]{Sakurai}, the quantum analog of the classical Liouville equation (Eq. (\ref{Liouville equation})). In fact, setting $\lambda=0$ means isolating the system, since the part of master equations multiplied by $\lambda$ describes the action of the environment.

\subsubsection{Our Lindbladian example}
In Eq. (\ref{lindblad_environ}), $\hat{H}$ and $\hat{\rho}(t)$ commute ($[\hat{H},\hat{\rho}(t)]=0$), the \emph{Lindblad} or \emph{jump} operator is $\hat{L}_i=\hat{\sigma}=\ket{0}\bra{1}$ and the dimension is 1 (so $i$ subindexes are dropped). Then, 
 \begin{equation} \label{lindbla_origin}
\dot{\hat{\rho}}=\frac{d}{dt}\hat{\rho}(t)=\lambda\left(\hat{\sigma}\,\hat{\rho}(t)\,\hat{\sigma}^\dagger -\frac{1}{2}\left\lbrace\hat{\sigma}^\dagger\,\hat{\sigma},\,\hat{\rho}(t)\right\rbrace\right)
\end{equation} 

Applying this equation to a general density operator $\hat{\rho}(t)\,\doteq\begin{pmatrix}a&b\\b^*&1-a\end{pmatrix}$ yields
\begin{equation}
\begin{split}
\frac{d}{dt}\hat{\rho}(t)
&=\lambda\left(\hat{\sigma}\,\hat{\rho}(t)\,\hat{\sigma}^\dagger -\frac{1}{2}\left\lbrace\hat{\sigma}^\dagger\,\hat{\sigma},\,\hat{\rho}(t)\right\rbrace\right)\doteq\lambda\begin{pmatrix}0&1\\0&0\end{pmatrix}\begin{pmatrix}a&b\\b^*&1-a\end{pmatrix}\begin{pmatrix}0&0\\1&0\end{pmatrix}-\lambda\frac{1}{2}\left\lbrace\begin{pmatrix}0&0\\1&0\end{pmatrix}\begin{pmatrix}0&1\\0&0\end{pmatrix},\,\hat{\rho}(t)\right\rbrace\\
&=\lambda\begin{pmatrix}0&1\\0&0\end{pmatrix}\begin{pmatrix}b&0\\1-a&0\end{pmatrix}-\lambda\frac{1}{2}\begin{pmatrix}0&0\\0&1\end{pmatrix}\begin{pmatrix}a&b\\b^*&1-a\end{pmatrix}-\lambda\frac{1}{2}\begin{pmatrix}a&b\\b^*&1-a\end{pmatrix}\begin{pmatrix}0&0\\0&1\end{pmatrix}\\
&=\lambda\begin{pmatrix}1-a&0\\0&0\end{pmatrix}-\lambda\frac{1}{2}\begin{pmatrix}0&0\\b^*&1-a\end{pmatrix}-\lambda\frac{1}{2}\begin{pmatrix}0&b\\0&1-a\end{pmatrix}=-\lambda\begin{pmatrix}a-1&b/2\\b^*/2&1-a\end{pmatrix}
\end{split}
\end{equation}
Hence, the solution of the Lindblad equation is
\begin{equation} 
\begin{split}
\bullet\,
&\frac{d}{dt}(\hat{\rho}(t))_{11}=\lambda(1-a)=\frac{da}{dt}\rightarrow \frac{da}{1-a}=\lambda dt \rightarrow -\ln(1-a)+C_1=\lambda t \xrightarrow[a(t=0)\equiv a_0]{t=0} -\ln(1-a)+C_1=0 \rightarrow\\
&  \ln\left(  \frac{1-a}{1-a_0}\right)= -\lambda t \rightarrow a=a(t)=1+e^{-\lambda t}(a_0-1)
\end{split}
\end{equation}
\begin{equation} 
\begin{split}
\bullet\,
&\frac{d}{dt}(\hat{\rho}(t))_{12}=-\lambda b/2=\frac{db}{dt} \rightarrow \frac{db}{b}=-\frac{\lambda}{2}dt \rightarrow \ln(b)+C_2=-\frac{\lambda}{2}t \xrightarrow[b(t=0)\equiv b_0]{t=0} \ln(b_0)+C_2=0 \rightarrow \\
&\ln(\frac{b}{b_0})=-\frac{\lambda}{2}t \rightarrow b=b(t)=b_0 e^{-\lambda t/2}
\end{split}
\end{equation}
These solutions can be viewed as $\hat{\rho}(t)=\sum_k\,\hat{M}_k\,\hat{\rho}(0)\,\hat{M}_k^\dagger$ with $\eta\equiv 1-e^{-\lambda t}$ and the following Kraus operators:
\begin{equation} \label{Lindblad_kraus_ops}
\hat{M}_0\doteq\begin{pmatrix}1&0\\0&\sqrt[]{1-\eta}\end{pmatrix}\,\textrm{,}\quad\textrm{and}\quad\hat{M}_1\doteq\begin{pmatrix}0&\sqrt[]{\eta}\\0&0\end{pmatrix}\,\textrm{.}
\end{equation}
Proof:
\begin{equation}
\begin{split}
\hat{\rho}(t)
&=\sum_k\,\hat{M}_k\,\hat{\rho}(0)\,\hat{M}_k^\dagger =  \hat{M}_0\,\hat{\rho}(0)\,\hat{M}_0^\dagger + \hat{M}_1\,\hat{\rho}(0)\,\hat{M}_1^\dagger \doteq \begin{pmatrix}1&0\\0&\sqrt[]{1-\eta}\end{pmatrix} \begin{pmatrix}a&b\\b^*&1-a\end{pmatrix} \begin{pmatrix}1&0\\0&\sqrt[]{1-\eta}\end{pmatrix}+\\ &\begin{pmatrix}0&\sqrt[]{\eta}\\0&0\end{pmatrix} \begin{pmatrix}a&b\\b^*&1-a\end{pmatrix} \begin{pmatrix}0&0\\\sqrt[]{\eta}&0\end{pmatrix}=\begin{pmatrix}1&0\\0&\sqrt[]{1-\eta}\end{pmatrix} \begin{pmatrix}a&b\,\sqrt[]{1-\eta}\\b^*&(1-a)\,\sqrt[]{1-\eta}\end{pmatrix}+\begin{pmatrix}0&\sqrt[]{\eta}\\0&0\end{pmatrix}\begin{pmatrix}b\,\sqrt[]{\eta}&0\\(1-a)\,\sqrt[]{\eta}&0\end{pmatrix}\\
&=\begin{pmatrix}a&b\,\sqrt[]{1-\eta}\\b^*\,\sqrt[]{1-\eta}&(1-a)\,(1-\eta)\end{pmatrix}+\begin{pmatrix}(1-a)\,{\eta}&0\\0&0\end{pmatrix}= \begin{pmatrix}a+(1-a)\eta&b\,\sqrt[]{1-\eta}\\b^*\,\sqrt[]{1-\eta}&(1-a)\,(1-\eta)\end{pmatrix}\,\textrm{. QED}
\end{split}
\end{equation}
In our particular case, $b\rightarrow b+ic$, so that $\hat{\rho}\rightarrow\hat{\rho}_{g_0}$. Equation (\ref{Lindblad_kraus_ops}) is a valid set of Kraus operators since 
\begin{equation}
\begin{split}
\sum_k\,\hat{M}_k^\dagger\,\hat{M}_k
&=\hat{M}_0^\dagger\,\hat{M}_0 + \hat{M}_1^\dagger\,\hat{M}_1 \doteq \begin{pmatrix}1&0\\0&\sqrt[]{1-\eta}\end{pmatrix}\begin{pmatrix}1&0\\0&\sqrt[]{1-\eta}\end{pmatrix}+ \begin{pmatrix}0&0\\\sqrt[]{\eta}&0\end{pmatrix}\begin{pmatrix}0&\sqrt[]{\eta}\\0&0\end{pmatrix} \\
&= \begin{pmatrix}1&0\\0&{1-\eta}\end{pmatrix}+ \begin{pmatrix}0&0\\0&{\eta}\end{pmatrix}=\hat{1}_2\,\textrm{.}
\end{split}
\end{equation}
\begin{itemize}
\item For $t=0$ $\rightarrow$ $\eta=1-e^{-\lambda 0}=1-1=0$ we recover the initial state $\hat{\rho}(t=0)$,  \begin{equation}
\hat{\rho}(t=0)\,\doteq \begin{pmatrix}a+(1-a) 0&b\,\sqrt[]{1-0}\\b^*\,\sqrt[]{1-0}&(1-a)\,(1-0)\end{pmatrix} = \begin{pmatrix}a&b\\b^*&1-a\end{pmatrix} \doteq \hat{\rho}(t=0)
\end{equation} \label{Lindblad_evol_infinity}
\item For $t=\infty$ $\rightarrow$ $\eta=1-e^{-\lambda \infty}=1-0=1$, conversely, \begin{equation}
\hat{\rho}(t=\infty)\,\doteq \begin{pmatrix}a+(1-a) 1&b\,\sqrt[]{1-1}\\b^*\,\sqrt[]{1-1}&(1-a)\,(1-1)\end{pmatrix} = \begin{pmatrix}1&0\\0&0\end{pmatrix} \doteq \ket{0}\bra{0}
\end{equation}
Regardless of the initial state $\hat{\rho}(t=0)$, as mentioned, the Lindbladian pushes the system towards its steady state $\ket{0}$, by destroying all coherences (off-diagonal elements). It can be considered that it describes a zero temperature effect, if we take $\ket{0}$ as the ground, or lowest energy, state.
\end{itemize}

\subsubsection{Proof of Lindblad's theorem}
%http://www.fmt.if.usp.br/~gtlandi/11---lindblad-equation-2.pdf
According to Lindblad's theorem, any quantum operation $\hat{\rho}^\prime=\sum_k\hat{M}_{k}\hat{\rho}\hat{M}_{k}^\dagger$ that is divisible (\emph{semigroup property}) can be written in the form of Eq. (\ref{Lindblad_general_form}). 

The evolution over an infinitesimal time $\Delta t$ is $\hat{\rho}(t+\Delta t)\,=\sum_k\hat{M}_{k}(\Delta t)\,\hat{\rho}(t)\,\hat{M}_{k}^\dagger(\Delta t)$. This statement confirms that the Lindbladian is \emph{Markovian}: $\hat{\rho}(t+\Delta t)$ depends only on $\hat{\rho}(t)$, not on any previous time $\tau<t$. On the other hand, we can also work out the Taylor expansion $\hat{\rho}(t+\Delta t)\approx \hat{\rho}(t)+(\frac{d}{dt}\hat{\rho}(t))\,\Delta t= \hat{\rho}(t)+\mathcal{L}[\hat{\rho}(t)]\,\Delta t$, where we used  $\frac{d}{dt}\hat{\rho}(t)=\mathcal{L}[\hat{\rho}(t)]$ from Eq. (\ref{Lindblad_general_form}). The following conditions ought to be fulfilled:
\begin{itemize}
\item For $k\neq 0$, $\hat{\rho}(t+\Delta t)\,=\sum_k\hat{M}_{k}(\Delta t)\,\hat{\rho}(t)\,\hat{M}_{k}^\dagger(\Delta t) \approx \hat{\rho}(t)+(\frac{d}{dt}\hat{\rho}(t))\,\Delta t$ $\leftrightarrow$ $\hat{M}_{k}(\Delta t)\,\hat{\rho}(t)\,\hat{M}_{k}^\dagger(\Delta t) \approx \mathcal{O}(\Delta t)$ $\leftrightarrow$ $\hat{M}_{k}(\Delta t)=\sqrt[]{\Delta t}\,\hat{L}_k$, for an arbitrary operator $\hat{L}_k$.
\item For $k= 0$, $\hat{\rho}(t+\Delta t)|_{\Delta t=0}\,=\hat{M}_{0}(0)\,\hat{\rho}(t)\,\hat{M}_{0}^\dagger(0) \approx \hat{\rho}(t)+(\frac{d}{dt}\hat{\rho}(t))\,0=\hat{\rho}(t)$ $\rightarrow$ $\hat{M}_{0}=\hat{1}+\hat{G}\,\Delta t$, for an arbitrary operator $\hat{G}$. Then, $\hat{M}_{0}|_{\Delta t = 0}=\hat{1}+\hat{G}\,0 = \hat{1}$
\end{itemize}

$\hat{M}_{0}=\hat{1}+\hat{G}\,\Delta t \neq \hat{1}$ so that the normalization condition for the Kraus operators can be satisfied:
\begin{equation} \label{Lindblad_kraus_normalization}
\begin{split}
\hat{1}
&=\sum_k\,\hat{M}_{k}^\dagger\,\hat{M}_{k} = \hat{M}_{0}^\dagger\,\hat{M}_{0} + \sum_{k\neq 0}\,\hat{M}_{k}^\dagger\,\hat{M}_{k} = (\hat{1}+\hat{G}^\dagger\,\Delta t)(\hat{1}+\hat{G}\,\Delta t) + \sum_{k\neq 0}\,\sqrt[]{\Delta t}\,\hat{L}_k^\dagger\,\sqrt[]{\Delta t}\,\hat{L}_k\\
&=\hat{1}+\hat{G}\,\Delta t +\hat{G}^\dagger\,\Delta t + \hat{G}\hat{G}^\dagger\,(\Delta t)^2 + \Delta t\,\sum_{k\neq 0}\,\hat{L}_k^\dagger\,\hat{L}_k =\hat{1}+\Delta t(\hat{G}+\hat{G}^\dagger) + \Delta t\,\sum_{k\neq 0}\,\hat{L}_k^\dagger\,\hat{L}_k + \mathcal{O}(\Delta t)^2\,\textrm{.}
\end{split}
\end{equation}
Defining $\hat{G}$ arbitrarily, in terms of the Hermitian operators $\hat{K}$ and $\hat{H}$, as $\hat{G}=\hat{K}-\frac{i}{\hbar}\,\hat{H}$, the normalization condition Eq. (\ref{Lindblad_kraus_normalization}) leads to 
\begin{equation} \label{K_operator_lindblad}
\hat{1}=\hat{1}+\Delta t(\hat{K}-\frac{i}{\hbar}\,\hat{H}+\hat{K}+\frac{i}{\hbar}\,\hat{H}) + \Delta t\,\sum_{k\neq 0}\,\hat{L}_k^\dagger\,\hat{L}_k + \mathcal{O}(\Delta t)^2\approx\hat{1}+2\hat{K}\,\Delta t +\Delta t\,\sum_{k\neq 0}\,\hat{L}_k^\dagger\,\hat{L}_k \rightarrow \hat{K}\approx-\frac{1}{2}\,\sum_{k\neq 0}\,\hat{L}_k^\dagger\,\hat{L}_k\,\textrm{,}
\end{equation}
whereas nothing can be said about $\hat{H}$. Then, we get
\begin{equation}
\begin{split}
\hat{\rho}(t+\Delta t)
&=\sum_k\hat{M}_{k}(\Delta t)\,\hat{\rho}(t)\,\hat{M}_{k}^\dagger(\Delta t)=\hat{M}_{0}(\Delta t)\,\hat{\rho}(t)\,\hat{M}_{0}^\dagger(\Delta t) + \sum_{k\neq 0}\hat{M}_{k}(\Delta t)\,\hat{\rho}(t)\,\hat{M}_{k}^\dagger(\Delta t)\\ 
&= (\hat{1}+\hat{G}^\dagger\,\Delta t)\,\hat{\rho}(t)\,(\hat{1}+\hat{G}\,\Delta t) + \sum_{k\neq 0}\,\sqrt[]{\Delta t}\,\hat{L}_k\,\hat{\rho}(t)\,\sqrt[]{\Delta t}\,\hat{L}_k^\dagger\\
&=\hat{\rho}(t)+ \Delta t	\, \left(\hat{\rho}(t)\hat{G}^\dagger+\hat{G}\hat{\rho}(t)\right) + \Delta t \sum_{k\neq 0}\,\hat{L}_k\,\hat{\rho}(t)\,\hat{L}_k^\dagger + \mathcal{O}(\Delta t)^2\\
&=\hat{\rho}(t)+ \Delta t	\, \left(\hat{\rho}(t)(\hat{K}+\frac{i}{\hbar}\,\hat{H})+(\hat{K}-\frac{i}{\hbar}\,\hat{H})\hat{\rho}(t)\right) + \Delta t \sum_{k\neq 0}\,\hat{L}_k\,\hat{\rho}(t)\,\hat{L}_k^\dagger + \mathcal{O}(\Delta t)^2\\
&=\hat{\rho}(t)+ \Delta t \{\hat{K},\hat{\rho}(t)\}-\frac{i}{\hbar}\,\Delta t\,[\hat{H},\hat{\rho}(t)] + \Delta t \sum_{k\neq 0}\,\hat{L}_k\,\hat{\rho}(t)\,\hat{L}_k^\dagger + \mathcal{O}(\Delta t)^2\\
&\numeq{\textrm{\ref{K_operator_lindblad}}}\hat{\rho}(t)-\frac{i}{\hbar}\,\Delta t\,[\hat{H},\hat{\rho}(t)] + \Delta t\,\sum_{k\neq 0} \left[ \hat{L}_k\,\hat{\rho}(t)\,\hat{L}_k^\dagger -\frac{1}{2}\{\hat{L}_k^\dagger\,\hat{L}_k,\,\hat{\rho}(t)\}  \right] + \mathcal{O}(\Delta t)^2\,\textrm{.}
\end{split}
\end{equation}
We finally obtain
\begin{equation} 
\begin{split}
\frac{\hat{\rho}(t+\Delta t)-\hat{\rho}(t)}{\Delta t}
&\approx-\frac{i}{\hbar}\,[\hat{H},\hat{\rho}(t)] +\sum_{k\neq 0} \left[ \hat{L}_k\,\hat{\rho}(t)\,\hat{L}_k^\dagger -\frac{1}{2}\{\hat{L}_k^\dagger\,\hat{L}_k,\,\hat{\rho}(t)\}  \right]
\end{split}\,\textrm{.}
\end{equation}
In the limit $\Delta t\to 0$ and making the change of variable $\hat{L}_k\leftrightarrow \hat{L}_k\,\sqrt[]{\lambda_k}$ we recover Eq. (\ref{Lindblad_general_form}). QED


\subsubsection{Vectorization} \label{vectorization}
In order to analyze the steady states of the Lindblad equation (Section \ref{steady_Lindblad}), first we have to introduce the concept of \emph{vectorization}. It consists on thinking of \emph{superoperators}, operators that act on operators, --the Linbladian $\mathcal{L}$, in our case-- as big matrices multiplying a big vector --$\hat{\rho}$, in our instance--. Vectorizing is based on the following relation:
\begin{equation} \label{vectorization}
\textrm{vec}(\ket{a}\bra{b})=\ket{b}\otimes\ket{a}\equiv\ket{b}\ket{a}\,\textrm{,}
\end{equation}
which is equivalent to thinking about a matrix as being a vector. For example, $\hat{1}$ vectorizes to (unnormalized) Bell states of the form of Eq. (\ref{Bell_plus_state}), $\textrm{vec}(\hat{1})=\textrm{vec}(\sum_a\,\ket{a}\bra{a}.)\numeq{\textrm{\ref{vectorization}}} \sum_a\,\ket{a}\otimes\ket{a}$. In other words, the vec(.) operator creates a column vector stacking the columns of the matrix representation of the operator it acts on:
\begin{equation} \label{vectorization_matrix}
\textrm{vec}\begin{pmatrix}a&b\\c&d\end{pmatrix}=\begin{pmatrix}a\\c\\b\\d\end{pmatrix}\,\textrm{.}
\end{equation}
We will use the following property:
\begin{equation} \label{vectorization_property}
\textrm{vec}(\hat{A}\hat{B}\hat{C})=(\hat{C}^T \otimes\hat{A})\,\textrm{vec}(\hat{B})\,\textrm{.}
\end{equation}
\emph{Proof}:
\begin{equation} \label{ABC_matrix_form}
\hat{A}\hat{B}\hat{C}=\sum_{a,b,c,d,e,f}\,(A_{ab}\ket{a}\bra{b})\,(B_{cd}\ket{c}\bra{d})\,(C_{ef}\ket{e}\bra{f}) = \sum_{a,b,c,d,e,f}\,A_{ab}\,B_{cd}\,C_{ef}\,\delta_{bc}\delta_{de}\ket{a}\bra{f}=  \sum_{a,b,e,f}\,A_{ab}\,B_{be}\,C_{ef}\,\ket{a}\bra{f}\textrm{.}
\end{equation}
Hence, 
\begin{equation} \label{vec_ABC}
\textrm{vec}(\hat{A}\hat{B}\hat{C}) \numeq{\textrm{\ref{ABC_matrix_form}}} \textrm{vec}\left(\sum_{a,b,e,f}\,A_{ab}\,B_{be}\,C_{ef}\,\ket{a}\bra{f}\right) \numeq{\textrm{\ref{vectorization}}} \sum_{a,b,e,f} \,A_{ab}\,B_{be}\,C_{ef}\,\ket{f}\otimes\ket{a}\,\textrm{.}
\end{equation}
On the other hand, 
\begin{equation}
\begin{split}
(\hat{C}^T \otimes\hat{A})\,\textrm{vec}(\hat{B})
&=\sum_{a,b,c,d,e,f}\left((C_{ef}\ket{e}\bra{f})^T \otimes(A_{ab}\ket{a}\bra{b})\right)\,\textrm{vec}(B_{be}\ket{b}\bra{e})\\ 
&\numeq{1} \sum_{a,b,c,d,e,f} \left( C_{ef}^*\,(\ket{f}\bra{e})^* \otimes A_{ab}\ket{a}\bra{b} \right)\, (B_{be}\ket{e}\otimes\ket{b})\\
&\numeq{2} \sum_{a,b,c,d,e,f} \left( C_{ef}\,\ket{f}\bra{e} \otimes A_{ab}\ket{a}\bra{b} \right)\, (B_{be}\ket{e}\otimes\ket{b}) \\
&\numeq{3} \sum_{a,b,c,d,e,f}  C_{ef}\,A_{ab}\,B_{be}\ket{f} \otimes \ket{a} = \textrm{(\ref{vec_ABC}). QED}
\end{split}
\end{equation}
where in $(1)$ we used $(\ket{a}\bra{b})^T=([\ket{b}\bra{a}]^\dagger)^T = ([(\ket{b}\bra{a})^*]^T)^T = (\ket{b}\bra{a})^* $ and Eq. (\ref{vectorization}); in $(2)$, we considered the real vector space instead of the complex one, so that $(\ket{a})^*=\ket{a}$ and $A_{ab}^*=A_{ab}$; and, in $(3)$, $(\hat{A}\otimes\hat{B})\,(\hat{C}\otimes\hat{D})=\hat{A}\hat{C}\otimes\hat{B}\hat{D}$  $\blacksquare$\\

\subsubsection{Steady states of the Lindblad equation} \label{steady_Lindblad}
Now we are ready to find the \emph{steady states} of the Lindblad equation. Using the property defined in Eq. (\ref{vectorization_property}), we can write the Lindbladian, Eq. (\ref{Lindblad_general_form}), as
\begin{equation} \label{Lindblad_vectorization}
\begin{split}
&\textrm{vec} \left\lbrace   \dot{\hat{\rho}} = -\frac{i}{\hbar}[\hat{H},\hat{\rho}(t)]+\sum_{i}\,\lambda_i\left(\hat{L}_i\,\hat{\rho}(t)\,\hat{L}_i^\dagger -\frac{1}{2}\left\lbrace\hat{L}_i^\dagger\,\hat{L}_i,\,\hat{\rho}(t)\right\rbrace\right) \right\rbrace \numeq{\textrm{lin.}} -\frac{i}{\hbar}\,\textrm{vec} \left\lbrace \hat{H}\hat{\rho}\hat{1} - \hat{1}\hat{\rho}\hat{H}  \right\rbrace \\
&+\sum_i\,\lambda_i\,\textrm{vec} \left\lbrace  \hat{L}_i\,\hat{\rho}(t)\,\hat{L}_i^\dagger -\frac{1}{2}\left([\hat{L}_i^\dagger\,\hat{L}_i]\,\hat{\rho}(t)\hat{1} + \hat{1}\hat{\rho}(t)\,[\hat{L}_i^\dagger\,\hat{L}_i]  \right) \right\rbrace  \numeq{\textrm{\ref{vectorization_property}}} -\frac{i}{\hbar}\,\left\lbrace \hat{1}^T\otimes\hat{H} -  \hat{H^T}\otimes\hat{1} \right\rbrace\textrm{vec}(\hat{\rho}) \\
& +\sum_i\,\lambda_i\, \left\lbrace  (\hat{L}_i^\dagger)^T\otimes\hat{L}_i -\frac{1}{2}\left(\hat{1}^T\otimes\hat{L}_i^\dagger\,\hat{L}_i + [\hat{L}_i^\dagger\,\hat{L}_i]^T\otimes\hat{1}  \right) \right\rbrace \textrm{vec}(\hat{\rho})\\
&\numeq{1} \left( -\frac{i}{\hbar}\,\left\lbrace \hat{1}\otimes\hat{H} -  \hat{H^T}\otimes\hat{1} \right\rbrace +\sum_i\,\lambda_i\, \left\lbrace  \hat{L}_i^*\otimes\hat{L}_i -\frac{1}{2}\left(\hat{1}\otimes\hat{L}_i^\dagger\,\hat{L}_i + [\hat{L}_i^\dagger\,\hat{L}_i]^T\otimes\hat{1}  \right) \right\rbrace\,\right) \textrm{vec}(\hat{\rho})\\
&= \hat{\mathcal{L}}\,\,\textrm{vec}(\hat{\rho}) \numeq{\textrm{\ref{Lindblad_general_form}}} \frac{d}{dt}\,\textrm{vec}(\hat{\rho})  \,\textrm{,}
\end{split}
\end{equation} 
where in $(1)$ we used $\hat{1}^T=\hat{1}$ and $(\hat{L}_i^\dagger)^T=((\hat{L}_i^*)^T)^T=\hat{L}_i^*$ $\,$. For instance, the vectorized version of Eq.(\ref{lindbla_origin}) is 
\begin{equation}
\hat{\mathcal{L}}\,\,\textrm{vec}(\hat{\rho}) =  \lambda\, \left\lbrace  \hat{\sigma}^*\otimes\hat{\sigma} -\frac{1}{2}\left(\hat{1}\otimes\hat{\sigma}^\dagger\,\hat{\sigma} + [\hat{\sigma}^\dagger\,\hat{\sigma}]^T\otimes\hat{1}  \right) \right\rbrace\,\textrm{vec}(\hat{\rho})\,\textrm{.}
\end{equation}
Hence, the postvectorized matrix representation of the Liouvillian superoperator is
\begin{equation} \label{Liouvillian_matrix}
\begin{split}
\hat{\mathcal{L}}
&=  \lambda\, \left\lbrace \begin{pmatrix}0&1\\0&0\end{pmatrix}\otimes \begin{pmatrix}0&1\\0&0\end{pmatrix}  -\frac{1}{2}\left(\hat{1}\otimes\begin{pmatrix}0&0\\1&0\end{pmatrix}\begin{pmatrix}0&1\\0&0\end{pmatrix} + [\hat{\sigma}^\dagger\,\hat{\sigma}]^T\otimes\hat{1}  \right) \right\rbrace\\
&= \lambda\, \left\lbrace \begin{pmatrix}0&0&0&1\\0&0&0&0\\0&0&0&0\\0&0&0&0\end{pmatrix} -\frac{1}{2} \left( \begin{pmatrix}0&0&&\\0&1&&\\&&0&0\\&&0&1\end{pmatrix} + \begin{pmatrix}0&0&0&0\\0&0&0&0\\0&0&1&\\0&0&&1\end{pmatrix}\right) \right\rbrace = -\frac{\lambda}{2} \begin{pmatrix}0&0&0&-2\\0&1&0&0\\0&0&1&0\\0&0&0&2
\end{pmatrix}\,\textrm{.}
\end{split}
\end{equation}
It is not Hermitian, so it will have different right $\ket{a}$ and left $\ket{b}$ eigenvectors:
\begin{equation} \label{right_left_eigenvectors}
\hat{\mathcal{L}}\textrm{vec}(a)=\gamma\textrm{vec}(a)\,\textrm{,}\quad\textrm{and}\quad\textrm{vec}(b)^\dagger\hat{\mathcal{L}}=\textrm{vec}(b)^\dagger\gamma
\end{equation}
On the other hand,  the normalization of the density operator $\hat{\rho}$ can be vectorized in the following way:
\begin{equation} \label{trace_vectorization}
\hat{1}=\textrm{Tr}(\hat{\rho})=\textrm{Tr}(\hat{1}^\dagger\hat{\rho})\numeq{1}\textrm{vec}(\hat{1})^\dagger\textrm{vec}(\hat{\rho})
\end{equation}
where in $(1)$ we used $\textrm{Tr}(\hat{A}^\dagger\hat{B})=\textrm{vec}(\hat{A})^\dagger\textrm{vec}(\hat{B})$. Since trace must be preserved, its time derivative will be zero:
\begin{equation} \label{Liouvillian_zero_eigenval}
\begin{split}
0 
&= \frac{d}{dt} \hat{1}\numeq{\textrm{\ref{trace_vectorization}}} \frac{d}{dt} \left( \textrm{vec}(\hat{1})^\dagger\textrm{vec}(\hat{\rho}) \right) = \frac{d}{dt} \left( \textrm{vec}(\hat{1})^\dagger\right) \textrm{vec}(\hat{\rho})  + \textrm{vec}(\hat{1})^\dagger\,\frac{d}{dt} \left( \textrm{vec}(\hat{\rho})\right)\\
&=  0 + \textrm{vec}(\hat{1})^\dagger\,\frac{d}{dt} \left( \textrm{vec}(\hat{\rho})\right) \numeq{\textrm{\ref{Lindblad_vectorization}}} \textrm{vec}(\hat{1})^\dagger \hat{\mathcal{L}}\textrm{vec}(\hat{\rho}) \,\, \overbrace{\leftrightarrow}^{\textrm{vec}(\hat{\rho})\neq 0} \,\, \textrm{vec}(\hat{1})^\dagger \hat{\mathcal{L}} = 0 \,\,\textrm{.}
\end{split} 
\end{equation}
Hence, using Eq. (\ref{right_left_eigenvectors}b) we can infer that $\textrm{vec}(\hat{1})$ is \emph{always} a left eigenstate of $\mathcal{L}$ with eigenvalue 0. On the other hand, the 0 eigenvalued left eigenfunction ($\hat{\rho}^{\gamma=0}$) is known as the \emph{steady state}: from Eq. (\ref{right_left_eigenvectors}a), $\hat{\mathcal{L}}\textrm{vec}(\hat{\rho}^{\gamma=0})=0$, or, equivalently, $\mathcal{L}[\hat{\tilde{\rho}}]=0$. Id est, a trace preserving Lindbladian must have $\gamma=0$ and its left (right) eigenvector is the $\hat{1}$ (the steady state $\hat{\rho}^{\gamma=0}$).
% http://www.fmt.if.usp.br/~gtlandi/lecture-notes-2.pdf,    Eq. (4.97)

\subsubsection{Steady state(s) of our Lindblad equation}
Let us find the steady state(s) corresponding to Eq. (\ref{lindbla_origin}). Using Eq. (\ref{Liouvillian_matrix}),

\begin{equation} 
\begin{split}
|\hat{\mathcal{L}}-\gamma\hat{1}|
&=0 \doteq \begin{vmatrix}-{\gamma}&0&0&+\lambda\\0&-\frac{\lambda}{2} -{\gamma}&0&0\\0&0&-\frac{\lambda}{2}-{\gamma}&0\\0&0&0&-\lambda-{\gamma}\end{vmatrix} = (-{\gamma})(\frac{\lambda}{2}+{\gamma})^2 (-\lambda-{\gamma}) \, \rightarrow \, \gamma= 0,-\frac{\lambda}{2} (g=2), -\lambda
\,\textrm{.}
\end{split}
\end{equation}
Thus, for $\lambda=0$, 
\begin{equation}
\begin{split}
&\begin{pmatrix}-{0}&0&0&+\lambda\\0&-\frac{\lambda}{2} -{0}&0&0\\0&0&-\frac{\lambda}{2}-{0}&0\\0&0&0&-\lambda-{0}\end{pmatrix} \begin{pmatrix}a\\b\\c\\d\\\end{pmatrix}=0 \, \leftrightarrow \, d=0,\,b=0,\,c=0,\,\forall a \,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{a=1}}}}{\rightarrow}}}\,\, \textrm{vec}(\hat{\rho}^{\gamma=0}) \doteq  \begin{pmatrix}1\\0\\0\\0\end{pmatrix}  \,\,\newcommand\myek1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{(\ref{vectorization_matrix})}}}}{\rightarrow}}}\\
&\hat{\rho}^{\gamma=0} \doteq \begin{pmatrix}1&0\\0&0\end{pmatrix} \doteq \ket{0}\bra{0}\,\,\,\textrm{is the \emph{steady state} of our Lindblad equation.}
\end{split}
\end{equation}




We saw in Eq. (\ref{Lindblad_evol_infinity}) that the system evolves towards the steady state of the Lindbladian. This occurs when the steady state is \emph{unique}, like in our case. We will prove it for a general case:\\
% http://www.fmt.if.usp.br/~gtlandi/lecture-notes-2.pdf  , p. 126

The diagonal decomposition of $\hat{\mathcal{L}}$ is
\begin{equation} \label{Liouvillian_diagonal_decomposition}
\hat{\mathcal{L}}=S\,\Gamma\,S^{-1}=\sum_{i=1}^{n^2-1}\,\gamma_i\,\textrm{vec}(a)_i\,\textrm{vec}(b)^\dagger_i\,\,\textrm{,}
\end{equation}
where $\Gamma\equiv \oplus_{i=1}^{n^2-1}\,\gamma_i =\textrm{diag}\{ \gamma_1,\,...,\,\gamma_{n^2-1}\}$ and --see Eq. (\ref{right_left_eigenvectors})-- $S$ [$S^{-1}$] is a matrix whose columns [rows] are the right [conjugate of the left] eigenfunctions $\textrm{vec}(a)$ [$\textrm{vec}(b)^\dagger$].\\

On the other hand, from Eq. (\ref{Lindblad_vectorization}),
\begin{equation} \label{Liou_diag_decomp}
\begin{split}
&\hat{\mathcal{L}}\,\,\textrm{vec}(\hat{\rho}(t)) = \frac{d}{dt}\,\textrm{vec}(\hat{\rho}(t))\,\rightarrow\,\hat{\mathcal{L}}\,\,dt = \frac{d\textrm{vec}(\hat{\rho}(t))}{\textrm{vec}(\hat{\rho}(t))}\,\,\rightarrow\, \hat{\mathcal{L}}\,\,t = \ln(\frac{\textrm{vec}(\hat{\rho}(t))}{\textrm{vec}(\hat{\rho}(0))})   \,\,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny \textrm{(1)}}}}{\rightarrow}}}\,\,\,\textrm{vec}(\hat{\rho}(t)) = e^{\hat{\mathcal{L}}t}\,\textrm{vec}(\hat{\rho}(0))\\
&\numeq{\textrm{\ref{Liouvillian_diagonal_decomposition}}}
\sum_{i=1}^{n^2-1}\,e^{\gamma_it}\,\textrm{vec}(a)_i\,\textrm{vec}(b)^\dagger_i\,\,\,\textrm{vec}(\hat{\rho}(0))= \sum_{i=1}^{n^2-1}\, \left[\textrm{vec}(\hat{\rho}(0))\,\textrm{vec}(b)^\dagger_i\right]\,\,\,e^{\gamma_it}\,\textrm{vec}(a)_i \equiv \sum_{i=1}^{n^2-1}\, c_i(t=0)\,\,\,e^{\gamma_it}\,\textrm{vec}(a)_i \,\textrm{,}
\end{split}
\end{equation}
which is analog to the usual solution of the Schrödinger equation \cite[p.~72, Eq.~(2.1.38)]{Sakurai} $\,\,$ $\ket{\psi,\,t_0=0; t}=\sum_i\,c_i(t=0)\ket{i}e^{-i\,E_i\,t/\hbar}$, if $\textrm{vec}(\hat{\rho}(t))\rightarrow \ket{\psi,\,t_0=0;t}$, $\,$ $\textrm{vec}(a)_i\rightarrow\ket{i}$ , $\,$ $c_i(t=0)\equiv\textrm{vec}(b)^\dagger_i \textrm{vec}(\hat{\rho}(0))\rightarrow c_i(t=0)\equiv \braket{i|\psi}$ $\equiv \braket{i|\psi,\,t_0=0}$ $\,$ and $\gamma_i\rightarrow -i\,E_i/\hbar$  . Note that, in $(1)$, we should be careful with the fact that $\textrm{vec}(\hat{\rho}(0))\,e^{\hat{\mathcal{L}}t} \neq e^{\hat{\mathcal{L}}t}\,\textrm{vec}(\hat{\rho}(0))$.

In order to ensure that $\lim_{t\to\infty}e^{\gamma_it}\neq \infty$, $\textrm{Re}(\gamma_i)<0$. If we suppose, as in our case, that $\gamma_{i=0}=0$ is not degenerate, Eq. (\ref{Liou_diag_decomp}) can adopt the form 
\begin{equation}
\begin{split}
\textrm{vec}(\hat{\rho}(t)) 
&= \sum_{i=1}^{n^2-1}\, c_i(t=0)\,\,\,e^{\gamma_it}\,\textrm{vec}(a)_i = \sum_{i=0}^{n^2-2}\, c_i(0)\,\,\,e^{\gamma_it}\,\textrm{vec}(a)_i = c_0(0)\,\,\,e^{0\,t}\,\textrm{vec}(a)_0 \\
& + \sum_{i=1}^{n^2-2}\, c_i(0)\,\,\,e^{\gamma_it}\,\textrm{vec}(a)_i \numeq{1} \textrm{vec}(a)_0 + \sum_{i=1}^{n^2-2}\, c_i(0)\,\,\,e^{\gamma_it}\,\textrm{vec}(a)_i\,\,\textrm{,}
\end{split}
\end{equation}
where in $(1)$ we used $c_0(0)=\textrm{vec}(\hat{\rho}(0))\,\textrm{vec}(b)^\dagger_0 \numeq{\textrm{\ref{Liouvillian_zero_eigenval}}} \textrm{vec}(\hat{\rho}(0))\,\textrm{vec}(\hat{1})^\dagger = \textrm{vec}(\hat{1})^\dagger\,\textrm{vec}(\hat{\rho}(0)) \numeq{\textrm{\ref{trace_vectorization}}} 1$ (trace preservation). In the $t\to \infty$ limit,
\begin{equation}
\begin{split}
\lim_{t\to\infty}\textrm{vec}(\hat{\rho}(t)) 
= \textrm{vec}(a)_0 + \sum_{i=1}^{n^2-2}\, c_i(0)\,\,\,e^{\gamma_i(t=\infty)}\,\textrm{vec}(a)_i \,\,\,\,\,\,\newcommand\myeq1{\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny $\textrm{Re}(\gamma_i)<0$}}}{=}}}\,\,\,\,\,\,\textrm{vec}(a)_0\,\,\textrm{.}
\end{split}
\end{equation}
So if the \emph{steady state is unique}, the system evolves toward it. QED
% http://www.fmt.if.usp.br/~gtlandi/lecture-notes-2.pdf   , p. 127












\section{Entanglement} \label{Entanglement}
Entangled states $\ket{\psi}_{AB}=\sum_{i,j}\,c_{ij}\ket{i}_A\ket{j}_B$ ($c_{ij}\neq a_i b_j$, normalized complex parameters) are not expressible as the product of their constituent states , $\ket{i}_A\ket{j}_B$ $:$ $i,j\in\{0,1\}$. Id est, an entangled state is definite states of a multipartite quantum system as a whole in which neither constituent by itself has a definite state: multiqubit  system that  cannot  be  reduced  to a product of the single qubits forming the system. In entangled states, single qubits lose their individuality and become a part of the system as a single entity.

 They exhibit correlations that have no classical analog. To see this in first hand, consider the Bell state or entangled bipartite state (triplet) of the form
\begin{equation} \label{Bell_plus_state}
\ket{\psi^+}=\frac{\ket{01}+\ket{10}}{\sqrt[]{2}}\equiv\frac{\ket{0}_A\ket{1}_B+\ket{1}_A\ket{0}_B}{\sqrt[]{2}}\in\mathcal{H}_{AB}=\mathcal{H}_A\otimes\mathcal{H}_B\,\textrm{,}
\end{equation}
as any Bell state, is \emph{maximally entangled}: entangled, because there is no way of expressing it as a list of one-qubit states, and, maximally entangled, because a measurement (in any basis, along any measurement axis at all) of one of the qubits (the system A or B) outputs 0 or 1 with $50\%$ probability. The degree of entanglement can be quantified by the coherence (off-diagonal elements of the density operator), or how mixed the reduced state is. Hence, since Bell states, as mentioned, are maximally entangled, we can predict that this instance gives maximum entropy according to Eq. (\ref{Entropy}); i.e., it will be a completely disordered, decohered or mixed state of the form $\hat{\rho}_A=\frac{1}{d_A}\,\hat{1}_{d_A}$, where $d_A$ is the dimension of the subsystem A ($d_A=2$ for qubit subsystems):
\begin{equation} \label{rho_A_entanglement}
\begin{split}
\hat{\rho}_A
&=\textrm{Tr}_B\,(\hat{\rho}_{AB})=\textrm{Tr}_B\,(\ket{\psi^+}\bra{\psi^+})\doteq\frac{1}{2}\textrm{Tr}_B\,\left[ (\ket{0}_A\ket{1}_B+\ket{1}_A\ket{0}_B)(\bra{0}_A\bra{1}_B+\bra{1}_A\bra{0}_B)\right]\\
&=\frac{1}{2}\textrm{Tr}_B\,\left[ \ket{0}_A\bra{0}_A\otimes\ket{1}_B\bra{1}_B+\ket{0}_A\bra{1}_A\otimes\ket{1}_B\bra{0}_B+\ket{1}_A\bra{0}_A\otimes\ket{0}_B\bra{1}_B+\ket{1}_A\bra{1}_A\otimes\ket{0}_B\bra{0}_B \right]\\
&\numeq{\textrm{1}}\frac{1}{2}\left( \ket{0}_A\bra{0}_A\,\,\textrm{Tr}\,\begin{pmatrix}0&0\\0&1\end{pmatrix}+\ket{0}_A\bra{1}_A\,\,\textrm{Tr}\,\begin{pmatrix}0&0\\1&0\end{pmatrix}+\ket{1}_A\bra{0}_A\,\,\textrm{Tr}\,\begin{pmatrix}0&1\\0&0\end{pmatrix}+\ket{1}_A\bra{1}_A\,\,\textrm{Tr}\,\begin{pmatrix}1&0\\0&0\end{pmatrix} \right)\\
&=\frac{1}{2}\left( \ket{0}_A\bra{0}_A\otimes 1+0+0+\ket{1}_A\bra{1}_A\otimes 1 \right)=\frac{1}{2}\left( \ket{0}_A\bra{0}_A+\ket{1}_A\bra{1}_A\right)=\frac{1}{2}\,\hat{1}_{A}=\frac{1}{2}\,\hat{1}_{2}
\end{split}
\end{equation}
where in equality $(1)$ we used $\textrm{Tr}\,(\hat{A}+\hat{B})=\textrm{Tr}\,(\hat{A})+\textrm{Tr}\,(\hat{B})$ and \cite[p.~105, Eq.~(2.178)]{Nielsen} $\textrm{Tr}_B\,(\hat{A}\otimes\hat{B})=\sum_b\,(\hat{1}_A\otimes\bra{b})(\hat{A}\otimes\hat{B})(\hat{1}_A\otimes\ket{b})=(\hat{1}_A\hat{A}\hat{1}_A)\,\sum_b\braket{b|\hat{B}|b}=\hat{A}\,\,\textrm{Tr}\,(\hat{B})$. Nevertheless, there is a \emph{correlation}: whenever $\ket{0}_A$ ($\ket{1}_A$) is measured, $\ket{1}_B$ ($\ket{0}_B$) is also measured, with total probability.

All in all, maximally entangled states' individual qubits behave randomly ($\hat{\rho}_A=\hat{\rho}_B=\hat{1}/d$), but, even if it can sound counter-intuitive, they allow prediction about the measurement output of the other qubit in the same basis. Entangled states only exhibit this distinctive combination of perfect individual randomness and strong correlation!


    
   


\vspace{1cm}
\section{Shor's quantum algorithm based upon the Fourier transform} \label{Quantum_Fourier_transform}

We know fast or efficient algorithms for multiplication: e.g., $11\times 13=(...)$. However, the reverse problem, $(...)\times(...)=143$, is not so tractable, because we ignore fast algorithms for factoring. Shor designed a fast algorithm for factoring. It is an example of algorithms based upon the Fourier transform and it is one of the most important quantum algorithms known \cite[p.~37, l.~25]{Nielsen}. Although it takes classical inputs (the number to be factorized) and yields classical outputs (the factors), Shor's quantum algorithm for factorization obtains its speedup by using \emph{superposition} to compute various paths simultaneously.

%The best classical algorithm for solving the modular exponentitation problem is the following:
%\noindent $\bullet$ Repeatedly square $x$ (mod $n$) to get $x^{2^i}$ (mod $n$) $:$ $i\leq \log_2r$ --or, equivalently, $2^i\leq r$--.
%\noindent $\bullet$ Then, multiply this to get $x^r$ (mod $n$).
%For $l$ bits and small numbers, this requires $\mathcal{O}(l)$ time for squarings and $\mathcal{O}(l^2)$ time for multiplications: $\mathcal{O}(l^3)$ time in total \cite[p.~10, l.~15-16]{Shor}.\\

The most direct way to factor a number $N$ is to try to divide it in parallel, using quantum superposition, by numbers $\in(1,\sqrt[]{N}]$. Classically, this method is said to be inefficient because it requires at least $\sqrt[]{N}$ steps (one step for each tried factor), and $\sqrt[]{N}=e^{\ln\sqrt[]{N}}=e^{\frac{1}{2}\ln N}$ is exponential in $\ln N$, rather than polynomial.

Nevertheless, this procedure is not successful even using quantum computation: measuring the computer's state in order to read the answer almost certainly yields one of the wrong (reminder $\neq 0$) paths and collapses the wave function to the measured state, losing all previous information.  

Instead, Shor reduced the problem of factoring to finding the period $r$ of the following modular exponential function or discrete logarithm problem: $f=f_N(x)=y^x$ mod $N$ \cite[p.~9, l.~37]{Shor}, where $f(x=r)=1$. In order to obtain the value of $f$: choose a value of $y\in[0,N]$ randomly, raise to the power of $x$, divide by $N$ and keep the reminder. For instance, $7^2$ mod $9=4$ is the reminder of dividing $7^2=49$ by $9$. Shor's algorithm provides $r$ if it exits, that is, if gcd(y,N)=1.

In Shor's algorithm, $f$ is evaluated on a superposition of arguments, then computing a Fourier transform on that superposition. First, the QC is prepared with two qubits: $\ket{x}$ and $\ket{y}$. $\ket{x}$ stores the arguments, and $y$ holds the corresponding values of $f$. In a register composed of $w\in\mathbb{N}$ qubits, there are $2^w$ possible Boolean states (0s and 1s), $2^w$ possible orthogonal states.

The initial state is $\ket{xy}=\ket{00}$. First, $\ket{x}$ is put into a uniform superposition that spreads over all the possible numerical values from $1$ to $2^w$ (or from $0$ to $2^w-1$, $0\leq x < 2^w$ or $0\leq x \leq 2^w-1$, if you prefer). Thus, the initial state evolves as $\ket{xy}=\ket{00}\to\frac{1}{\sqrt[]{2^w}}\sum_{x=1}^{2^w}\ket{x0}$, which has a unique $y$ value, $y=0$. Next, $f(x)$ is calculated for all the $x$ values of the superposition $\frac{1}{\sqrt[]{2^w}}\sum_{x=1}^{2^w}\ket{x0}$ simultaneously, and the result is stored in $\ket{y}$, giving $\frac{1}{\sqrt[]{2^w}}\sum_{x=1}^{2^w}\ket{x,f(x)}$. Finally, the quantum discrete Fourier transform $\hat{U}_{DFT}$  is performed on $\ket{x}$ resulting in $\,\,$ \cite[p.~12, Eq.~(4.1)]{Shor} 
\begin{equation} \label{DFT}
\begin{split}
&\hat{U}_{DFT}\left( \frac{1}{\sqrt[]{2^w}}\sum_{x=1}^{2^w}\ket{x,f(x)} \right)=\left(\frac{1}{\sqrt[]{2^w}}\sum_{x,k}e^{2\pi i\,kx/2^w}\,\ket{ky}\bra{xy}\right)\,\left( \frac{1}{\sqrt[]{2^w}}\sum_{x=1}^{2^w}\ket{x,f(x)} \right)\\
&= \frac{1}{2^w}\sum_{x,k}e^{2\pi i\,kx/2^w}\ket{ky}\braket{xy|x,f(x)} =  \frac{1}{2^w}\sum_{x,k}e^{2\pi i\,kx/2^w}\ket{ky}\delta_{y,f(x)}= \frac{1}{2^w}\sum_{x,k}e^{2\pi i\,kx/2^w}\ket{k,f(x)}\textrm{,}
\end{split}
\end{equation}
and $\ket{x}$ is measured to obtain $k\approx m\,2^w/r$, from which $r$ can be infered. Notice that, due to quantum \emph{superposition}, all the values of $f$ can be computed by running the computation only once!

\begin{figure}[H] 
	\centering
	\includegraphics[scale=0.2]{Images/DFT.png}
	\caption{\emph{DFT}, the essential operation for Shor's algorithm, acting on $w=4$ qubits ($2^w=2^4$ bits). The phases are related to the operations $\hat{S}(\phi_{jk})$ $:$ $\phi_{jk}=\pi/2^{j-k}$, and $\hat{A}_j\equiv\hat{U}_{\textrm{Had}_j}$. The $k$th wires or qubits are represented by the black dots.}
	  \label{fig:DTF}
\end{figure}

 Two types of quantum gates need to be used in order to deploy DFT. In the $\{\ket{0},\ket{1}\}$ and $\{\ket{0},\ket{1}\}^{\otimes 2}=\{\ket{00},\ket{01},\ket{10},\ket{11}\}$ bases, respectively,
\begin{equation}
\hat{U}_{\textrm{Had}_j} \doteq \frac{1}{\sqrt[]{2}} \begin{pmatrix}1&1\\1&-1\end{pmatrix}\,\textrm{,}\quad\textrm{and}\quad\hat{S}_{jk}=\hat{1}_3\oplus e^{i\,\phi_{jk}}\,:\,\phi_{jk}=\pi/2^{j-k}\textrm{,}
\end{equation} 
which act on the $j$th qubit and on the qubits in positions $j$ and $k$ ($j>k$, so that $1/2^{j-k}<1$). 

They are applied in the following order (from left to right), where $w$ is the number of qubits used: $\,\,$ \cite[p.~13, Eq.~(4.4)]{Shor}
\begin{equation} \label{fourier_gate_sequence}
\hat{U}_{\textrm{Had}_{w-1}} \,\,\hat{S}_{w-1,w-2} \,\,\hat{U}_{\textrm{Had}_{w-2}} \,\,\hat{S}_{w-1,w-3}\hat{S}_{w-2,w-3} \,\,\hat{U}_{\textrm{Had}_{w-3}}...\hat{U}_{\textrm{Had}_{1}}\,\,\hat{S}_{w-1,0}\hat{S}_{w-2,0}...\hat{S}_{20}\hat{S}_{10}\,\,\hat{U}_{\textrm{Had}_{0}}\,\,\textrm{.}
\end{equation} 
For example, for $w=4$ bits (Fig. (\ref{fig:DTF})), $\hat{U}_{\textrm{Had}_{3}} \,\,\hat{S}_{32} \,\,\hat{U}_{\textrm{Had}_{2}} \,\,\hat{S}_{31}\hat{S}_{21} \,\,\hat{U}_{\textrm{Had}_{1}}\,\,\hat{S}_{30}\hat{S}_{20}\hat{S}_{10}\,\,\hat{U}_{\textrm{Had}_{0}}$. Applying  sequence (\ref{fourier_gate_sequence}), $\frac{1}{\sqrt[]{q}}\,\sum_{b=0}^{q-1}\,\ket{b}e^{2\pi i\,kx/q}$ is obtained, where $b$ is the bit-reversal of $k$ in Eq. (\ref{DFT}). The gates $\hat{U}_\textrm{Had}$ produce a global factor $1/\sqrt[]{2^w}$ and $\hat{S}_{jk}$ changes the phases of the bits. Then, the bits of $\ket{b}$ must be read in reversed order to give $\ket{k}$.

To sum up, instead of giving a quantum algorithm for factoring a number $N$ directly, Shor's article gives an algorithm for finding the least integer $r$ such that $y^r=1$ (mod $N$) \cite[p.~15, l.~17]{Shor}. % First, we find $q$, the power of 2 for which $n^2\leq q < 2n^2$


\vspace{1cm}
\section{Quantum Search Algorithm} \label{quantum_search_algorithm}

A classical algorithm takes $N/2$ steps to examine $N$ elements and find the desired one with $50\%$ probability \cite[p.~1, l.~1-11]{Grover}. In other words, using classical computation, on average $N/2$ tries are needed, $N$ in the worst case.

On the other hand, since quantum mechanical systems can be in  a superposition of states, which allow to simultaneously examine multiple elements. Hence, as you might have guessed, quantum search algorithms are more efficient than any classical one: for $50\%$ probability, instead of $N/2$ steps, $\mathcal{O}(\sqrt[]{N})$ are enough.
	
Let our system have $N=2^n$ states: $\{ S_i \}$ : $i=1,2,... N$. Thus, the system can be described by $n$ bits (recall that for the \emph{qubit}, $n=1$). We assume that the desired state $S_\nu$ is the only one that satisfies condition function $C$: 
\begin{equation} 
  C(S_i)= \delta_{i\nu} = \begin{cases}
 1\,\textrm{,} & \text{if $i=\nu$} \\
 0\,\textrm{,} & \text{otherwise}
  \end{cases}
\end{equation}
and each $C$ can be evaluated in each time step. The problem is to identify $S_\nu$. $\,\,$ \cite[p.~3, l.~20-26]{Grover}\\

Grover's quantum search algorithm is the following: $\,\,$ \cite[p.~3]{Grover}

\noindent $(\textrm{i})$ Normalize the system so that there is the same amplitude ($1/\sqrt[]{N}$) to be in each of the $N$ states.

At the beginning, we suppose any of the $2^n$ states can be the desired one with equal probability. Thus, the initial state is a uniform superposition: $\ket{\psi_0}=\frac{1}{\sqrt[]{2^n}}\sum_{i=0}^{2^n-1}\ket{S_i}$. At this point, if we measure in the $\{\ket{S_i}\}$ basis, $\ket{\psi_0}$ will collapse to any of the basis states with $1/2^n$ probability, so we would need $2^n=N$ runs of the system to get the desired basis state. Grover's algorithm enhances this guessing probability, amplifying the amplitude of the desired state.

\noindent $(\textrm{ii})$ Main part of the algorithm. Each loop increases the amplitude of the desired state $S_\nu$ by $\mathcal{O}(1/\sqrt[]{N})$, where $1/\sqrt[]{N}$ is the amplitude average of the initial state. Hence, the following procedure must be repeated $\mathcal{O}(\sqrt[]{N})$ times so that the amplitude of $S_\nu$ becomes $\mathcal{O}(1/\sqrt[]{N})\,\mathcal{O}(\sqrt[]{N})=\mathcal{O}(1)$:

$(\textrm{ii.a})$ If $C(S)=1$, apply $e^{i\pi}\,\hat{1}_N = -\hat{1}_N$. That is, apply $\hat{U}\ket{S_i}=(-1)^{C(S_i)}\ket{S_i}$.

$(\textrm{ii.b})$ Apply the difussion transform $\hat{D}$ $:$ $D_{ij}= -\delta_{ij}+\frac{2}{N}$. It can be implemented as $\hat{D}=\hat{U}_{\textrm{Had}}\,\hat{R}\,\hat{U}_{\textrm{Had}}$. $\hat{R}$ is the rotation operator ($R_{ij}=(-1)^{1+\delta_{i0}}\,\delta_{ij}$) and, $\hat{U}_{\textrm{Had}}$, the Hadamard operator, where $\left( \hat{U}^{\otimes n}_{\textrm{Had}}\right)_{ij}=\frac{1}{\sqrt[]{2^n}}\,(-1)^{i\cdot j}$ $\,\,$ \cite[p.~35, Eq.~(1.50) ]{Nielsen} and $i\cdot j$ is the bitwise dot product of $i$ and $j$,  modulo 2.

\noindent $(\textrm{iii})$ Sample the final state. If we had $C(S)=1$ in $(\textrm{ii.a})$, for a unique $S=S_\nu$ the final state is $S_\nu$ with probability $\geq 1/2$.\\

% https://quantumexperience.ng.bluemix.net/proxy/tutorial/full-user-guide/004-Quantum_Algorithms/070-Grover's_Algorithm.html
%The desired state $\ket{S_\nu}$ and the initial state $\ket{\psi_0}$ for a plane in $\mathbb{C}^{2^n}$. After (ii.a) and \\

$\hat{D}$ constitutes an \emph{inversion about the amplitude average}. Id est, when $\hat{D}$ operates on an arbitrary vector $\vec{v}$, $\left( \hat{D}=\hat{1}+2\frac{1}{N})\right)\,\vec{v}=\vec{v}+2\frac{\vec{v}}{N}=\frac{\vec{v}}{N}+\left(\frac{\vec{v}}{N}-\vec{v}\right)$. After step $(\textrm{i})$ all amplitudes are $1/\sqrt[]{N}$ and the step $(\textrm{ii.a})$ makes the amplitude of $S_\nu$ negative. Then, when $\hat{D}$ is applied all amplitudes but the negative one (the amplitude of $S_\nu$) remain the same because they are approximately equal to the average, and the amplitude of $S_\nu$ is made positive and increased by $\mathcal{O}(1/\sqrt[]{N})$ (its norm becomes  $\approx 2/\sqrt[]{N}$). $\,\,\,$ \cite[p.~4, Fig.~2]{Grover}


\vspace{1cm}
\section{Turing machine} \label{Turing machine}
The Turing machine is a device composed of a read/write head as \emph{processing unit} and an infinite tape as unlimited \emph{memory}. The \emph{tape} is divided into discrete cells and each cell has a symbol from a finite alphabet (Boolean states, 0s and 1s, for example). The \emph{head} can be in one of a finite set of states $\{q_0,q_1,...,q_h\}$. $q_h$ is the \emph{halting state}, whose properties we will describe in a moment.

The head scans the tape, one cell at a time. In each step, there are two initial conditions: the current state of the head and the alphabetic symbol in the cell being scanned. Given this pair of initial conditions, the machine receives a tripartite instruction, which specifies the next state of the head, the symbol the head is to write into the scanned cell and whether the head is to move one cell to the left or the right or is not to move.

The mentioned two initial states and three instructions can be described as a finite set of quintuples: $(q,s,q^\prime,s^\prime,d)$. From left to right, $q=$ current head state, $s=$ symbol being scanned by the head, $q^\prime=$ next head state, $s^\prime=$ symbol to be written in the place of $s$, $d$= next head movement direction (left, right or stay). Once the head state enters the halting state $q_h$, no further change occurs: $(q=q_h,s,q^\prime=q=q_h,s^\prime=s,d=\textrm{no movement})$.

Notice that the the operation of the Turing machine is \emph{local} in the sense that transitions between states depend only on the current head state and the symbol being scanned, rather than on the whole global configuration.

The classical model described above suggests a quantum generalization. The head states and cell symbols correspond to orthogonal states (qubits, for example, if two-dimensional), and the head's position $x$ would be an observable.


\vspace{1cm}
\section{Trapped Ion Quantum Computers} \label{trapped_ion}
The first theoretical model of a trapped ion quantum computer was proposed in 1995 by Cirac and Zoller. The trap surrounds the ions, holding them suspended in place using electric and magnetic fields, similar to the way magnets can be used to levitate larger objects in the air. Quantum gates in this design are implemented by laser light.





The scheme of the CNOT gate was implemented in the experiment. Both  the control and target qubit were deployed in the same ion. In order to provide for scalability, interaction between qubits caused by the collective mode of the ion chain should be implemented. However, such a global state is subjected to strong decoherence.

\begin{figure}[H] 
	\centering
	\includegraphics[scale=0.2]{Images/ion_trap.png}
	\caption{Magnified picture of a quantum computer made up of three Beryllium atoms. Each one stores a qubit.}
	  \label{fig:ion_trap}
\end{figure}

The ions in Fig. \ref{fig:ion_trap} are a thousand times smaller than the spacing between them. They look a lot bigger than they really are, because of the way the picture was created:  shining laser light. The particles making up the laser light are much bigger than the atoms.





\vspace{1cm}
\section{Photon Quantum Computers} \label{photon_quantum_computers}

Example: Mach-Zehnder interferometer.

A photon passes through the first beam splitter (BS1) and propagates via 2 different paths to another beam splitter (BS2), which directs the particle to one of the two detectors. Along each path between the two beam splitters, there is a phase shifter (PS$i$ $:$ $i=1,2$).

\begin{figure}[H] 
	\centering
	\includegraphics[scale=0.2]{Images/Mach-Zehnder.png}
	\caption{Mach-Zehnder interferometer. P$_i$ is the probability of directing the particle to detector $i=0,1$.}
	  \label{fig:Mach-Zehnder}
\end{figure}

If the initial particle is in path $\ket{0}$, it undergoes the following:
\begin{equation}
\begin{split}
&\ket{\psi(t_0)}=\ket{0}\,\to\,\hat{U}_{\textrm{BS1}}\ket{0}=\frac{1}{\sqrt[]{2}}(\ket{0}+\ket{1})\,\to\,\hat{U}_{\textrm{PS}}\ket{0}=\frac{1}{\sqrt[]{2}}(e^{i\phi_0}\ket{0}+e^{i\phi_1}\ket{1})\\
&=\frac{1}{\sqrt[]{2}}e^{i\frac{\phi_0+\phi_1}{2}}(e^{i\frac{\phi_0-\phi_1}{2}}\ket{0}+e^{-i\frac{\phi_0-\phi_1}{2}}\ket{1})\, \to \, \hat{U}_{\textrm{BS2}}\left( \frac{1}{\sqrt[]{2}}e^{i\frac{\phi_0+\phi_1}{2}}(e^{i\frac{\phi_0-\phi_1}{2}}\ket{0}+e^{-i\frac{\phi_0-\phi_1}{2}}\ket{1}) \right)\\
& = \frac{1}{\sqrt[]{2}}e^{i\frac{\phi_0+\phi_1}{2}} \left( e^{i\frac{\phi_0-\phi_1}{2}}\frac{1}{\sqrt[]{2}}(\ket{0}+\ket{1})+e^{-i\frac{\phi_0-\phi_1}{2}}\frac{1}{\sqrt[]{2}}(\ket{0}-\ket{1}) \right)\\
&= \frac{1}{2}  e^{i\frac{\phi_0+\phi_1}{2}} \left( 2\cos\left( e^{i\frac{\phi_0-\phi_1}{2}} \right) +  2i\sin\left( e^{i\frac{\phi_0-\phi_1}{2}} \right) \right) =  e^{i\frac{\phi_0+\phi_1}{2}} \left( \cos\left( e^{i\frac{\phi_0-\phi_1}{2}} \right) +  i\sin\left( e^{i\frac{\phi_0-\phi_1}{2}} \right) \right)\,\textrm{.}
\end{split}
\end{equation}

The global phase $e^{i\frac{\phi_0+\phi_1}{2}}$, as mentioned in Section (\ref{GoL quantum with phase}), is irrelevant. BS1 prepares the particle in a superposition of paths, PS1 and PS2 modify quantum phases and BS2 erases information about which path was taken from BS1.

Notice that this is a quantum circuit! $\hat{U}_{\textrm{BS}}\equiv\hat{U}_{\textrm{Had}}$ and and %$\hat{U}_{\textrm{PS}}\equiv\hat{U}_{\textrm{Had}}$







\section{IBM Quantum Composer} \label{IBM Quantum Composer}
\begin{itemize}
\item \emph{Real} quantum processor:

$\diamond$ Allowed connections between the qubits are defined by the IBM's experimental setup's schematic, which puts hardware constraints on some two-qubit gates, like the CNOT.

$\diamond$ Errors in the measurement due to experimental imperfections.

\item \emph{Custom} quantum processor:

$\diamond$ Unlimited number of qubits $n$.

$\diamond$ Quantum gates can be placed anywhere.
\end{itemize}
Each circuit must end with a measurement gate, which stores the result in the classical bit register. Note that after measurement, since it becomes a classical bit, a qubit loses the quantum properties of superposition and entanglement.

If the qubit measured is
\begin{equation}
\hat{U}_{\textrm{Had}}\ket{0}\doteq\frac{1}{\sqrt[]{2}}\begin{pmatrix}1&1\\1&-1\end{pmatrix}\begin{pmatrix}1\\0
\end{pmatrix}=\frac{1}{\sqrt[]{2}}\begin{pmatrix}1\\1
\end{pmatrix}\doteq\frac{1}{\sqrt[]{2}}(\ket{0}+\ket{1})\,\textrm{,}\quad\textrm{or}\quad\hat{U}_{\textrm{Had}}\ket{1}=\frac{1}{\sqrt[]{2}}(\ket{0}-\ket{1})\,\textrm{,}
\end{equation}
the measurement forces the qubit to choose a final state that can be translated into a classical bit: $\ket{0}$ (classical bit 0) or $\ket{1}$ (classical bit 1). Thus, when you repeat the experiment many “shots”, about half the time the result is 0 and, half the time, 1. That is, a quantum measurement takes any superposition state of the qubit, and projects it to either the state $\ket{0}$ or $\ket{0}$, with a probability determined from the amplitudes of the superposition. Because of this, we say that a quantum system in a definite state can still behave randomly!


In the IBM QC, for multiqubit states,  the first qubit is always listed at the far right!, to be consistent with the classical binary representation. In our work we used the opposite notation, the first qubit at the left. 

To make use of those many configurations in the quantum world, we need gates that perform \emph{conditional logic} between qubits, meaning the state of one qubit depends on the state of another: for instance, $\hat{U}_{C_{NOT}}$.


IBM's quantun processor is housed inside a printed circuit board, inside a light- and magnetic field-tight can, at the bottom of a dilution refrigerator ($\textrm{T}\approx 15\,\textrm{mK}$). In order to prepare the initial qubit $\ket{0}$, the  system gets cold , and the superconducting qubit reaches equilibrium at the ground state $\ket{0}$.

Each qubit has a different frequency, like a musical note.

Quantum gates are performed by sending electromagnetic impulses at microwave frequencies to the qubits through coaxial cables. These electromagnetic pulses have a particular duration, frequency, and phase that determine the angle of rotation of the qubit state around a particular axis of the Bloch sphere.  For single-qubit operations, only one pulse type needs to be calibrated, namely $\hat{X}_{\pi/2}$. For examplethe Hadamard gate is performed by the sequence $\hat{S}\,\hat{X}_{\pi/2}\,\hat{S}$. On the other hand, two-qubit gates require interaction between the two qubits during the gate duration, and minimizing the interaction at any other time.

Measurements ought to be performed in a way that does not destroy the qubit's state. One method is to weakly couple each qubit to a microwave resonator whose resonance characteristics depend on the state of the qubit. In this method, measuring means a microwave tone to qubit's resonators and analyzing the phase and amplitude of the signal reflected back.














\end{appendices}







    
\renewcommand{\refname}{Bibliography}

\newpage

\begin{thebibliography}{X}

\bibitem{Nielsen} M. A. Nielsen \& I. L. Chuang, {\it Quantum Computation and Quantum Information}, 10th Anniversary Edition,  (Cambridge University Press, Cambridge, United Kingdom, 2010).

\bibitem{Lloyd} S. Lloyd, {\it Universal quantum simulators}, Science, vol. {\bf 273}, p. \href{http://science.sciencemag.org/content/273/5278/1073}{1073} (1996).

\bibitem{Shor} P. W. Shor, {\it Polynomial time algorithms for prime factorization and discrete logarithms on a quantum computer}, SIAM J. Sci. Statist. Comput., vol. {\bf 26}, p. \href{https://epubs.siam.org/doi/10.1137/S0097539795293172}{1484} (1997).

\bibitem{Ricard_Sole} Ricard Sol\'{e}, {\it Vidas Sint\'{e}ticas} (Tusquets Editores, Barcelona, Spain, 2012).

%\bibitem{Xuewei_Li} Xuewe Li, Jinpei Wu \& Xueyan Li, {\it Theory of Practical Cellular Automaton} (Springer \& Beijing Jiaotong University Press, Beijing, China, 2018).

\bibitem{Gardner} M. Gardner, {\it Mathematical games: The fantastic combinations of John Conway’s new solitaire game Life}, Scientific American {\bf 223}(10), p. \href{https://web.stanford.edu/class/sts145/Library/life.pdf}{120-123} (1970).

\bibitem{Adamatzky} A. Adamatzky (Ed.), {\it Game of Life Cellular Automata} (Springer-Verlag London Limited, 2010).

%\bibitem{Rendell} P. Rendell, {\it Turing Machine Universality of the Game of Life} (Springer International Publishing, 2016).

\bibitem{QAL_IBM} U. Alvarez-Rodriguez, M. Sanz, L. Lamata \& E. Solano, {\it Quantum Artificial Life in an IBM Quantum Computer}, Scientific Reports {\bf 8}, Article number: \href{https://www.nature.com/articles/s41598-018-33125-3.pdf}{14793} (2018).

\bibitem{Feynman} R. P. Feynman, {\it Simulating physics with computers}, Int. J. Theor. Phys., Vol. {\bf 21}, p. \href{https://link.springer.com/article/10.1007/BF02650179}{467–488} (1982).

\bibitem{Flitney} A. P. Flitney \& D. Abbott, {\it A semi-quantum version of the game of Life}, arXiv:\href{https://arxiv.org/abs/quant-ph/0208149}{quant-ph/0208149} (2002).

\bibitem{Sakurai} J. J. Sakurai \& Jim J. Napolitano, {\it Modern Quantum Mechanics} (Addison-Wesley Publishing Company, San Francisco, United States, 2010).

\bibitem{Griffiths} D. J. Griffiths, {\it Introduction to Quantum Mechanics} (Pearson Education International, United States, 2004).

\bibitem{Grover} L. K. Grover, {\it  A fast quantum mechanical algorithm for database search}, Proceedings, 28th Annual ACM Symposium on the Theory of Computing (STOC), \href{https://arxiv.org/pdf/quant-ph/9605043v3.pdf}{\bf 212} (1996).

\bibitem{Shankar} R. Shankar, {\it Principles of Quantum Mechanics} (Plenum Press, New York and London, 1994).

\bibitem{AL_in_QT} U. Alvarez-Rodriguez, M. Sanz, L. Lamata \& E. Solano, {\it Artificial Life in Quantum Technologies}, Scientific Reports {\bf 6}, Article number: \href{https://www.nature.com/articles/srep20956.pdf}{20956} (2016). 

\bibitem{Bio_Cloning} U. Alvarez-Rodriguez, M. Sanz, L. Lamata \& E. Solano, {\it Biomimetic Cloning of Quantum Observables}, Scientific Reports {\bf 4}, Article number: \href{https://www.nature.com/articles/srep04910.pdf}{4910} (2014).

\bibitem{Ferraro} A. Ferraro, A. Galbiati, \& M. Paris, {\it Cloning of observables}, J. Phys. {\bf A 39}, \href{https://arxiv.org/pdf/quant-ph/0509170.pdf}{L219-L228} (2006).

\bibitem{DiVincenzo} D. P. DiVincenzo, {\it Quantum computation and spin physics}, Journal of Applied Physics {\bf 81}, p. \href{https://aip.scitation.org/doi/pdf/10.1063/1.365176?class=pdf}{4602-4607} (1997).

\bibitem{Unitary Matrix} T. Rowland, {\it Unitary Matrix}, Mathworld -- A Wolfram Web Resource,  \href{http://mathworld.wolfram.com/UnitaryMatrix.html}{http://mathworld.wolfram.com/UnitaryMatrix.html}.

%\bibitem{Trace} R. A. Horn and C.R. Johnson, {\it Topics in Matrix Analysis} (Cambridge University Press, Cambridge, United Kingdom, 1991).

%\bibitem{TraceAB} M. H. J. Gruber, {\it Matrix Algebra for Linear Models} (John Wiley \& Sons, New Jersey, United States, 2014).

%\bibitem{No-cloning} W. K. Wootters \& W. H. Zurek, {\it A single quantum cannot be cloned}, Nature {\bf 299}, p. \href{https://www.nature.com/articles/299802a0.pdf}{802} (1982).

%\bibitem{No-cloning2} D. Dieks, {\it Communication by EPR devices}, Physics Letters, {\bf 92A}, p. \href{https://scholar.google.com/citations?user=mo49rmoAAAAJ&hl=en#d=gs_md_cita-d&u=\%2Fcitations\%3Fview_op\%3Dview_citation\%26hl\%3Den\%26user\%3Dmo49rmoAAAAJ\%26citation_for_view\%3Dmo49rmoAAAAJ\%3Au5HHmVD_uO8C\%26tzom\%3D-60}{271-272} (1982).

%\bibitem{FLASH} N. Herbert, {\it FLASH -- A Superluminal Communicator Based Upon a New Kind of Quantum Measurement}, Foundation of Physics, Vol. {\bf 12}, No. \href{https://link.springer.com/content/pdf/10.1007\%2FBF00729622.pdf}{12} (1982).

\bibitem{Deutsch} D. E. Deutsch, {\it Quantum computational networks}, Proc. Royal Soc. Lond., vol. A {\bf 425}, p. \href{https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1989.0099}{73-90} (1989).

\bibitem{Mermin} N. D. Mermin, {\it Quantum Computer Science: An Introduction},  (Cambridge University Press, Cambridge, United Kingdom, 2007).

\bibitem{No-broadcasting} H. Barnum, C. M. Caves, C. A. Fuchs, R. Jozsa, and B. Schumacher, {\it Noncommuting Mixed States Cannot Be Broadcast}, Phys. Rev. Lett., vol. {\bf 76}, p. \href{https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.76.2818}{2818-2821} (1996).



%\bibitem{Cloning and joint measurements} T. Brougham, E. Andersson, \& S. M. Barnett, {\it Cloning and joint measurements of incompatible components of spin}, Phys. Rev., vol. {\bf A 73}, p. \href{https://arxiv.org/pdf/quant-ph/0601098.pdf}{062319} (2006).

%\bibitem{A general no-cloning theorem} G. Lindblad, {\it A general no-cloning theorem}, Letters in Mathematical Physics, vol. {\bf 47}, p. \href{https://link.springer.com/article/10.1023/A:1007581027660}{189-196} (1999).


\end{thebibliography}




\newpage
\section{Defense \normalfont{of possible questions.}}

\subsection{$\braket{ \hat{A}\otimes \hat{1}}_{\hat{\rho}_1} \neq \braket{\hat{1}\otimes\hat{A}}_{\hat{\rho}_1}$, \normalfont{in general}.}

Preservation condition, Eq. (\ref{preservation_condition}), obeys $ 
\braket{\hat{A}}_{\hat{\rho}_0} \numeq{{\color{purple}1}} \braket{\hat{A}_{g_1}\otimes \hat{1}_{p_0}}_{\hat{\rho}_1}\equiv \braket{\hat{A}}_{g_1} \numeq{{\color{orange}2}} \braket{\hat{1}_{g_1}\otimes\hat{A}_{p_0}}_{\hat{\rho}_1}\equiv\braket{\hat{A}}_{p_0}(t_0)$, where $\hat{A}$ is the observable chosen to be partially cloned. $\hat{A}=\hat{\sigma}_z$, in our case. Nevertheless, generally,
\begin{equation}
\braket{\hat{A}\otimes \hat{1}}_{\hat{\rho}_1} \neq \braket{\hat{1}\otimes\hat{A}}_{\hat{\rho}_1}\,.
\end{equation}

\noindent
{\color{red} \rule{\linewidth}{0.5mm} }
\emph{Proof}:
\begin{equation} \label{Kronecker_trace}
\begin{split}
\braket{\hat{A}\otimes\hat{1}_2}_{\hat{\rho}_1}
&\equiv\textrm{Tr}(\hat{\rho}_1(\hat{A}\otimes\hat{1}_2))\numeq{\ref{rho_0}}\textrm{Tr}([\hat{U}(\hat{\rho}_g\otimes\hat{\rho}_A)\hat{U}^\dagger](\hat{A}\otimes\hat{1}_2))\\
&\numeq{\ref{U_CNOT}}\textrm{Tr}([(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x)^\dagger](\hat{A}\otimes\hat{1}_2))\\
&\numeq{1}\textrm{Tr}([((\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\rho}_g\otimes\hat{\rho}_A)+(\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A))(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)](\hat{\sigma_i}\otimes\hat{1}_2))\\
&=\textrm{Tr}((\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)(\hat{\sigma_i}\otimes\hat{1}_2)+(\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A)\\
&(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)(\hat{\sigma_i}\otimes\hat{1}_2))=\textrm{Tr}((\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\sigma_i}\otimes\hat{1}_2))\\
&+\textrm{Tr}((\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)(\hat{\sigma_i}\otimes\hat{1}_2))+\textrm{Tr}((\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\sigma_i}\otimes\hat{1}_2))\\
&+\textrm{Tr}((\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)(\hat{\sigma_i}\otimes\hat{1}_2))\numeq{2}\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{0}\bra{0}\hat{\sigma_i})\otimes(\hat{1}_2\hat{\rho}_A\hat{1}_2\hat{1}_2))+\\
&+\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{1}\bra{1}\hat{\sigma_i})\otimes(\hat{1}_2\hat{\rho}_A\hat{\sigma}_x^\dagger\hat{1}_2))+\textrm{Tr}((\ket{1}\bra{1}\hat{\rho}_g\ket{0}\bra{0}\hat{\sigma_i})\otimes(\hat{\sigma}_x \hat{\rho}_A \hat{1}_2 \hat{1}_2))\\
&+\textrm{Tr}((\ket{1}\bra{1}\hat{\rho}_g\ket{1}\bra{1}\hat{\sigma_i})\otimes(\hat{\sigma}_x \hat{\rho}_A \hat{\sigma}_x^\dagger \hat{1}_2))=\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{0}\bra{0}\hat{\sigma_i})\otimes\hat{\rho}_A)\\
&+\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{1}\bra{1}\hat{\sigma_i})\otimes(\hat{\rho}_A\hat{\sigma}_x^\dagger))+\textrm{Tr}((\ket{1}\bra{1}\hat{\rho}_g\ket{0}\bra{0}\hat{\sigma_i})\otimes(\hat{\sigma}_x \hat{\rho}_A))\\
&+\textrm{Tr}((\ket{1}\bra{1}\hat{\rho}_g\ket{1}\bra{1}\hat{\sigma_i})\otimes(\hat{\sigma}_x \hat{\rho}_A \hat{\sigma}_x^\dagger))\numeq{3}\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{0}\bra{0}\hat{\sigma_i})\,\,\textrm{Tr}\hat{\rho}_A+...\\
&\numeq{4}\\
&\equiv\braket{\hat{1}_2\otimes\hat{\sigma_i}}_{\rho_0}
\end{split}
\end{equation}


\noindent
{\color{red} \rule{\linewidth}{0.5mm} }
HOW?
$$ \textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{0}\bra{0}\hat{\sigma_i})\,\,\textrm{Tr}\hat{\rho}_A+... \numeq{?} \textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{0}\bra{0})\,\,\textrm{Tr}(\hat{\rho}_A\hat{\sigma_i})+... $$
\noindent
{\color{red} \rule{\linewidth}{0.5mm} }



\begin{equation} \label{Kronecker_trace2}
\begin{split}
\braket{\hat{1}_2\otimes\hat{\sigma_i}}_{\rho_0}
&\equiv\textrm{Tr}(\rho_0(\hat{1}_2\otimes\hat{\sigma_i}))\numeq{\ref{rho_0}}\textrm{Tr}([\hat{U}(\hat{\rho}_g\otimes\hat{\rho}_A)\hat{U}^\dagger](\hat{1}_2\otimes\hat{\sigma_i}))\\
&\numeq{\ref{U_CNOT}}\textrm{Tr}([(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x)^\dagger](\hat{1}_2\otimes\hat{\sigma_i}))\\
&\numeq{1}\textrm{Tr}([((\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\rho}_g\otimes\hat{\rho}_A)+(\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A))(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)](\hat{1}_2\otimes\hat{\sigma_i}))\\
&=\textrm{Tr}((\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)(\hat{\sigma_i}\otimes\hat{1}_2)+(\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A)\\
&(\ket{0}\bra{0}\otimes\hat{1}_2+\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)(\hat{\sigma_i}\otimes\hat{1}_2))=\textrm{Tr}((\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{1}_2\otimes\hat{\sigma_i}))\\
&+\textrm{Tr}((\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)(\hat{1}_2\otimes\hat{\sigma_i}))+\textrm{Tr}((\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{0}\bra{0}\otimes\hat{1}_2)(\hat{1}_2\otimes\hat{\sigma_i}))\\
&+\textrm{Tr}((\ket{1}\bra{1}\otimes\hat{\sigma}_x)(\hat{\rho}_g\otimes\hat{\rho}_A)(\ket{1}\bra{1}\otimes\hat{\sigma}_x^\dagger)(\hat{1}_2\otimes\hat{\sigma_i}))\numeq{2}\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{0}\bra{0}\hat{1}_2)\otimes(\hat{1}_2\hat{\rho}_A\hat{1}_2\hat{\sigma_i}))+\\
&+\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{1}\bra{1}\hat{1}_2)\otimes(\hat{1}_2\hat{\rho}_A\hat{\sigma}_x^\dagger\hat{\sigma_i}))+\textrm{Tr}((\ket{1}\bra{1}\hat{\rho}_g\ket{0}\bra{0}\hat{1}_2)\otimes(\hat{\sigma}_x \hat{\rho}_A \hat{1}_2 \hat{\sigma_i}))\\
&+\textrm{Tr}((\ket{1}\bra{1}\hat{\rho}_g\ket{1}\bra{1}\hat{1}_2)\otimes(\hat{\sigma}_x \hat{\rho}_A \hat{\sigma}_x^\dagger \hat{\sigma_i}))=\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{0}\bra{0})\otimes(\hat{\rho}_A\hat{\sigma_i}))\\
&+\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{1}\bra{1})\otimes(\hat{\rho}_A\hat{\sigma}_x^\dagger\hat{\sigma_i}))+\textrm{Tr}((\ket{1}\bra{1}\hat{\rho}_g\ket{0}\bra{0})\otimes(\hat{\sigma}_x \hat{\rho}_A\hat{\sigma_i}))\\
&+\textrm{Tr}((\ket{1}\bra{1}\hat{\rho}_g\ket{1}\bra{1})\otimes(\hat{\sigma}_x \hat{\rho}_A \hat{\sigma}_x^\dagger\hat{\sigma_i}))\numeq{3}\textrm{Tr}((\ket{0}\bra{0}\hat{\rho}_g\ket{0}\bra{0})\,\,\textrm{Tr}(\hat{\rho}_A\hat{\sigma_i})+...\\
\end{split}
\end{equation}




and where we used
\begin{itemize}
\item in equality (\ref{Kronecker_trace}(1)), from Ref. \cite[p.~243, 4.2.4-5]{Trace}: $(\hat{A}\otimes\hat{B})^T=\hat{A}^T\otimes\hat{B}^T$, and $(\hat{A}\otimes\hat{B})^*=\hat{A}^*\otimes\hat{B}^*$. Therefore, since $\hat{A}^\dagger\equiv(\hat{A}^*)^T\equiv(\hat{A}^T)^*$, $(\hat{A}\otimes\hat{B})^\dagger=\hat{A}^\dagger\otimes\hat{B}^\dagger$. We additionally used $(\ket{0}\bra{0})^\dagger\doteq\begin{pmatrix}1&0\\0&0\end{pmatrix}^\dagger=\begin{pmatrix}1&0\\0&0\end{pmatrix}\doteq\ket{0}\bra{0}$, $(\ket{1}\bra{1})^\dagger\doteq\begin{pmatrix}0&0\\0&1\end{pmatrix}^\dagger=\begin{pmatrix}0&0\\0&1\end{pmatrix}\doteq\ket{1}\bra{1}$ and $(\hat{1}_2)^\dagger\doteq\begin{pmatrix}1&0\\0&1\end{pmatrix}^\dagger=\begin{pmatrix}1&0\\0&1\end{pmatrix}\doteq\hat{1}_2$ and, from Ref. \cite[p.~243, 4.2.7]{Trace}, $(\hat{A}+\hat{B})\otimes\hat{C}=\hat{A}\otimes\hat{C}+\hat{B}\otimes\hat{C}$.
\item in equality (\ref{Kronecker_trace}(2)), from Ref. \cite[p.~251, ex.~4.2.14]{Trace}: $(\hat{A}_1\otimes\hat{B}_1)(\hat{A}_2\otimes\hat{B}_2)...(\hat{A}_n\otimes\hat{B}_n)=(\hat{A}_1\hat{A}_2...\hat{A}_n)\otimes(\hat{B}_1\hat{B}_2...\hat{B}_n)$ %, and $(\hat{A}_1\otimes\hat{A}_2\otimes...\otimes\hat{A}_n)(\hat{B}_1\otimes\hat{B}_2\otimes...\otimes\hat{B}_n)=\hat{A}_1\hat{B}_1\otimes\hat{A}_2\hat{B}_2\otimes...\otimes\hat{A}_n\hat{B}_n$ 
\item in equality (\ref{Kronecker_trace}(3)), from Ref. \cite[p.~250, ex.~4.2.12]{Trace}: $\textrm{Tr}(\hat{A}\otimes\hat{B})=\textrm{Tr}\hat{A}\,\textrm{Tr}\hat{B}=\textrm{Tr}\hat{B}\,\textrm{Tr}\hat{A}=\textrm{Tr}(\hat{B}\otimes\hat{A})$
\item in equality (\ref{Kronecker_trace}(4)), from Ref. \cite[p.~56, Theo.~4.3]{TraceAB} --$\textrm{Tr}(\hat{A}\hat{B})=\textrm{Tr}(\hat{B}\hat{A})$-- and Ref. \cite[p.~56, cor.~4.1]{TraceAB} --$\textrm{Tr}(\hat{A}\hat{B}\hat{C})=\textrm{Tr}(\hat{C}\hat{A}\hat{B})=\textrm{Tr}(\hat{B}\hat{C}\hat{A})$--. Id est, the trace is \emph{cyclic}.
\end{itemize}

  

\noindent
{\color{red} \rule{\linewidth}{0.5mm} }

We follow the definition of the partial cloning unitary operator $\hat{U}$ proposed in Ref. \cite[p.~2, Eq.~(5)]{Bio_Cloning}. We are in a Hilbert space of dimension $n=\dim \mathcal{H}_{g_0}=2$, $\mathcal{H}_{g_0}\in\mathbb{C}^{n=2}$. Consequently, $\hat{U}\in\,\mathcal{H}\otimes\mathcal{H}$ --$\mathbb{C}^{2}\otimes\mathbb{C}^{2}$, in our model-- is defined as follows:
\begin{equation} \label{why_U_CNOT}
\hat{U}_{n=2}\equiv\sum_{i=0}^{(n=2)-1}\hat{\Lambda}_{\ket{i}}\otimes \hat{x}_{ni}=\ket{0}\bra{0}\otimes\hat{x}_{20}+\ket{1}\bra{1}\otimes\hat{x}_{20}\doteq\begin{pmatrix}1&0\\0&0\end{pmatrix}\otimes\hat{x}_{20}+\begin{pmatrix}0&0\\0&1\end{pmatrix}\otimes\hat{x}_{21}=\begin{pmatrix}\hat{x}_{20}&\\&\hat{x}_{21}\end{pmatrix}\equiv\oplus_{i=0}^{(n=2)-1}\,\hat{x}_{ni}
\end{equation}
where, $\hat{\Lambda}_{\ket{i}}\equiv\ket{i}\bra{i}$ is the projector \cite[p.~2, Eq.~(4)]{Bio_Cloning} and $\hat{x}_{ni}$ is the translation operator defined as 
\begin{equation} \label{translation group}
\hat{x}_{ni}\ket{k}=
\begin{cases}
 \ket{k+i} & \text{if $k< n-i$}  \\
 \ket{k-(n-i)} & \text{if $k\geq n-i$}
 \end{cases}
 \,\,\textrm{,}
\end{equation} 
where, since we wanted the computational basis $\{\ket{0},\ket{1}\}$, we made the $i\leftrightarrow i+1$ variable change in Ref. \cite[p.~2, Eq.~(3)]{Bio_Cloning}. Then, for the computational basis, $k=0,1$ we have
\begin{equation} \label{x_ni}
\hat{x}_{20}\ket{0}=\ket{0+0}=\ket{0}\,\textrm{,}\quad\hat{x}_{20}\ket{1}=\ket{1+0}=\ket{1}\,\textrm{,}\quad\hat{x}_{21}\ket{0}=\ket{0+1}=\ket{1}\,\textrm{, and}\quad\hat{x}_{21}\ket{1}=\ket{1-(2-1)}=\ket{0}\,\textrm{.}
\end{equation}
Then,
\begin{equation} \label{x_20}
\hat{x}_{20}\doteq\begin{pmatrix}\braket{0|\hat{x}_{20}|0}&\braket{0|\hat{x}_{20}|1}\\\braket{1|\hat{x}_{20}|0}&\braket{1|\hat{x}_{20}|1}\end{pmatrix}\numeq{\textrm{\ref{x_ni}a, b}}\begin{pmatrix}\braket{0|0}&\braket{0|1}\\\braket{1|0}&\braket{1|1}\end{pmatrix}=\begin{pmatrix}1&0\\0&1\end{pmatrix}\doteq\hat{1}_2\,\textrm{,}
\end{equation}
\begin{equation} \label{x_21}
\hat{x}_{21}\doteq\begin{pmatrix}\braket{0|\hat{x}_{21}|0}&\braket{0|\hat{x}_{21}|1}\\\braket{1|\hat{x}_{21}|0}&\braket{1|\hat{x}_{21}|1}\end{pmatrix}\numeq{\textrm{\ref{x_ni}c, d}}\begin{pmatrix}\braket{0|1}&\braket{0|0}\\\braket{1|1}&\braket{1|0}\end{pmatrix}=\begin{pmatrix}0&1\\1&0\end{pmatrix}\doteq\hat{\sigma}_x\,\textrm{,}
\end{equation}\\

Therefore, Eq. (\ref{why_U_CNOT}) becomes
\begin{equation} \label{why_U_CNOT2}
\hat{U}_{n=2}=\ket{0}\bra{0}\otimes\hat{x}_{20}+\ket{1}\bra{1}\otimes\hat{x}_{20}\numeq{\textrm{\ref{x_20}-\ref{x_21}}}\ket{0}\bra{0}\otimes\hat{1}_{2}+\ket{1}\bra{1}\otimes\hat{\sigma}_{x}\equiv\hat{U}_{C_{NOT}}
\end{equation}

\noindent
{\color{red} \rule{\linewidth}{0.5mm} }


\vspace{1cm}











\end{document}
